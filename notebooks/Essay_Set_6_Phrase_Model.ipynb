{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import spacy\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "essays = pd.read_csv('../data/intermediate/prepped_essays_df.csv')\n",
    "\n",
    "# ----------- ISOLATE JUST ESSAYS FROM 6th SET ------------ #\n",
    "essays = essays[essays['essay_set'] == 6]\n",
    "essays.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "intermediate_directory = os.path.join('../data/intermediate')\n",
    "\n",
    "essay_set6_txt_filepath = os.path.join(intermediate_directory, 'essay_set6_text_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from 1,800 essays written to the new txt file.\n"
     ]
    }
   ],
   "source": [
    "# ----------- WRITE ALL ESSAYS TO A .TXT FILE ------------ #\n",
    "if 0 == 1:\n",
    "    essay_count = 0\n",
    "\n",
    "    # create & open a new file in write mode\n",
    "    with codecs.open(essay_set6_txt_filepath, 'w', encoding='utf_8') as essay_set6_txt_file:\n",
    "\n",
    "        # loop through all essays in the dataframe\n",
    "        for row in essays.itertuples():\n",
    "            # write the essay as a line in the new file and escape newline characters in the original essays\n",
    "            essay_set6_txt_file.write(row.essay.replace('\\n', '\\\\n') + '\\n')\n",
    "            essay_count += 1\n",
    "\n",
    "        print('Text from {:,} essays written to the new txt file.'.format(essay_count))\n",
    "\n",
    "else:\n",
    "\n",
    "    with codecs.open(essay_set6_txt_filepath, encoding='utf_8') as essay_set6_txt_file:\n",
    "        for essay_count, line in enumerate(essay_set6_txt_file):\n",
    "            pass\n",
    "\n",
    "        print('Text from {:,} essays in the txt file.'.format(essay_count + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There were many obstacles the builders of the Empire State Building faced in attempting to allow dirigibles to dock on the mooring mast. One obstacle they faced was the lack of a suitable landing area. They would have to design a mast for the dirigibles. Another obstacle was the dirigibles was held by a single cable tether and that would add stress to the building\\'s frame. Next, New York City would have to spend over sixty thousand dollars\\' worth of modifications had to be made to the building\\'s framework. Then the greatest reason of safety came upon them. That was, most dirigibles from outside of the United States used hydrogen rather than helium. And hydrogen is highly flammable. On @DATE1 a German dirigible \"Hindenburg\" was destroyed by fire in Lakehurst, New Jersey. The owners of the Empire state building realized if that happened to New York and how big of a problem that would cause. The final and greatest obstacle they faced to the successful use of the mooring mast was nature itself. From all the violent wind and air currents would be hard to tether the dirigibles to the mast. In conclusion, those were the obstacles the builders of the Empire state Building faced in attempting to allow dirigibles to land there.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------- USING SPACY ON A SINGLE ESSAY ------------ #\n",
    "# Run the commands below to look more into a specific essay\n",
    "\n",
    "test_essay = essays.iloc[1443, 2]\n",
    "test_essay\n",
    "# parsed_essay = nlp(test_essay)\n",
    "\n",
    "# for num, sentence in enumerate(parsed_essay.sents):\n",
    "#     print('Sentence {}:'.format(num + 1))\n",
    "#     print(sentence)\n",
    "#     print('')\n",
    "\n",
    "# for num, entity in enumerate(parsed_essay.ents):\n",
    "#     print('Entity {}:'.format(num + 1), entity, '-', entity.label_)\n",
    "#     print('')\n",
    "\n",
    "# token_text = [token.orth_ for token in parsed_essay]\n",
    "# token_pos = [token.pos_ for token in parsed_essay]\n",
    "\n",
    "# pd.DataFrame(zip(token_text, token_pos), columns=['token_text', 'part_of_speech'])\n",
    "\n",
    "# token_lemma = [token.lemma_ for token in parsed_essay]\n",
    "# token_shape = [token.shape_ for token in parsed_essay]\n",
    "\n",
    "# pd.DataFrame(zip(token_text, token_lemma, token_shape), columns=['token_text', 'token_lemma', 'token_shape'])\n",
    "\n",
    "# token_entity_type = [token.ent_type_ for token in parsed_essay]\n",
    "# token_entity_iob = [token.ent_iob_ for token in parsed_essay]\n",
    "\n",
    "# pd.DataFrame(zip(token_text, token_entity_type, token_entity_iob), columns=['token_text', 'entity_type', 'inside_outside_begin'])\n",
    "\n",
    "# token_attributes = [(token.orth_,\n",
    "#                      token.prob,\n",
    "#                      token.is_stop,\n",
    "#                      token.is_punct,\n",
    "#                      token.is_space,\n",
    "#                      token.like_num,\n",
    "#                      token.is_oov)\n",
    "#                     for token in parsed_essay]\n",
    "\n",
    "# df = pd.DataFrame(token_attributes,\n",
    "#                   columns=['text',\n",
    "#                            'log_probability',\n",
    "#                            'stop?',\n",
    "#                            'punctuation?',\n",
    "#                            'whitespace?',\n",
    "#                            'number?',\n",
    "#                            'out of vocab.?'])\n",
    "\n",
    "# df.loc[:, 'stop?':'out of vocab.?'] = (df.loc[:, 'stop?':'out of vocab.?'].applymap(lambda x: u'Yes' if x else u''))\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- ADD OR REMOVE STOP WORDS ------------ #\n",
    "# removing_stanford_nlp_groups_NER_from_stop_words(nlp)\n",
    "def adding_stanford_nlp_groups_NER_to_stop_words():\n",
    "    \"\"\"\n",
    "    helper funciton to add Stanford NLP Group NERs to spaCy stop words\n",
    "    range of 0 - 15\n",
    "    \"\"\"\n",
    "\n",
    "    for number in list(range(0, 16)):\n",
    "        nlp.vocab['@ORGANIZATION' + str(number)].is_stop = True\n",
    "        nlp.vocab['@PERSON' + str(number)].is_stop = True\n",
    "        nlp.vocab['@CAPS' + str(number)].is_stop = True\n",
    "        nlp.vocab['@LOCATION' + str(number)].is_stop = True\n",
    "        nlp.vocab['@DATE' + str(number)].is_stop = True\n",
    "        nlp.vocab['@TIME' + str(number)].is_stop = True\n",
    "        nlp.vocab['@MONEY' + str(number)].is_stop = True\n",
    "        nlp.vocab['@PERCENT' + str(number)].is_stop = True\n",
    "        nlp.vocab['@MONTH' + str(number)].is_stop = True\n",
    "        nlp.vocab['@EMAIL' + str(number)].is_stop = True\n",
    "        nlp.vocab['@NUM' + str(number)].is_stop = True\n",
    "        nlp.vocab['@DR' + str(number)].is_stop = True\n",
    "        nlp.vocab['@CITY' + str(number)].is_stop = True\n",
    "        nlp.vocab['@STATE' + str(number)].is_stop = True\n",
    "        \n",
    "adding_stanford_nlp_groups_NER_to_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obstacle dirigible hold single cable tether\n",
      "\n",
      "add stress building frame order frame sturdy modification building framework cost thousand dollar\n",
      "\n",
      "obstacle builder face dirigible use hydrogen highly flammable\n",
      "\n",
      "New York densely populated area work\n",
      "\n",
      "dirigible weight lead weight\n",
      "\n",
      "order lead weight end dangle high pedestrian street safety issue obstacle builder face law airship fly low urban area\n",
      "\n",
      "law illegal ship tie building approach area\n",
      "\n",
      "passage Mooring Mast Marcia Amidon\n",
      "\n",
      "builder Empire State Building face opstacle building Empire State Building allow dirigible dock\n",
      "\n",
      "reason Al Smith term governor New York head effort construct Empire State Building year office tower tall\n",
      "\n",
      "hight building 1,250 ft\n",
      "\n",
      "lose title world tall tower announce hat tower\n",
      "\n",
      "reason tower dirigible blimp\n",
      "\n",
      "people New York New Jersey\n",
      "\n",
      "Smith want place dirigible dock\n",
      "\n",
      "happen german dirigible Hindenburg destroy fire Lakehurst New Jersey 6 1937 owner State building realize bad accident New York\n",
      "\n",
      "1930 idea drop dirigible try proform stunt\n",
      "\n",
      "Empire State Building get fofil\n",
      "\n",
      "builder Empire State Building face obstacle attempt allow dirigible dock\n",
      "\n",
      "obstacle face exist law airship fly low urban area\n",
      "\n",
      "illegal dirigible tie building\n",
      "\n",
      "obstacle face allow dirigible dock safety\n",
      "\n",
      "dirigible hydrogen highly flammable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def punct_space_stop(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation, whitespace or stopwords\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space or token.is_stop\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(line_review(filename), batch_size=100, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield ' '.join([token.lemma_ for token in sent if not punct_space_stop(token)])\n",
    "\n",
    "\n",
    "# ----------- LOOKING AT UNIGRAMS ------------ #\n",
    "unigram_sentences_filepath = os.path.join(intermediate_directory, 'unigram_sentences_all_essays6.txt')\n",
    "essays_set6_all_filepath = os.path.join(intermediate_directory, 'essay_set6_text_all.txt')\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus(essays_set6_all_filepath):\n",
    "            f.write(sentence + '\\n')\n",
    "\n",
    "unigram_sentences = LineSentence(unigram_sentences_filepath)\n",
    "\n",
    "for unigram_sentence in it.islice(unigram_sentences, 19, 42):\n",
    "    print(' '.join(unigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obstacle dirigible hold_single cable_tether\n",
      "\n",
      "add_stress building frame order frame sturdy modification building framework cost_thousand dollar\n",
      "\n",
      "obstacle builder face dirigible use hydrogen_highly flammable\n",
      "\n",
      "New_York densely_populated area work\n",
      "\n",
      "dirigible weight_lead weight\n",
      "\n",
      "order lead_weight end dangle_high pedestrian_street safety_issue obstacle builder face law_airship fly_low urban_area\n",
      "\n",
      "law illegal_ship tie building approach_area\n",
      "\n",
      "passage_Mooring Mast_Marcia Amidon\n",
      "\n",
      "builder Empire_State Building face opstacle building Empire_State Building allow dirigible dock\n",
      "\n",
      "reason Al_Smith term_governor New_York head effort construct Empire_State Building year office tower tall\n",
      "\n",
      "hight building 1,250_ft\n",
      "\n",
      "lose_title world_tall tower announce hat tower\n",
      "\n",
      "reason tower dirigible blimp\n",
      "\n",
      "people New_York New_Jersey\n",
      "\n",
      "Smith_want place dirigible dock\n",
      "\n",
      "happen german dirigible Hindenburg_destroy fire_Lakehurst New_Jersey 6_1937 owner State building realize_bad accident New_York\n",
      "\n",
      "1930 idea drop dirigible try proform stunt\n",
      "\n",
      "Empire_State Building get fofil\n",
      "\n",
      "builder Empire_State Building face obstacle attempt_allow dirigible dock\n",
      "\n",
      "obstacle face exist_law airship_fly low_urban area\n",
      "\n",
      "illegal dirigible tie building\n",
      "\n",
      "obstacle face allow dirigible dock safety\n",
      "\n",
      "dirigible hydrogen_highly flammable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------- LOOKING AT BIGRAMS ------------ #\n",
    "bigram_model_filepath = os.path.join(intermediate_directory, 'bigram_model_all6')\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "\n",
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)\n",
    "\n",
    "bigram_sentences_filepath = os.path.join(intermediate_directory, 'bigram_sentences_all6.txt')\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            bigram_sentence = ' '.join(bigram_model[unigram_sentence])\n",
    "\n",
    "            f.write(bigram_sentence + '\\n')\n",
    "\n",
    "bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "\n",
    "for bigram_sentence in it.islice(bigram_sentences, 19, 42):\n",
    "    print(' '.join(bigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quote_show Dirigible need find proper landing_area\n",
      "\n",
      "able fit\n",
      "\n",
      "need area space\n",
      "\n",
      "long_thousand_foot length_block_New_York City\n",
      "\n",
      "space Dirigible long\n",
      "\n",
      "show architect come plan make work way fit properly\n",
      "\n",
      "obstacle builder Empire_State_Building face\n",
      "\n",
      "lack_suitable area\n",
      "\n",
      "builder Empire_State_Building face difficult circumstance obstacle task design brand new Empire_State_Building accompany new mean travel\n",
      "\n",
      "builder mission design Empire_State_Building accommodate mooring blimp thousand_foot air\n",
      "\n",
      "obstacle design landing_area\n",
      "\n",
      "difficult architecture need create attempt past\n",
      "\n",
      "second obstacle have sure Empire_State_Building withstand_stress create blimp\n",
      "\n",
      "paragraph say stress dirigible load_wind_pressure_transmit way building foundation\n",
      "\n",
      "difficulty obstacle have refurbish steel_frame Empire_State_Building take lot time work thousand_dollar\n",
      "\n",
      "great obstacle successful mooring nature\n",
      "\n",
      "violent_wind current building blimp stable\n",
      "\n",
      "pedestrian moor dirigible dangerous obstacle\n",
      "\n",
      "lastly pre exist_law_airship_fly low_urban_area pose new problem\n",
      "\n",
      "successful architecture law disallow blimp place\n",
      "\n",
      "plane popular\n",
      "\n",
      "build Empire_State_Building builder face problem allow dirigible dock\n",
      "\n",
      "obstacle builder face actually have way dirigible dock 1,250_foot ground\n",
      "\n",
      "strong air_current change wind direction difficult piolot steer dirigible close mast docking\n",
      "\n",
      "final problem builder face law_airship_fly_low urban_area\n",
      "\n",
      "basically mean dock Empire_State building low_urban aera law\n",
      "\n",
      "idea mooring dirigible building stand 1,250_foot street downtown_New_York facinating amazing idea\n",
      "\n",
      "idea bring New_York age_transportation\n",
      "\n",
      "unfortunately wonderful idea hole plan\n",
      "\n",
      "later architect build mooring_mast discover idea go fulfill\n",
      "\n",
      "idea obstacle overcome\n",
      "\n",
      "fact dirigible outside U. S hydrogen_helium_hydrogen_highly flammable\n",
      "\n",
      "wrong catostrophic seeing highly_populated street\n",
      "\n",
      "great obstacle nature\n",
      "\n",
      "wind aircraft steady undercontrol\n",
      "\n",
      "reality fact idea moor derigible sound great far risk carry plan\n",
      "\n",
      "excerpt mooring Marcia_Amidon builder empire_State_Building face obstacle attempt_allow dirigible dock\n",
      "\n",
      "Empire_State_Building destine_fulfill_purpose reason obstacle\n",
      "\n",
      "reason dirigible outside_United_States_hydrogen helium_hydrogen_highly_flammable\n",
      "\n",
      "furthermore big obstacle sucessful use morning_mast nature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------- LOOKING AT TRIGRAMS ------------ #\n",
    "trigram_model_filepath = os.path.join(intermediate_directory, 'trigram_model_all6')\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "\n",
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)\n",
    "\n",
    "trigram_sentences_filepath = os.path.join(intermediate_directory, 'trigram_sentences_all6.txt')\n",
    "\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            trigram_sentence = ' '.join(trigram_model[bigram_sentence])\n",
    "\n",
    "            f.write(trigram_sentence + '\\n')\n",
    "\n",
    "trigram_sentences = LineSentence(trigram_sentences_filepath)\n",
    "\n",
    "for trigram_sentence in it.islice(trigram_sentences, 205, 245):\n",
    "    print(' '.join(trigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "In the the excerpt \"The Mooring Mast\" by Marcia Amidon Lüsted, the builders of the Empire State Building faced many obstacles in the attempt to allow dirigibles to dock there. The architects had to acomidate a lot of thing to allow dirigibles to dock at The mooring mast. For example In @CAPS1 @NUM1 it says \"The steelframe of the Empire State Building would have to modify and strengthen to accommodate this new situation\". Also in @CAPS1 @NUM2 it says \"The greatest obstacle to the successful use of the mooring mast was natur itself. The winds on top of the building were constantly shifting due to violent air currents\". These factores and many more where the reason the mooring mast was never poot to use do to the feer of safty and law.\n",
      "\n",
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "excerpt_Mooring_Mast_Marcia Amidon_Lüsted builder Empire_State_Building face obstacle attempt_allow dirigible dock architect acomidate lot thing allow dirigible dock mooring_mast example say steelframe Empire_State_Building modify_strengthen_accommodate_new situation say great obstacle successful_use_mooring_mast natur wind building constantly_shift_violent_air current factore reason mooring_mast poot use feer safty law\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------- RUN THE TRIGRAMS PHRASE MODEL ON ALL ESSAYS ------------ #\n",
    "trigram_essays_all_filepath = os.path.join(intermediate_directory, 'trigram_essays_all6.txt')\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(trigram_essays_all_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "        for parsed_essay in nlp.pipe(line_review(essays_set6_all_filepath), batch_size=100, n_threads=4):\n",
    "            # lemmatize the text, removing punctuation and whitespace\n",
    "            unigram_essays = [token.lemma_ for token in parsed_essay if not punct_space_stop(token)]\n",
    "\n",
    "            # apply the first-order and second-order phrase models\n",
    "            bigram_essays = bigram_model[unigram_essays]\n",
    "            trigram_essays = trigram_model[bigram_essays]\n",
    "\n",
    "            # write the transformed review as a line in the new file\n",
    "            trigram_essays = ' '.join(trigram_essays)\n",
    "            f.write(trigram_essays + '\\n')\n",
    "\n",
    "print('Original:' + '\\n')\n",
    "\n",
    "for essay in it.islice(line_review(essays_set6_all_filepath), 301, 302):\n",
    "    print(essay)\n",
    "\n",
    "print('----' + '\\n')\n",
    "print('Transformed:' + '\\n')\n",
    "\n",
    "with codecs.open(trigram_essays_all_filepath, encoding='utf_8') as f:\n",
    "    for essay in it.islice(f, 301, 302):\n",
    "        print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
