{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>misspelt</th>\n",
       "      <th>correct</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>n_top500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>123</td>\n",
       "      <td>1.37</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>180</td>\n",
       "      <td>1.55</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>169</td>\n",
       "      <td>1.62</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>1.69</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>162</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          domain1_score  misspelt  correct  length  lexical_diversity  \\\n",
       "essay_id                                                                \n",
       "14834               2.0         6      116     123               1.37   \n",
       "14835               3.0        11      169     180               1.55   \n",
       "14836               4.0         4      162     169               1.62   \n",
       "14837               1.0        18      175     199               1.69   \n",
       "14838               3.0         4      158     162               1.74   \n",
       "\n",
       "          n_sentences  nouns  verbs  adverbs  adjectives  n_top500  \n",
       "essay_id                                                            \n",
       "14834               9     29     22        9           9         0  \n",
       "14835               9     43     35       15          13         0  \n",
       "14836               8     41     35       12           9         0  \n",
       "14837              11     36     38        8           4         0  \n",
       "14838              11     38     34       10          13         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "essays = pd.read_csv('../data/processed/essays_model_2.csv', index_col=0)\n",
    "\n",
    "# Set the essay id as the index of the dataframe\n",
    "essays.set_index('essay_id', inplace=True)\n",
    "\n",
    "essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = essays.drop(['domain1_score'], axis=1)\n",
    "y = essays['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5888888888888889"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred, y_test)\n",
    "accuracy_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5388888888888889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_gini = accuracy_score(y_pred, y_test)\n",
    "accuracy_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63103448, 0.57439446, 0.55555556, 0.59930314, 0.55944056])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=2)\n",
    "\n",
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "Accuracy_CV_scores = cross_val_score(dt_entropy, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1) \n",
    "\n",
    "Accuracy_CV_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED=3\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=5)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=SEED)\n",
    "\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.525\n",
      "K Nearest Neighbours : 0.536\n",
      "Classification Tree : 0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_pred, y_test) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=0.016, random_state=4)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=12)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.61\n",
      "OOB accuracy of bc: 0.58\n"
     ]
    }
   ],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=0.016, random_state=4)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, oob_score=True, n_jobs=-1, random_state=13)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Extract the OOB accuracy from bc\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) \n",
    "\n",
    "print('OOB accuracy of bc: {:.2f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestClassifier(criterion='entropy', random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 2,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': ['gini', 'entropy'],\n",
       " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# criterion for information gain\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'criterion': criterion,\n",
    "               'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=2, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'criterion': 'entropy',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[  2   0   1   1   0]\n",
      " [  3  10  19   2   1]\n",
      " [  0   4  34  35   0]\n",
      " [  2   4  24 119  22]\n",
      " [  0   0   2  35  40]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.50      0.36         4\n",
      "         1.0       0.56      0.29      0.38        35\n",
      "         2.0       0.42      0.47      0.44        73\n",
      "         3.0       0.62      0.70      0.66       171\n",
      "         4.0       0.63      0.52      0.57        77\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       360\n",
      "   macro avg       0.50      0.49      0.48       360\n",
      "weighted avg       0.57      0.57      0.56       360\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestClassifier(criterion='entropy', random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[  1   1   0   2   0]\n",
      " [  0   9  24   2   0]\n",
      " [  0   0  34  38   1]\n",
      " [  0   0  19 128  24]\n",
      " [  0   0   1  32  44]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.25      0.40         4\n",
      "         1.0       0.90      0.26      0.40        35\n",
      "         2.0       0.44      0.47      0.45        73\n",
      "         3.0       0.63      0.75      0.69       171\n",
      "         4.0       0.64      0.57      0.60        77\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       360\n",
      "   macro avg       0.72      0.46      0.51       360\n",
      "weighted avg       0.62      0.60      0.59       360\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate rf with best params from Random Search\n",
    "rf_random = RandomForestClassifier(criterion='entropy', \n",
    "                            n_estimators=1400, \n",
    "                            min_samples_leaf=4, \n",
    "                            min_samples_split=10, \n",
    "                            max_features='sqrt',\n",
    "                            max_depth=20,\n",
    "                            bootstrap=True,\n",
    "                            random_state=2)\n",
    "\n",
    "# Fit rf to the training set    \n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEICAYAAAAtAOHGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYHVWd//H3h4CABCEQwrCFFoyDhCVIA4KKigq4ogMYFMSAY0RRwjzAgMoIbiOiowZRITBsgmMENxRlkdVh2DoQAhEQTEC2nyGSBALI0nx+f9RpvTaddKeX3NvVn9fz3Cd1T51z6lvV6XxzTp17S7aJiIiom1WaHUBERMRQSIKLiIhaSoKLiIhaSoKLiIhaSoKLiIhaSoKLiIhaSoKLiIhaSoKL6EbS/ZKekbS04bXxAPt8s6SHBivGgWixWNokWdKqzY4l6icJLqJn77E9uuH1SDODqWMCqOM5RWtJgotYAZJeJ+n/JC2WdLukNzfsO0TSXZKelDRP0sdL+VrAb4CNG0eEks6R9OWG9v8wsiojyWMlzQGekrRqafcTSY9Jmi/piIb6O0vqkPSEpD9L+mYfz+kaSV8u57VU0i8lrS/pgtLXLZLaGupb0hHlHBdK+rqkVcq+VSQdL+kBSQsknSdpnbKva7T2UUl/Aq4CrivdLi7H3lXSlpKukvSX0v8Fktbtdl2OljRH0hJJMyWt0bB/H0mzS+x/lLR3KV9H0n9LelTSw+WcR5V9r5J0belvoaSZfbl20dqS4CL6SNImwCXAl4H1gKOBn0jaoFRZALwbeAVwCPAtSa+1/RTwDuCRfowIPwi8C1gXeBH4JXA7sAnwVuBISXuVutOB6bZfAWwJ/HgFTu8A4MOl3y2BG4Czy3neBZzQrf77gXbgtcA+wKGlfEp5vQXYAhgNnNqt7ZuA1wB7AbuXsnXLdbkBEPBVYONSbzPgxG59fADYG3glsF05JpJ2Bs4DjqG6ZrsD95c25wAvAK8CdgD2BP617PsScDkwBtgU+E4P1yiGmSS4iJ79vIzSFkv6eSk7CPi17V/bftH2FUAH8E4A25fY/qMr11L9g/nGAcZxiu0HbT8D7ARsYPuLtp+zPQ84gyo5ATwPvErSWNtLbd+4Asc5u8S+hGq0+Ufbv7X9AnAhVUJo9DXbj9v+E/BtqkQMcCDwTdvzbC8FPgMc0G068kTbT5Vzegnb99m+wvazth8DvkmVFLtfl0dsP06V9CeV8o8CZ5X2L9p+2Pbdkjak+jkdWY69APhWt2u3ObCx7b/a/t++X7poVUlwET17n+11y+t9pWxzYP+GxLcYeAOwEYCkd0i6UdLjZd87gbEDjOPBhu3NqaY5G4//WWDDsv+jwKuBu8u04rtX4Dh/bth+pof3o5cT1wNUoy3Knw9027dqQ4zd276EpA0l/ahMIz4BnM9Lr+P/a9h+uiG+zYA/9tDt5sBqwKMN1+50YFzZ/+9UI8ebJc2VdGgPfcQwk5u8EX33IPAD2x/rvkPS6sBPgIOBX9h+voz8VKr09NiOp4CXN7z/px7qNLZ7EJhve0JPwdm+F/hguR/2L8BFktYvU6SDbTNgbtkeD3RNuT5ClUxo2PcCVcLctCvUxrB76Ps/S/m2th+X9D5eOs25LA9STbH2VP4sMLaMSv+B7f8HfAxA0huA30q6zvZ9fTxutKCM4CL67nzgPZL2kjRK0hplYcimwMuA1YHHgBckvYPqHk+XPwPrdy24KGYD75S0nqR/Ao7s5fg3A0+WhSdrlhi2kbQTgKSDJG1g+0VgcWnz4oDPumfHSBojaTNgGtC1KON/gH+T9EpJo6mS1cyekkrxWIlxi4aytYGlwJJy3/OYFYjrv4FDJL21LHjZRNJWth+lmjL+L0mvKPu2lPQmAEn7l58jwCKqBDtU1y5WkiS4iD6y/SDVgorPUv3D/CDVP76r2H4SOIJqYcci4EPAxQ1t76b6x39emSLbGPgB1YKR+6n+8V3uyj3bnVSLWCYB84GFwJlAV9LcG5graSnVgpMDlnWfaxD8AphFlaQvoUosAGdRndd1Jca/Ap9eVie2nwa+AlxfrsvrgC9QLV5ZUvr+aV+Dsn0zZYFPaX8tfx9RHkz1H5HfU/2MLqJML1Pd37ypXLuLgWnlHmcMY8oDTyNiRUgyMCHTd9HqMoKLiIhaSoKLiIhayhRlRETUUkZwERFRS/kcXBONHTvWbW1tzQ4jImJYmTVr1kLbG/RWLwmuidra2ujo6Gh2GBERw4qkB3qvlSnKiIioqSS4iIiopSS4iIiopSS4iIiopSwyaaIFnQuYvmh6s8OIiFippo2ZtlKOkxFcRETUUhJcRETUUhJcRETU0ohJcJLaJN0l6YzySPrLy0MjJ0m6UdIcST+TNKbUv0ZSe9keK+n+sj1F0k8lXSrpXkknl/JRks6RdKekOyT9W9NONiIiRk6CKyYA37U9keqJx/sC5wHH2t4OuAM4oQ/9TAImA9sCk8tTjScBm9jexva2wNk9NZQ0VVKHpI6lC5cO/IwiIqJHIy3Bzbc9u2zPArYE1rV9bSk7F9i9D/1caXuJ7b9SPR14c2AesIWk70jaG3iip4a2Z9hut90+euzoAZ1MREQs20hLcM82bHcC6y6n7gv8/fqs0Us/q9peBGwPXAMcBpw5oEgjImJARlqC624JsEjSG8v7DwNdo7n7gR3L9n69dSRpLLCK7Z8AxwOvHdxQIyJiReSD3vAR4DRJL6eaZjyklH8D+LGkqcAlfehnE+BsSV3/afjMoEcaERF9lid6N9H4Hcb7qKuOanYYEREr1UC/yUTSLNvtvdXLCK6Jxo0at9K+siYiYqQZ6ffgIiKippLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilvJVXU20oHMB0xdNb3YYERED0qpfOZgRXERE1NKISHCSlg5Bn5MkvbPh/YmSjh7s40RERP+MiAQ3RCYB7+y1VkRENMWIS3CSjpF0i6Q5kr5Qytok3SXpDElzJV0uac2yb6dSd7akr0u6U9LLgC8Ck0v55NL91pKukTRP0hFNOsWIiGCEJThJewITgJ2pRmA7Stq97J4AfNf2RGAxsG8pPxv4uO1JQCeA7eeAzwMzbU+yPbPU3QrYq/R/gqTVeohhqqQOSR1LFw76zGlERBQjKsEBe5bXbcCtVAlpQtk33/bssj0LaJO0LrC27RtK+Q976f8S28/aXggsADbsXsH2DNvttttHjx09wNOJiIhlGWkfExDwVdun/0Oh1AY821DUCazZj/679zHSrm9ERMsYaSO4y4BDJY0GkLSJpHHLqmx7MfCkpF1K0QENu58E1h6ySCMiYkBGVIKzfTnVNOMNku4ALqL3JPVR4AxJs4G1gCWl/GqqRSWNi0wiIqJFyHazY2hpkkbbXlq2jwM2sj0oH9tvb293R0fHYHQVETFiSJplu723erlH1Lt3SfoM1bV6AJjS3HAiIqIvkuB6UT4CMLPXihER0VJG1D24iIgYOZLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilpLgIiKilvJB7yZa0LmA6YumNzuMiKi5aWMG5dsFh52M4CIiopaS4CIiopaS4AaZpCmSNm52HBERI10SXANJqy7vfR9NAZLgIiKarLaLTCQdDBwNGJgD/AdwFjAWeAw4xPafJJ0D/BXYAbhe0hPAlsAWwJ8kHQScBLwZWB34ru3TyzGOBQ4CXgR+A3QA7cAFkp4BdrX9zEo54YiI+Ae1THCSJgLHA7vZXihpPeBc4Fzb50o6FDgFeF9psmmp2ynpRGBr4A22n5E0FVhieydJq1MlwcuBrYB9gF1sPy1pPduPS/oUcLTtHp9kWvqbCjBm0zFDdQkiIka8uk5R7gFcaHshgO3HgV2BH5b9PwDe0FD/QtudDe8vbhh57QkcLGk2cBOwPjABeBtwtu2nG47RK9szbLfbbh89dnT/zi4iInpVyxFcPzy1nPcCPm37ssYKkvYa8qgiIqLf6jqCuwrYX9L6AGWK8v+AA8r+A4Hf9bGvy4BPSFqt9PVqSWsBVwCHSHp5wzEAngTWHpSziIiIfqvlCM72XElfAa6V1AncBnwaOFvSMZRFJn3s7kygDbhVkkrb99m+VNIkoEPSc8Cvgc8C5wCnZZFJRERzyXazYxix2tvb3dHR41qUiIhYBkmzbLf3Vq+uU5QRETHCJcFFREQtJcFFREQtJcFFREQtJcFFREQtJcFFREQtJcFFREQtJcFFREQtJcFFREQtJcFFREQt1fK7KIeLBZ0LmL5oerPDiKiVaWOmNTuEaBEZwUVERC0N2wQnaYqkU8v2YZIO7kcf60r6ZMP7jSVdNJhxRkREcwzbBNfI9mm2z+tH03WBvyU424/Y3m/wIouIiGZp2QQn6eeSZkmaK2lqKTtE0h8k3Qy8vqHuiZKOLttbSrq0tP2dpK1K+YaSfibp9vLaDTgJ2FLSbElfl9Qm6c5S/0ZJExuOcY2kdklrSTpL0s2SbpO0T9k/sZTNljRH0oSVdrEiIuIlWnmRyaG2H5e0JnCLpEuALwA7AkuAq6keZNrdDOAw2/dK2gX4HrAHcApwre33SxoFjAaOA7axPQlAUltDPzOBDwAnSNoI2Mh2h6T/BK6yfaikdYGbJf0WOAyYbvsCSS8DRvV0UiVZTwUYs+mYfl+ciIhYvlZOcEdIen/Z3gz4MHCN7ccAJM0EXt3YQNJoYDfgwurh2wCsXv7cAzgYwHYnsETS8jLMj4HLgROoEl3Xvbk9gfd2jRiBNYDxwA3A5yRtCvzU9r09dWp7BlUSZvwO4/O02YiIIdKSCU7Sm4G3AbvaflrSNcDdwNa9NF0FWNw1IhsI2w9L+ouk7YDJVCM0AAH72r6nW5O7JN0EvAv4taSP275qoHFERET/tOo9uHWARSW5bQW8DlgTeJOk9SWtBuzfvZHtJ4D5kvYHUGX7svtK4BOlfJSkdYAngbWXE8dM4N+BdWzPKWWXAZ9WGSJK2qH8uQUwz/YpwC+A7fp/+hERMVCtmuAuBVaVdBfVQpAbgUeBE6mmAq8H7urWpmu670Dgo5JuB+YC+5TyacBbJN0BzAK2tv0X4HpJd0r6eg9xXAQcQDVd2eVLwGrAHElzy3uopjHvlDQb2Aboz6rOiIgYJLKH/20gSd8BbrV9drNjWRHjdxjvo646qtlhRNRKvsmk/iTNst3eW72WvAe3IiR9CdiFanQ3rIwbNS6/jBERQ6RVpyj7zPZ/2N65TDdGREQANUhwERERPUmCi4iIWkqCi4iIWkqCi4iIWkqCi4iIWkqCi4iIWkqCi4iIWkqCi4iIWkqCi4iIWhr2X9U1nC3oXMD0RdObHUbEsJGvtosVkRFcRETUUhJcRETUUq8JTtLS/nQsaWNJF/Wz7TmS9utj3TdL+lXZfq+k4/pzzD4e62/nJGmSpHcO1bEiImJghmwEZ/sR231KUoN4zIttnzTQfiT1eG+y2zlNApLgIiJa1AolOEnHSLpF0hxJXyhlO5X3a0haS9JcSdtIapN0Z6kzStI3ypOz50j6dCn/fOnvTkkzJKmPcewt6W5JtwL/0lA+RdKpktaR9ICkVUr5WpIelLSapC0lXSpplqTfSdqq1DlH0mmSbgJOlvQmSbPL6zZJa3edk6SXAV8EJpf9kyXdK2mD0tcqku7ret8t9qmSOiR1LF3Yr8FxRET0QZ9XUUraE5gA7AwIuFjS7ravk3Qx8GVgTeB823dKamtoPhVoAybZfkHSeqX8VNtfLP3/AHg38Mte4lgDOAPYA7gPmNm9ju0lkmYDbwKuLv1eZvt5STOAw2zfK2kX4HulL4BNgd1sd0r6JXC47esljQb+2tD/c5I+D7Tb/lSJayvgQODbwNuA220/1kNsM4AZUD3Re3nnGhER/bciI7g9y+s24FZgK6qEB9Vo5u1AO3ByD23fBpxu+wUA24+X8rdIuknSHVRJZmIf4tgKmG/7XtsGzl9GvZnA5LJ9ADCzJKrdgAtLAjwd2KihzYW2O8v29cA3JR0BrNsV+3KcBRxctg8Fzu7DuURExBBZkc/BCfiq7dN72Lc+MBpYDVgDeKrXzqqR2PeoRkEPSjqxtB0sFwP/WUaLOwJXAWsBi21PWkabv8Vt+yRJl1DdZ7te0l40jOK6K+fwZ0l7UI1yDxyk84iIiH5YkRHcZcChZRSEpE0kjSv7Tgf+A7gA+FoPba8APt61eKMkna5ktrD02dcFKXcDbZK2LO8/2FMl20uBW4DpwK9sd9p+Apgvaf8ShyRt31N7SVvavsP210o/W3Wr8iSwdreyM6lGlI0jwYiIaII+JzjblwM/BG4oU4oXAWtLOhh43vYPgZOAncooptGZwJ+AOZJuBz5kezHVvbQ7qZLnLX2M469U9/QuKYtMFiyn+kzgIP7xPt2BwEdLHHOBfZbR9siuRTHA88Bvuu2/Gti6a5FJKbuYaiSb6cmIiCZTdRsrBoOkduBbtt/Yl/rt7e3u6OgY4qgiIupF0izb7b3Vy3dRDpLyAfNPkHtvEREtoaUTnKSfAa/sVnys7cuaEc/ylA+YD/hD5hERMThaOsHZfn+zY4iIiOEpX7YcERG1lAQXERG1lAQXERG1lAQXERG1lAQXERG1lAQXERG1lAQXERG11NKfg6u7BZ0LmL5oerPDiGhZ08ZMa3YIMYxlBBcREbWUBLeCJC1tdgwREdG7TFH2kSRRPfQ1IiKGgRE3gpN0kqTDG96fKOloScdIukXSHElfKPvaJN0j6Tyq59ZtVsq/JWmupCslbVDKjpD0+9L+R804t4iI+LsRl+CoHn76gYb3HwAeAyYAOwOTgB0l7V72TwC+Z3ui7QeAtYAO2xOBa4ETSr3jgB1sbwcctqyDS5oqqUNSx9KFme2MiBgqIy7B2b4NGCdpY0nbA4uAbYE9gduAW4GtqBIbwAO2b2zo4kX+/oTw84E3lO05wAWSDgJeWM7xZ9hut90+euzowTqtiIjoZqTeg7sQ2A/4J6pktTnwVdunN1aS1AY81UtfXY9EfxewO/Ae4HOStrW9zEQXERFDa8SN4IqZwAFUSe5C4DLgUEmjASRtImncMtquUtoBfAj4X0mrAJvZvho4FlgHyPAsIqKJRuQIzvZcSWsDD9t+FHhU0muAG6rFkiwFDgI6e2j+FLCzpOOBBcBkYBRwvqR1qFZanmJ78Uo4lYiIWAbZ7r1WDIn29nZ3dHQ0O4yIiGFF0izb7b3VG6lTlBERUXNJcBERUUtJcBERUUtJcBERUUtJcBERUUtJcBERUUtJcBERUUtJcBERUUtJcBERUUtJcBERUUsj8rsoW8WCzgVMXzS92WFEDJlpY6Y1O4QYwTKCi4iIWkqCi4iIWhoRCU7SFEmnDlJfJ0o6ejD6ioiIoTMiEtxgkZR7lhERw0QtEpykn0uaJWmupKml7BBJf5B0M/D6UraOpAfKE7iRtJakByWtJmlLSZeWfn4naatS5xxJp0m6CTi5HHJ7STdIulfSx0q9jSRdJ2m2pDslvXGlX4iIiPibuoxIDrX9uKQ1gVskXQJ8AdgRWAJcDdxme4mk2cCbStm7gctsPy9pBnCY7Xsl7QJ8D9ij9L8psJvtTkknAtsBrwPWAm4rx/tg6esrkkYBL+8p0JKApwKM2XTM4F+JiIgA6pPgjpD0/rK9GfBh4BrbjwFImgm8uuyfCUymSnAHAN+TNBrYDbhQUlefqzf0f6Htzob3v7D9DPCMpKuBnYFbgLMkrQb83PbsngK1PQOYATB+h/F5nHpExBAZ9lOUkt4MvA3Y1fb2wG3A3ctpcjGwt6T1qEZ4V1Fdh8W2JzW8XtPQ5qlufXRPTLZ9HbA78DBwjqSD+31SERExYMM+wQHrAItsP13um70OWBN4k6T1y4hq/67KtpdSjbamA7+y3Wn7CWC+pP0BVNl+OcfcR9IaktYH3kw1Lbo58GfbZwBnAq8d/FONiIi+qsMU5aXAYZLuAu4BbgQeBU4EbgAWA92nC2cCF1Ilpy4HAt+XdDywGvAj4PZlHHMO1RTnWOBLth+R9BHgGEnPA0uBjOAiIppIdm4DNUt7e7s7OjqaHUZExLAiaZbt9t7q1WGKMiIi4iWS4CIiopaS4CIiopaS4CIiopaS4CIiopaS4CIiopaS4CIiopaS4CIiopaS4CIiopaS4CIiopbq8F2Uw9aCzgVMXzS92WFEjUwbM63ZIUS0jIzgIiKilmqd4CS9V9JxK+E450jar2wfKanHp3lHRMTKU+sEZ/ti2yet5MMeCSTBRUQ02bBNcJLaJN1dRk9/kHSBpLdJul7SvZJ2ljRF0qml/v6S7pR0u6TrStlESTdLmi1pjqQJDf1eIOkuSRd1jcgk7SjpWkmzJF0maaNuMR0BbAxcLenqlX1NIiLi74ZtgiteBfwXsFV5fQh4A3A08NludT8P7GV7e+C9pewwYLrtSUA78FAp/2fge7ZfAzwBfLI8Gfw7wH62dwTOAr7SeADbpwCPAG+x/ZaeApY0VVKHpI6lC5f2/8wjImK5hnuCm2/7DtsvAnOBK109wfUOoK1b3euBcyR9DBhVym4APivpWGBz28+U8gdtX1+2z6dKmv8MbANcIWk2cDyw6YoGbHuG7Xbb7aPHjl7R5hER0UfD/WMCzzZsv9jw/kW6nZvtwyTtArwLmCVpR9s/lHRTKfu1pI8D84Dujzk3IGCu7V2H4DwiImKQDfcRXJ9J2tL2TbY/DzwGbCZpC2BemVr8BbBdqT5eUlci+xDwv8A9wAZd5ZJWkzSxh0M9Caw9lOcSERG9GzEJDvi6pDsk3Qn8H3A78AHgzjLluA1wXql7D3C4pLuAMcD3bT8H7Ad8TdLtwGxgtx6OMwO4NItMIiKaS9Utq+giqQ34le1thvpY43cY76OuOmqoDxMjSL7JJEYCSbNst/dWb7jfgxvWxo0al3+QIiKGSBJcN7bvp5qujIiIYWwk3YOLiIgRJAkuIiJqKQkuIiJqKQkuIiJqKQkuIiJqKQkuIiJqKQkuIiJqKQkuIiJqKQkuIiJqKd9k0kQLOhcwfdH0ZocRQyhfxRbRPBnBRURELdU6wUn6bLNjiIiI5qh1ggOS4CIiRqiVluAktUm6S9IZkuZKulzSmsuoe4Sk30uaI+lHpWwtSWdJulnSbZL2KeVTJP1U0qWS7pV0cik/CVhT0mxJF5Syg0r72ZJOlzSqlC+V9BVJt0u6UdKGpXxDST8r5bdL2m1Z/ZTXOZLuLA9W/bchv6gREbFMK3sENwH4ru2JwGJg32XUOw7YwfZ2wGGl7HPAVbZ3Bt5C9YTutcq+ScBkYFtgsqTNbB8HPGN7ku0DJb2m1Hm97UlAJ3Bgab8WcKPt7YHrgI+V8lOAa0v5a4G5y+lnErCJ7W1sbwuc3dOJSZoqqUNSx9KFS/t+5SIiYoWs7AQ33/bssj0LaFtGvTnABZIOAl4oZXsCx0maDVwDrAGML/uutL3E9l+B3wOb99DnW4EdgVtKH28Ftij7ngN+1UNcewDfB7DdaXvJcvqZB2wh6TuS9gae6OnEbM+w3W67ffTY0cs4/YiIGKiV/TGBZxu2O4EepyiBdwG7A+8BPidpW0DAvrbvaawoaZce+u3pvASca/szPex73rZ7ad9rP5K2B/aiGnV+ADh0Of1ERMQQarlFJpJWATazfTVwLLAOMBq4DPi0JJV6O/Shu+clrVa2rwT2kzSutF9PUk8jvUZXAp8o9UdJWmdZ/UgaC6xi+yfA8VRTmhER0SSt+EHvUcD5JZkIOMX2YklfAr4NzClJcD7w7l76mlHq31ruwx0PXF7aPw8cDjywnPbTgBmSPko1svuE7RuW0c8zwNmlDKCnkWJERKwk+vvMXKxs43cY76OuOqrZYcQQyjeZRAw+SbNst/dWrxVHcCPGuFHj8g9gRMQQaWqCk/Rd4PXdiqfb7nGJfURERF81NcHZPryZx4+IiPpquVWUERERgyEJLiIiaikJLiIiaikJLiIiaikJLiIiaikJLiIiaikJLiIiainfZNJECzoXMH3R9AH3k29DiYh4qYzgIiKilpLgIiKilpLgIiKilmqZ4CRNkbTxANs/Jml2ef1rw76PSLq3vD7SUL6jpDsk3SfplK4Hs0ZERHPUMsEBU4B+J7hipu1J5XUmVE/vBk4AdgF2Bk6QNKbU/z7wMWBCee09wONHRMQADJsEJ6lN0l2SzpA0V9Llktbsod5+QDtwQRl9rSnprZJuKyOssyStXureL+nkUn6zpFf1EsZewBW2H7e9CLgC2FvSRsArbN/o6gmy5wHvW8Z5TJXUIalj6cKlA7giERGxPMMmwRUTgO/anggsBvbtXsH2RUAHcKDtSYCBc4DJtrel+mjEJxqaLCnlpwLfbijfV9IcSRdJ2qyUbQI82FDnoVK2SdnuXv4StmfYbrfdPnrs6D6edkRErKjhluDm255dtmcBbX1o88+l3R/K+3OB3Rv2/0/Dn7uW7V8Cbba3oxqlnTuQoCMiYuUbbgnu2YbtTgbng+ruvm37L7a7jnUmsGPZfhjYrKH+pqXs4bLdvTwiIppkuCW4vnoSWLts3wO0Ndxf+zBwbUPdyQ1/3gBQ7ql1eS9wV9m+DNhT0piyuGRP4DLbjwJPSHpdWT15MPCLQT6niIhYAXX9qq5zgNMkPUM17XgIcKGkVYFbgNMa6o6RNIdqdPjBUnaEpPcCLwCPU63KxPbjkr5U+gD4ou3Hy/Yny3HXBH5TXss1btS4fM1WRMQQUbXob2SSdD/QbnthM47f3t7ujo6OZhw6ImLYkjTLdntv9eo6RRkRESPcsJ6ilPRd4PXdiqfbPrsv7W23DXpQERHREoZ1grN9eLNjiIiI1pQpyoiIqKURvcik2SQ9SfUxhlY1FmjKApw+SnwDk/gGJvENzEDi29z2Br1VGtZTlDVwT19WAjWLpI7E13+Jb2AS38AkvkxRRkRETSXBRURELSXBNdeMZgfQi8Q3MIlvYBLfwIz4+LLIJCIiaikjuIiIqKUkuIiIqKUkuCEgaW9J90i6T9JxPexfXdLMsv8mSW0N+z5Tyu+RtFcrxSdK0spvAAAEZUlEQVTp7ZJmSbqj/LnHUMQ3kBgb9o+XtFTS0a0Wn6TtJN0gaW65lmu0SnySVpN0bonrLkmfGezY+hjf7pJulfSCpP267fuIpHvL6yOtFJ+kSQ0/2zmSJndv28z4Gva/QtJDkk5ttfjK7+7l5e/f77v/bq8Q23kN4gsYBfwR2AJ4GXA7sHW3Op8ETivbBwAzy/bWpf7qwCtLP6NaKL4dgI3L9jbAw612DRv2XwRcCBzdSvFRffZ0DrB9eb9+i/2MPwT8qGy/HLif6un2Kzu+NmA74Dxgv4by9YB55c8xZXtMC8X3amBC2d4YeBRYt1Xia9g/HfghcGqTfj+WGR9wDfD2sj0aeHl/Y8kIbvDtDNxne57t54AfAft0q7MPcG7Zvgh4qySV8h/Zftb2fOC+0l9LxGf7NtuPlPK5wJqSVh/k+AYUI4Ck9wHzS4xDYSDx7QnMsX07/O3p8Z0tFJ+BtVQ9O3FN4DngiZUdn+37bc8BXuzWdi/gCtuP214EXAHs3Srx2f6D7XvL9iPAAqDXb9xYWfEBSNoR2BC4fJDjGnB8krYGVrV9Ram31PbT/Q0kCW7wbQI82PD+oVLWYx3bLwBLqP4n35e2zYyv0b7ArbafHeT4BhSjpNHAscAXhiCuAcdH9T98S7qsTNH8e4vFdxHwFNXI40/AN/z3h/quzPiGom1fDcoxJO1MNYL54yDF1aXf8UlaBfgvYEim7ouBXL9XA4sl/VTSbZK+LmlUfwPJV3XFCpM0Efga1Wik1ZwIfMv20jKgazWrAm8AdgKeBq5U9fDGK5sb1t/sDHRSTa+NAX4n6be25zU3rOFF0kbAD4CP2H7JKKqJPgn82vZDLfz78Uaq2yF/AmYCU4D/7k9nGcENvoeBzRreb1rKeqxTpoLWAf7Sx7bNjA9JmwI/Aw62Pdj/Mx2MGHcBTlb1tPYjgc9K+lQLxfcQcJ3thWXq5dfAa1sovg8Bl9p+3vYC4HpgsL8vcCB/z1vld2SZJL0CuAT4nO0bBzk2GFh8uwKfKr8f3wAOlnTS4IY3oPgeAmaX6c0XgJ8zkN+Pwb7BONJfVP8DmUe1SKTrBuvEbnUO5x9v8P+4bE/kHxeZzGPwFyAMJL51S/1/adVr2K3OiQzNIpOBXMMxwK1UCzhWBX4LvKuF4jsWOLtsrwX8HthuZcfXUPccXrrIZH65jmPK9notFN/LgCuBIwf7791gxNdt3xSGZpHJQK7fqFJ/g/L+bODwfscyVD+EkfwC3gn8gWru/XOl7IvAe8v2GlQr/O4Dbga2aGj7udLuHuAdrRQfcDzV/ZnZDa9xrRRjtz5OZAgS3CD8jA+iWgBzJ3ByK8VHtWrtwhLf74FjmhTfTlT/m3+KamQ5t6HtoSXu+4BDWim+8rN9vtvvyKRWia9bH1MYggQ3CD/ft1OtNL6DKgG+rL9x5Ku6IiKilnIPLiIiaikJLiIiaikJLiIiaikJLiIiaikJLiIiaikJLiIiaikJLiIiaun/A3zVKPZRH6VLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_, index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
