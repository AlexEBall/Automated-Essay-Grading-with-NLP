{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>misspelt</th>\n",
       "      <th>correct</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>n_top500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>123</td>\n",
       "      <td>1.37</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>180</td>\n",
       "      <td>1.55</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>169</td>\n",
       "      <td>1.62</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>1.69</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>162</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          domain1_score  misspelt  correct  length  lexical_diversity  \\\n",
       "essay_id                                                                \n",
       "14834               2.0         6      116     123               1.37   \n",
       "14835               3.0        11      169     180               1.55   \n",
       "14836               4.0         4      162     169               1.62   \n",
       "14837               1.0        18      175     199               1.69   \n",
       "14838               3.0         4      158     162               1.74   \n",
       "\n",
       "          n_sentences  nouns  verbs  adverbs  adjectives  n_top500  \n",
       "essay_id                                                            \n",
       "14834               9     29     22        9           9         0  \n",
       "14835               9     43     35       15          13         0  \n",
       "14836               8     41     35       12           9         0  \n",
       "14837              11     36     38        8           4         0  \n",
       "14838              11     38     34       10          13         0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "essays = pd.read_csv('../data/processed/essays_model_2.csv', index_col=0)\n",
    "\n",
    "# Set the essay id as the index of the dataframe\n",
    "essays.set_index('essay_id', inplace=True)\n",
    "\n",
    "essays.head()\n",
    "\n",
    "# binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 1., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.domain1_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryClassification(v):\n",
    "    if v < 3.0:\n",
    "        v = 0.0\n",
    "    elif v >= 3.0:\n",
    "        v = 1.0\n",
    "    return v\n",
    "\n",
    "essays['domain1_score'] = essays['domain1_score'].map(binaryClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.domain1_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = essays.drop(['domain1_score'], axis=1)\n",
    "y = essays['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111111111111111"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred, y_test)\n",
    "accuracy_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_gini = accuracy_score(y_pred, y_test)\n",
    "accuracy_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81314879, 0.79930796, 0.83333333, 0.80836237, 0.81184669])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=2)\n",
    "\n",
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "Accuracy_CV_scores = cross_val_score(dt_entropy, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1) \n",
    "\n",
    "Accuracy_CV_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED=3\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=5)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=SEED)\n",
    "\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.825\n",
      "K Nearest Neighbours : 0.817\n",
      "Classification Tree : 0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
    "\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_pred, y_test) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_leaf=0.016, random_state=4)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=12)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.84\n",
      "OOB accuracy of bc: 0.82\n"
     ]
    }
   ],
   "source": [
    "# split data set into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_leaf=0.016, random_state=4)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, oob_score=True, n_jobs=-1, random_state=13)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Extract the OOB accuracy from bc\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) \n",
    "\n",
    "print('OOB accuracy of bc: {:.2f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestClassifier(criterion='gini', random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 2,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': ['gini', 'entropy'],\n",
       " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# criterion for information gain\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'criterion': criterion,\n",
    "               'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=2, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'criterion': 'entropy',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 82  30]\n",
      " [ 34 214]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.73      0.72       112\n",
      "         1.0       0.88      0.86      0.87       248\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       360\n",
      "   macro avg       0.79      0.80      0.79       360\n",
      "weighted avg       0.82      0.82      0.82       360\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestClassifier(criterion='entropy', random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 75  37]\n",
      " [ 22 226]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.67      0.72       112\n",
      "         1.0       0.86      0.91      0.88       248\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       360\n",
      "   macro avg       0.82      0.79      0.80       360\n",
      "weighted avg       0.83      0.84      0.83       360\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate rf with best params from Random Search\n",
    "rf_random = RandomForestClassifier(criterion='entropy', \n",
    "                            n_estimators=800, \n",
    "                            min_samples_leaf=4, \n",
    "                            min_samples_split=5, \n",
    "                            max_features='sqrt',\n",
    "                            max_depth=None,\n",
    "                            bootstrap=True,\n",
    "                            random_state=2)\n",
    "\n",
    "# Fit rf to the training set    \n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8361111111111111\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf_random.feature_importances_, index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
