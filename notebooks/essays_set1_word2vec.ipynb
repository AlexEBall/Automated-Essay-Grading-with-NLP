{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../utils\")\n",
    "\n",
    "from helpers import adding_stanford_nlp_groups_NER_to_stop_words, removing_stanford_nlp_groups_NER_from_stop_words, punct_space_stop, line_review, lemmatized_sentence_corpus, trigram_bow_generator, explore_topic\n",
    "\n",
    "os.chdir(\"../notebooks\")\n",
    "\n",
    "essays = pd.read_csv('../data/intermediate/prepped_essays_df.csv')\n",
    "\n",
    "# try svm, k-nn, random forrest\n",
    "# remove @Person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = essays[essays['essay_set'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prompt</th>\n",
       "      <th>has_source_material</th>\n",
       "      <th>grade_7</th>\n",
       "      <th>grade_8</th>\n",
       "      <th>grade_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0             4.0             4.0            8.0   \n",
       "1             5.0             4.0            9.0   \n",
       "2             4.0             3.0            7.0   \n",
       "3             5.0             5.0           10.0   \n",
       "4             4.0             4.0            8.0   \n",
       "\n",
       "                                              prompt  has_source_material  \\\n",
       "0  More and more people use computers, but not ev...                    0   \n",
       "1  More and more people use computers, but not ev...                    0   \n",
       "2  More and more people use computers, but not ev...                    0   \n",
       "3  More and more people use computers, but not ev...                    0   \n",
       "4  More and more people use computers, but not ev...                    0   \n",
       "\n",
       "   grade_7  grade_8  grade_10  \n",
       "0        0        1         0  \n",
       "1        0        1         0  \n",
       "2        0        1         0  \n",
       "3        0        1         0  \n",
       "4        0        1         0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essays.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_directory = os.path.join('../data/intermediate')\n",
    "\n",
    "essay_set1_txt_filepath = os.path.join(intermediate_directory, 'essay_set1_text_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from 1,783 essays in the txt file.\n",
      "CPU times: user 57 ms, sys: 4.25 ms, total: 61.2 ms\n",
      "Wall time: 94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "    \n",
    "    essay_count = 0\n",
    "\n",
    "    # create & open a new file in write mode\n",
    "    with codecs.open(essay_set1_txt_filepath, 'w', encoding='utf_8') as essay_set1_txt_file:\n",
    "\n",
    "        # loop through all essays in the dataframe\n",
    "        for row in essays.itertuples():\n",
    "\n",
    "            # write the essay as a line in the new file and escape newline characters in the original essays\n",
    "            essay_set1_txt_file.write(row.essay.replace('\\n', '\\\\n') + '\\n')\n",
    "            essay_count += 1\n",
    "\n",
    "    print('Text from {:,} essays written to the new txt file.'.format(essay_count))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    with codecs.open(essay_set1_txt_filepath, encoding='utf_8') as essay_set1_txt_file:\n",
    "        for essay_count, line in enumerate(essay_set1_txt_file):\n",
    "            pass\n",
    "        \n",
    "    print('Text from {:,} essays in the txt file.'.format(essay_count + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import itertools as it\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_essay = essays.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_essay       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# parsed_essay = nlp(test_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num, sentence in enumerate(parsed_essay.sents):\n",
    "#     print('Sentence {}:'.format(num + 1))\n",
    "#     print(sentence)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num, entity in enumerate(parsed_essay.ents):\n",
    "#     print('Entity {}:'.format(num + 1), entity, '-', entity.label_)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_text = [token.orth_ for token in parsed_essay]\n",
    "# token_pos = [token.pos_ for token in parsed_essay]\n",
    "\n",
    "# pd.DataFrame(zip(token_text, token_pos),\n",
    "#              columns=['token_text', 'part_of_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_lemma = [token.lemma_ for token in parsed_essay]\n",
    "# token_shape = [token.shape_ for token in parsed_essay]\n",
    "\n",
    "# pd.DataFrame(zip(token_text, token_lemma, token_shape),\n",
    "#              columns=['token_text', 'token_lemma', 'token_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_entity_type = [token.ent_type_ for token in parsed_essay]\n",
    "# token_entity_iob = [token.ent_iob_ for token in parsed_essay]\n",
    "\n",
    "# pd.DataFrame(zip(token_text, token_entity_type, token_entity_iob),\n",
    "#              columns=['token_text', 'entity_type', 'inside_outside_begin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_attributes = [(token.orth_,\n",
    "#                      token.prob,\n",
    "#                      token.is_stop,\n",
    "#                      token.is_punct,\n",
    "#                      token.is_space,\n",
    "#                      token.like_num,\n",
    "#                      token.is_oov)\n",
    "#                     for token in parsed_essay]\n",
    "\n",
    "# df = pd.DataFrame(token_attributes,\n",
    "#                   columns=['text',\n",
    "#                            'log_probability',\n",
    "#                            'stop?',\n",
    "#                            'punctuation?',\n",
    "#                            'whitespace?',\n",
    "#                            'number?',\n",
    "#                            'out of vocab.?'])\n",
    "\n",
    "# df.loc[:, 'stop?':'out of vocab.?'] = (df.loc[:, 'stop?':'out of vocab.?']\n",
    "#                                        .applymap(lambda x: u'Yes' if x else u''))\n",
    "                                               \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing_stanford_nlp_groups_NER_from_stop_words(nlp)\n",
    "adding_stanford_nlp_groups_NER_to_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = os.path.join(intermediate_directory, 'unigram_sentences_all_essays.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_set1_all_filepath = os.path.join(intermediate_directory, 'essay_set1_text_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus(essays_set1_all_filepath):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for unigram_sentence in it.islice(unigram_sentences, 19, 42):\n",
    "#     print(' '.join(unigram_sentence))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(unigram_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model_filepath = os.path.join(intermediate_directory, 'bigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.7 ms, sys: 19.4 ms, total: 117 ms\n",
      "Wall time: 525 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = os.path.join(intermediate_directory, 'bigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        \n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            \n",
    "            bigram_sentence = ' '.join(bigram_model[unigram_sentence])\n",
    "            \n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences = LineSentence(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bigram_sentence in it.islice(bigram_sentences, 19, 42):\n",
    "#     print(' '.join(bigram_sentence))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model_filepath = os.path.join(intermediate_directory, 'trigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 10.1 ms, total: 113 ms\n",
      "Wall time: 209 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = os.path.join(intermediate_directory, 'trigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        \n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            \n",
    "            trigram_sentence = ' '.join(trigram_model[bigram_sentence])\n",
    "            \n",
    "            f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for trigram_sentence in it.islice(trigram_sentences, 205, 245):\n",
    "#     print(' '.join(trigram_sentence))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_essays_all_filepath = os.path.join(intermediate_directory, 'trigram_essays_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "#     with codecs.open(trigram_essays_all_filepath, 'w', encoding='utf_8') as f:\n",
    "#         for sentence in lemmatized_sentence_corpus(essays_set1_all_filepath, codecs, nlp):\n",
    "#             f.write(sentence + '\\n')\n",
    "    \n",
    "    \n",
    "    with codecs.open(trigram_essays_all_filepath, 'w', encoding='utf_8') as f:\n",
    "        \n",
    "        for parsed_essay in nlp.pipe(line_review(essays_set1_all_filepath), batch_size=100, n_threads=4):\n",
    "            \n",
    "            # lemmatize the text, removing punctuation and whitespace\n",
    "            unigram_essays = [token.lemma_ for token in parsed_essay\n",
    "                              if not punct_space_stop(token)]\n",
    "            \n",
    "            # apply the first-order and second-order phrase models\n",
    "            bigram_essays = bigram_model[unigram_essays]\n",
    "            trigram_essays = trigram_model[bigram_essays]\n",
    "            \n",
    "            # write the transformed review as a line in the new file\n",
    "            trigram_essays = ' '.join(trigram_essays)\n",
    "            f.write(trigram_essays + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "Dear @CAPS1 times, @CAPS2 you think computers benefit society? Well I think so! There are countless reasons why computers are both resourceful and helpful. Many citizens in our own community of watertown think computers are a great resource for many things while others disagree with this completely. Computers can benefit society because you can learn many new things on the internet, also you can interact with your friends and family, and lastly there are many applications used for business. On both a computer and the internet there are more than @NUM1 million things you can learn. When you are struggling with homework a computer is a great resource. You can quickly open @CAPS3.com and search any topic at any time. For example, if you did not know a conversion it is easily found on the internet. Another thing you can be taught or informed about is news. There are websites such as nytimes.com and cnn.com that give you daily news. I personally use these websites weekly. On the computer you can find vacation sports you want to learn about and go to. When my family was planning our trip to @ORGANIZATION1 in @LOCATION1 we used the computer constantly. In the end, computers can teach you many things. Secondly you can interact with people on the internet in many ways. These include social networking websites, webchat and email. Social networking websites are a great way to connect to family members and friends from the past. Websites that were created for this include: facebook, myspace, and twitter. These free websites let you add friends, send messages, and post pictures. Web chatting is a way to video people. You can personally see someone from acroos the @ORGANIZATION1 from your webcam. Lastly, emailing is a great way to inform people. You can write a visual letter to one of your friends. In conclusion, the computer is one excellent way to interact. Lastly, the computer is used for business. An application called microsoft office is used in countless bussinesses, microsoft office word, powerpoint, excel and @CAPS4. Each of these are used to plan, sell, present, manage, and write about products. Microsoft is something you should download in the near future. Business also use webchatting, as I previously state, for conference calls. A production company can be face to face with a company from china without being in the room with them. This makes it much easier than to fly half way across the @ORGANIZATION1. Finally, computers are used when manufacturing a product in or at a business. Work sites such as @CAPS5 companies use computers to control their machines. I know that the @ORGANIZATION2 factory uses computers in their factory due to the fact that I watche the show unwrapped about them on @CAPS5 @CAPS6. In the end computers are a necessary item in a business. In conslusion, computers have a great affect on people. The can teach people many new and exciting things they did not know. Also, connect humans with each from half way across the @ORGANIZATION1. Lastly, businesses would not run well without a computer. Computers can benefit society because you can learn many new things on the internet. Also you can interact with your friends and family, and there are many applications used for business. If I were an expert I would have nothing to worry about concerning computers. They are a magnificent thing. @CAPS2 you have the same belief and understanding as me?\n",
      "\n",
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "dear time think computer benefit_society think countless reason computer resourceful helpful citizen community watertown think computer great_resource thing disagree completely computer benefit_society learn_new thing internet interact friend family lastly application business computer internet million thing learn struggle homework computer great_resource quickly open @CAPS3.com search_topic time example know conversion easily find internet thing teach inform news website nytimes.com cnn.com daily news personally use website weekly computer find vacation sport want learn family plan_trip computer constantly end computer teach thing secondly interact people internet way include social_networking website webchat email social_networking website great_way connect family_member friend past website create include facebook_myspace_twitter free website let add friend send_message post_picture web chatting way video people personally acroo webcam lastly emailing great_way inform people write visual letter friend conclusion computer excellent way interact lastly computer business application call microsoft office countless bussinesse microsoft office word powerpoint excel plan sell present manage write product Microsoft download near future business use webchatting previously state conference call production company face_face company china room make easy fly half way finally computer manufacture product business work site company use computer control machine know factory use computer factory fact watche unwrap end computer necessary item business conslusion computer great affect people teach people new exciting thing know connect human half way lastly business run computer computer benefit_society learn_new thing internet interact friend family application business expert worry concern computer magnificent thing belief understanding\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original:' + '\\n')\n",
    "\n",
    "for essay in it.islice(line_review(essays_set1_all_filepath), 301, 302):\n",
    "    print(essay)\n",
    "\n",
    "print('----' + '\\n')\n",
    "print('Transformed:' + '\\n')\n",
    "\n",
    "with codecs.open(trigram_essays_all_filepath, encoding='utf_8') as f:\n",
    "    for essay in it.islice(f, 301, 302):\n",
    "        print(essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with Latent Dirichlet Allocation (_LDA_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Topic modeling* is family of techniques that can be used to describe and summarize the documents in a corpus according to a set of latent \"topics\". For this demo, we'll be using [*Latent Dirichlet Allocation*](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) or LDA, a popular approach to topic modeling.\n",
    "\n",
    "In many conventional NLP applications, documents are represented a mixture of the individual tokens (words and phrases) they contain. In other words, a document is represented as a *vector* of token counts. There are two layers in this model &mdash; documents and tokens &mdash; and the size or dimensionality of the document vectors is the number of tokens in the corpus vocabulary. This approach has a number of disadvantages:\n",
    "* Document vectors tend to be large (one dimension for each token $\\Rightarrow$ lots of dimensions)\n",
    "* They also tend to be very sparse. Any given document only contains a small fraction of all tokens in the vocabulary, so most values in the document's token vector are 0.\n",
    "* The dimensions are fully indepedent from each other &mdash; there's no sense of connection between related tokens, such as _knife_ and _fork_.\n",
    "\n",
    "LDA injects a third layer into this conceptual model. Documents are represented as a mixture of a pre-defined number of *topics*, and the *topics* are represented as a mixture of the individual tokens in the vocabulary. The number of topics is a model hyperparameter selected by the practitioner. LDA makes a prior assumption that the (document, topic) and (topic, token) mixtures follow [*Dirichlet*](https://en.wikipedia.org/wiki/Dirichlet_distribution) probability distributions. This assumption encourages documents to consist mostly of a handful of topics, and topics to consist mostly of a modest set of the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating an LDA model is to learn the full vocabulary of the corpus to be modeled. We'll use gensim's [**Dictionary**](https://radimrehurek.com/gensim/corpora/dictionary.html) class for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_dictionary_filepath = os.path.join(intermediate_directory, 'trigram_dict_all.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 ms, sys: 2.44 ms, total: 4.18 ms\n",
      "Wall time: 2.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to learn the dictionary yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    trigram_essays = LineSentence(trigram_essays_all_filepath)\n",
    "\n",
    "    # learn the dictionary by iterating over all of the reviews\n",
    "    trigram_dictionary = Dictionary(trigram_essays)\n",
    "    \n",
    "    # filter tokens that are very rare or too common from\n",
    "    # the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "    trigram_dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "    trigram_dictionary.compactify()\n",
    "\n",
    "    trigram_dictionary.save(trigram_dictionary_filepath)\n",
    "    \n",
    "# load the finished dictionary from disk\n",
    "trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like many NLP techniques, LDA uses a simplifying assumption known as the [*bag-of-words* model](https://en.wikipedia.org/wiki/Bag-of-words_model). In the bag-of-words model, a document is represented by the counts of distinct terms that occur within it. Additional information, such as word order, is discarded. \n",
    "\n",
    "Using the gensim Dictionary we learned to generate a bag-of-words representation for each review. The `trigram_bow_generator` function implements this. We'll save the resulting bag-of-words reviews as a matrix.\n",
    "\n",
    "In the following code, \"bag-of-words\" is abbreviated as `bow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_bow_filepath = os.path.join(intermediate_directory, 'trigram_bow_corpus_all.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trigram_bow_generator(filepath):\n",
    "#     \"\"\"\n",
    "#     generator function to read reviews from a file\n",
    "#     and yield a bag-of-words representation\n",
    "#     \"\"\"\n",
    "    \n",
    "#     for essay in LineSentence(filepath):\n",
    "#         yield trigram_dictionary.doc2bow(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 ms, sys: 4.02 ms, total: 6.03 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to build the bag-of-words corpus yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    # generate bag-of-words representations for\n",
    "    # all reviews and save them as a matrix\n",
    "    MmCorpus.serialize(trigram_bow_filepath, trigram_bow_generator(trigram_essays_all_filepath))\n",
    "    \n",
    "# load the finished bag-of-words corpus from disk\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the bag-of-words corpus, we're finally ready to learn our topic model from the essays. We simply need to pass the bag-of-words matrix and Dictionary from our previous steps to `LdaMulticore` as inputs, along with the number of topics the model should learn. For this demo, we're asking for 5 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_filepath = os.path.join(intermediate_directory, 'lda_model_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I need to expand the number of topics along with the most import/unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 ms, sys: 2.88 ms, total: 7.18 ms\n",
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to train the LDA model yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        \n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        lda = LdaMulticore(trigram_bow_corpus,\n",
    "                           num_topics=5,\n",
    "                           id2word=trigram_dictionary,\n",
    "                           workers=3,\n",
    "                           random_state=50\n",
    "                          )\n",
    "    \n",
    "    lda.save(lda_model_filepath)\n",
    "    \n",
    "# load the finished LDA model from disk\n",
    "lda = LdaMulticore.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our topic model is now trained and ready to use! Since each topic is represented as a mixture of tokens, you can manually inspect which tokens have been grouped together into which topics to try to understand the patterns the model has discovered in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_topic(topic_number, topn=5):\n",
    "#     \"\"\"\n",
    "#     accept a user-supplied topic number and\n",
    "#     print out a formatted list of the top terms\n",
    "#     \"\"\"\n",
    "        \n",
    "#     print('{:20} {}'.format('term', 'frequency') + '\\n')\n",
    "\n",
    "#     for term, frequency in lda.show_topic(topic_number, topn=5):\n",
    "#         print('{:20} {:.3f}'.format(term, round(frequency, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "allow                0.011\n",
      "game                 0.010\n",
      "information          0.010\n",
      "internet             0.009\n",
      "place                0.009\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = {0: 'looking_at_websites_for_info',\n",
    "               1: 'doesnt_have_the_negative_exercise_effect',\n",
    "               2: 'spend_time_looking_on_websites',\n",
    "               3: 'games_and_information',\n",
    "               4: 'bad_if_kids_spend_too_much_time'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names_filepath = os.path.join(intermediate_directory, 'topic_names.pkl')\n",
    "\n",
    "with open(topic_names_filepath, 'wb') as f:\n",
    "    pickle.dump(topic_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_data_filepath = os.path.join(intermediate_directory, 'ldavis_prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.18 ms, sys: 1.41 ms, total: 5.59 ms\n",
      "Wall time: 4.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda, trigram_bow_corpus, trigram_dictionary)\n",
    "\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el81863063857361877425266\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el81863063857361877425266_data = {\"mdsDat\": {\"x\": [0.011901613691480446, -0.004331936542000665, 0.005469401281212863, 0.005076339643040666, -0.018115418073733326], \"y\": [-0.011155523546197033, 0.004269022511376844, -0.000207588730341577, 0.0121124779689177, -0.00501838820375591], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.661989212036133, 26.385953903198242, 19.158803939819336, 14.609124183654785, 13.184133529663086]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [1219.0, 320.0, 559.0, 645.0, 933.0, 986.0, 753.0, 993.0, 917.0, 731.0, 932.0, 1316.0, 697.0, 902.0, 833.0, 384.0, 696.0, 327.0, 529.0, 770.0, 1058.0, 446.0, 527.0, 547.0, 1340.0, 487.0, 603.0, 1222.0, 299.0, 346.0, 10.267879486083984, 12.231898307800293, 8.426789283752441, 9.123835563659668, 10.478593826293945, 9.870430946350098, 22.9926815032959, 10.435089111328125, 13.45598316192627, 6.0275397300720215, 7.587058067321777, 11.823457717895508, 7.9039130210876465, 14.273598670959473, 8.182441711425781, 12.885342597961426, 85.12626647949219, 9.2355318069458, 7.081974506378174, 8.168222427368164, 34.38077163696289, 7.917466640472412, 8.553664207458496, 11.002164840698242, 11.874730110168457, 35.24481964111328, 14.041099548339844, 11.48615550994873, 5.83818244934082, 9.21158218383789, 14.550898551940918, 258.96234130859375, 144.1739959716797, 330.28656005859375, 273.53289794921875, 273.2856140136719, 166.57241821289062, 124.42829132080078, 84.1351318359375, 101.21487426757812, 215.35060119628906, 133.81594848632812, 43.255760192871094, 163.12510681152344, 260.9869384765625, 213.46641540527344, 310.2881164550781, 307.8939208984375, 163.99435424804688, 79.14905548095703, 222.56959533691406, 371.1923828125, 92.20591735839844, 85.6979751586914, 355.94256591796875, 188.1147918701172, 295.3182067871094, 228.12625122070312, 360.9656982421875, 242.4280548095703, 204.33665466308594, 225.63070678710938, 245.85614013671875, 167.62881469726562, 261.4462890625, 240.1465301513672, 237.85691833496094, 178.5574951171875, 194.90594482421875, 249.3294219970703, 187.27268981933594, 181.74343872070312, 186.9274139404297, 174.16552734375, 6.785966396331787, 8.34968376159668, 27.730525970458984, 7.354048728942871, 11.771875381469727, 9.02687931060791, 5.35304069519043, 7.957162857055664, 5.618537425994873, 27.25480079650879, 6.169849395751953, 11.374870300292969, 12.359763145446777, 8.687492370605469, 8.179637908935547, 4.849760055541992, 567.427734375, 20.87959861755371, 13.61424446105957, 13.403327941894531, 6.127827167510986, 20.788923263549805, 7.435829162597656, 5.1862311363220215, 18.96416473388672, 14.127481460571289, 596.38232421875, 6.425391674041748, 33.58725357055664, 5.070747375488281, 39.69709014892578, 65.21610260009766, 78.47108459472656, 295.4376525878906, 24.115467071533203, 366.760498046875, 488.4294738769531, 232.2674102783203, 152.64137268066406, 230.4048309326172, 130.35020446777344, 90.20555114746094, 148.3075714111328, 57.34785461425781, 256.7927551269531, 102.28047180175781, 321.8975524902344, 379.85516357421875, 60.750892639160156, 65.25955200195312, 242.6917266845703, 208.9714813232422, 282.55633544921875, 216.2247772216797, 276.2132263183594, 230.7101593017578, 287.1122131347656, 337.7874755859375, 271.5461120605469, 231.87106323242188, 289.39044189453125, 214.79922485351562, 144.56570434570312, 213.60064697265625, 211.11756896972656, 223.15003967285156, 166.7841796875, 211.04454040527344, 208.80599975585938, 167.60914611816406, 160.008056640625, 163.28976440429688, 45.0135498046875, 15.238934516906738, 8.937102317810059, 4.846516132354736, 6.372957229614258, 5.380285263061523, 6.483577251434326, 10.145888328552246, 3.9380624294281006, 7.9365339279174805, 17.550273895263672, 6.79387903213501, 15.840731620788574, 58.821815490722656, 6.62947416305542, 8.894525527954102, 8.283546447753906, 6.792768478393555, 10.927330017089844, 16.378490447998047, 28.48697853088379, 16.457704544067383, 7.925217628479004, 4.028111457824707, 40.68334197998047, 9.443009376525879, 5.460006237030029, 4.483924865722656, 5.343733310699463, 167.23963928222656, 71.65443420410156, 73.57069396972656, 14.22575855255127, 53.01496887207031, 271.93780517578125, 111.04362487792969, 102.49703216552734, 183.9468536376953, 185.45040893554688, 42.5297737121582, 70.46380615234375, 43.360084533691406, 192.4822998046875, 66.74847412109375, 241.7416229248047, 153.82579040527344, 65.81930541992188, 236.0345001220703, 221.79461669921875, 84.38729858398438, 89.13162994384766, 142.71592712402344, 105.4521484375, 65.963134765625, 66.58710479736328, 173.45016479492188, 97.74444580078125, 102.286376953125, 112.4312515258789, 132.1964111328125, 206.05397033691406, 162.5996856689453, 179.9532470703125, 142.79014587402344, 133.59043884277344, 202.67323303222656, 168.05999755859375, 155.21473693847656, 145.25502014160156, 169.2548065185547, 195.44871520996094, 137.569580078125, 174.76495361328125, 178.66188049316406, 149.1282196044922, 127.33612060546875, 158.25680541992188, 140.67425537109375, 129.521240234375, 5.86420202255249, 12.637218475341797, 5.850931167602539, 6.177511692047119, 4.731901168823242, 3.6508994102478027, 5.538669586181641, 6.768536567687988, 4.207988739013672, 29.326953887939453, 7.592262268066406, 7.113671779632568, 4.355606555938721, 4.013210296630859, 9.68639850616455, 8.873961448669434, 4.524731159210205, 4.112975120544434, 43.05162048339844, 3.202272653579712, 11.217765808105469, 4.854733943939209, 3.149587631225586, 8.17049503326416, 4.2506022453308105, 6.872199535369873, 7.546594142913818, 13.991175651550293, 6.6373066902160645, 4.409990310668945, 30.444501876831055, 16.883214950561523, 25.55809783935547, 15.457406044006348, 71.69911193847656, 122.56443786621094, 97.85619354248047, 21.90737533569336, 77.6693115234375, 198.02255249023438, 162.2117919921875, 149.3365478515625, 34.6715087890625, 85.18183898925781, 182.44595336914062, 138.7790985107422, 66.12078857421875, 192.9966583251953, 144.10118103027344, 46.15032958984375, 210.8138427734375, 85.19287109375, 83.23640441894531, 92.94573974609375, 88.52806854248047, 55.925506591796875, 72.03298950195312, 130.9833221435547, 100.43041229248047, 74.66348266601562, 150.4799041748047, 185.9754638671875, 73.44222259521484, 139.69676208496094, 164.50083923339844, 124.5803451538086, 123.09371948242188, 106.24588775634766, 113.66023254394531, 120.36898803710938, 92.3150634765625, 103.98143768310547, 117.34626770019531, 123.59109497070312, 100.2103500366211, 105.7518310546875, 97.7451171875, 108.78433227539062, 100.174072265625, 5.159533977508545, 121.29146575927734, 4.202375411987305, 24.550756454467773, 8.599759101867676, 4.343998908996582, 3.379401445388794, 13.976685523986816, 4.9053850173950195, 12.937870025634766, 3.923781156539917, 3.6843457221984863, 4.313278675079346, 7.859416961669922, 6.7060394287109375, 3.4226574897766113, 9.572887420654297, 4.869920253753662, 7.7018208503723145, 9.905632019042969, 25.788837432861328, 6.179701805114746, 5.478157043457031, 8.111747741699219, 22.367849349975586, 3.6723074913024902, 4.415108680725098, 3.8805391788482666, 7.113775253295898, 3.9570281505584717, 151.1029052734375, 41.7635383605957, 164.6988983154297, 11.792451858520508, 21.547290802001953, 12.489208221435547, 13.882850646972656, 29.412954330444336, 65.55966186523438, 152.84353637695312, 20.21673583984375, 55.25524139404297, 30.803483963012695, 231.08584594726562, 178.92221069335938, 23.56776237487793, 80.34220886230469, 31.242189407348633, 104.57249450683594, 177.54734802246094, 52.758460998535156, 71.03785705566406, 72.27920532226562, 81.20972442626953, 44.65666961669922, 186.74293518066406, 118.49742126464844, 71.79510498046875, 134.92919921875, 123.3938980102539, 64.7254867553711, 94.50029754638672, 74.06781768798828, 125.49835205078125, 90.10242462158203, 68.99055480957031, 81.81967163085938, 102.1017837524414, 116.49272918701172, 118.97459411621094, 132.6852264404297, 127.48711395263672, 93.35787200927734, 107.20330810546875, 108.30160522460938, 100.95774841308594, 102.1876220703125, 92.98959350585938, 106.5055923461914, 83.99986267089844], \"Term\": [\"spend_time\", \"nature\", \"chat\", \"believe\", \"website\", \"exercise\", \"great\", \"get\", \"game\", \"child\", \"not\", \"kid\", \"easy\", \"place\", \"type\", \"cause\", \"person\", \"email\", \"homework\", \"say\", \"school\", \"spend\", \"have\", \"come\", \"internet\", \"positive_effect\", \"book\", \"look\", \"big\", \"fact\", \"white\", \"portable\", \"disaster\", \"evolve\", \"thay\", \"buissness\", \"buisnesse\", \"enhance\", \"road\", \"professional\", \"researching\", \"click_away\", \"star\", \"government\", \"incredible\", \"criminal\", \"laptop\", \"method\", \"power_point\", \"channel\", \"school_project\", \"teach_hand_eye\", \"natural_disaster\", \"aid\", \"lesson\", \"rely\", \"stock\", \"career\", \"pose\", \"video_chatting\", \"crime\", \"job\", \"benefit\", \"type\", \"society\", \"fun\", \"teach\", \"hand\", \"sport\", \"skill\", \"research\", \"teacher\", \"trip\", \"hand_eye_coordination\", \"student\", \"book\", \"game\", \"lot\", \"make\", \"adult\", \"effect\", \"look\", \"education\", \"meet\", \"information\", \"communicate\", \"work\", \"important\", \"internet\", \"example\", \"easy\", \"allow\", \"place\", \"dear\", \"school\", \"bad\", \"not\", \"technology\", \"play\", \"kid\", \"People\", \"outside\", \"get\", \"say\", \"watch_news\", \"beautiful_nature\", \"reson\", \"frend\", \"get_fat\", \"will_able\", \"produce\", \"fresh\", \"com\", \"past\", \"kick\", \"advice\", \"big_problem\", \"exercis\", \"board_game\", \"conclution\", \"spend_time\", \"suppose\", \"clean\", \"jog\", \"delete\", \"download\", \"post_picture\", \"explore_nature\", \"beneficial_society\", \"ect\", \"kid\", \"plug\", \"story\", \"storm\", \"take_away\", \"school_work\", \"watch\", \"outside\", \"thi\", \"exercise\", \"internet\", \"instead\", \"start\", \"technology\", \"play_game\", \"stuff\", \"parent\", \"dear_local_newspaper\", \"People\", \"try\", \"work\", \"information\", \"business\", \"e_mail\", \"say\", \"let\", \"bad\", \"person\", \"website\", \"play\", \"get\", \"look\", \"lot\", \"allow\", \"school\", \"child\", \"spend\", \"great\", \"important\", \"example\", \"able\", \"game\", \"not\", \"society\", \"job\", \"place\", \"bad_effect\", \"u\", \"alow\", \"tradition\", \"quiz\", \"quality\", \"foreign_place\", \"cheap\", \"relative_live\", \"degree\", \"interact_family\", \"live_faraway\", \"damage\", \"travel\", \"dear_reader\", \"health_issue\", \"schoolwork\", \"teach_skill\", \"usefull\", \"lack_exercise\", \"addicting\", \"shopping\", \"shop_online\", \"throught\", \"meet_new\", \"majority\", \"depressed\", \"eye_hand\", \"new_one\", \"positive_effect\", \"eye\", \"program\", \"physically\", \"negative_effect\", \"place\", \"communication\", \"interact\", \"effect\", \"easy\", \"future\", \"change\", \"better\", \"important\", \"money\", \"exercise\", \"live\", \"study\", \"get\", \"website\", \"site\", \"email\", \"new\", \"well\", \"useful\", \"news\", \"People\", \"cause\", \"opinion\", \"tell\", \"able\", \"school\", \"allow\", \"bad\", \"person\", \"believe\", \"information\", \"not\", \"example\", \"play\", \"work\", \"internet\", \"great\", \"look\", \"kid\", \"game\", \"let\", \"spend_time\", \"lot\", \"student\", \"excersice\", \"abuse\", \"neatly\", \"massive\", \"material\", \"instal\", \"current_event\", \"alternative\", \"Technology\", \"negative\", \"dollar\", \"well_grade\", \"claim\", \"radio\", \"twitter\", \"electricity\", \"challenge\", \"page_essay\", \"letter\", \"twitter_facebook\", \"daily_life\", \"great_resource\", \"spending_time_family\", \"final\", \"chating\", \"shoot\", \"acess\", \"war\", \"point_view\", \"plan_vacation\", \"benifit\", \"famous\", \"page\", \"inform\", \"phone\", \"have\", \"helpful\", \"computor\", \"email\", \"website\", \"great\", \"person\", \"pay\", \"write\", \"not\", \"easy\", \"big\", \"school\", \"say\", \"affect\", \"look\", \"agree\", \"stay\", \"make\", \"hand_eye_coordination\", \"save\", \"fact\", \"student\", \"come\", \"cause\", \"exercise\", \"kid\", \"country\", \"bad\", \"information\", \"type\", \"example\", \"society\", \"allow\", \"place\", \"communicate\", \"outside\", \"work\", \"spend_time\", \"child\", \"get\", \"play\", \"internet\", \"lot\", \"obease\", \"nature\", \"personal_experience\", \"virus\", \"honestly\", \"lake\", \"watch_tv\", \"love_one\", \"burn_calorie\", \"apart\", \"fail_class\", \"customer\", \"seriously\", \"entertaining\", \"exercise_enjoy_nature_interact\", \"o\", \"u\", \"intouch\", \"depression\", \"design\", \"kill\", \"Facebook\", \"waist\", \"guess\", \"park\", \"unfortunately\", \"till\", \"headache\", \"television\", \"status\", \"chat\", \"close\", \"believe\", \"child_adult\", \"addiction\", \"outdoors\", \"neat\", \"waste\", \"love\", \"child\", \"addicting\", \"little\", \"brain\", \"spend_time\", \"game\", \"die\", \"hour\", \"question\", \"homework\", \"get\", \"ask\", \"take\", \"cause\", \"spend\", \"connect\", \"internet\", \"great\", \"parent\", \"not\", \"type\", \"benefit_society\", \"book\", \"away\", \"lot\", \"instead\", \"lastly\", \"come\", \"say\", \"exercise\", \"work\", \"information\", \"look\", \"fun\", \"website\", \"school\", \"place\", \"bad\", \"play\", \"kid\", \"outside\"], \"Total\": [1219.0, 320.0, 559.0, 645.0, 933.0, 986.0, 753.0, 993.0, 917.0, 731.0, 932.0, 1316.0, 697.0, 902.0, 833.0, 384.0, 696.0, 327.0, 529.0, 770.0, 1058.0, 446.0, 527.0, 547.0, 1340.0, 487.0, 603.0, 1222.0, 299.0, 346.0, 15.792341232299805, 20.02052879333496, 14.364311218261719, 16.235963821411133, 18.76709747314453, 18.107694625854492, 42.36445999145508, 19.41990852355957, 25.916519165039062, 11.790185928344727, 14.883260726928711, 23.57627296447754, 15.970941543579102, 28.85794448852539, 16.856252670288086, 26.614870071411133, 175.8930206298828, 19.23160171508789, 14.772480010986328, 17.079206466674805, 71.99267578125, 16.756120681762695, 18.109840393066406, 23.31751251220703, 25.306028366088867, 75.19195556640625, 30.374223709106445, 24.9812068939209, 12.712637901306152, 20.064817428588867, 31.82964324951172, 601.853515625, 345.5473327636719, 833.6937866210938, 694.4881591796875, 697.2546997070312, 413.93389892578125, 303.51123046875, 202.99588012695312, 249.52822875976562, 566.2688598632812, 344.4837646484375, 102.06117248535156, 443.5914306640625, 744.3866577148438, 603.223388671875, 917.278076171875, 945.7867431640625, 466.6087341308594, 204.01004028320312, 671.537109375, 1222.045654296875, 243.75453186035156, 223.703369140625, 1235.656982421875, 588.46875, 1022.7914428710938, 746.6167602539062, 1340.37109375, 821.3198852539062, 697.3107299804688, 796.376220703125, 902.4105224609375, 542.4818725585938, 1058.18896484375, 944.54052734375, 932.0980224609375, 634.529052734375, 761.6058349609375, 1316.854736328125, 774.1650390625, 758.2267456054688, 993.373291015625, 770.7092895507812, 11.392594337463379, 14.873278617858887, 50.61323547363281, 13.978124618530273, 22.504098892211914, 17.690176010131836, 10.666886329650879, 16.04543113708496, 11.343234062194824, 55.816566467285156, 12.642704963684082, 23.707563400268555, 25.827678680419922, 18.19956398010254, 17.390853881835938, 10.340763092041016, 1219.1279296875, 44.891754150390625, 29.424053192138672, 29.04810333251953, 13.304224014282227, 45.357635498046875, 16.227922439575195, 11.377718925476074, 41.68380355834961, 31.09687042236328, 1316.854736328125, 14.349767684936523, 75.12104797363281, 11.395452499389648, 90.41067504882812, 153.3226776123047, 189.11441040039062, 758.2267456054688, 55.74917984008789, 986.6192016601562, 1340.37109375, 610.72265625, 404.2331237792969, 634.529052734375, 342.05035400390625, 229.51853942871094, 403.68817138671875, 143.77029418945312, 774.1650390625, 277.5085144042969, 1022.7914428710938, 1235.656982421875, 155.7734375, 168.98202514648438, 770.7092895507812, 656.0894775390625, 944.54052734375, 696.9740600585938, 933.4336547851562, 761.6058349609375, 993.373291015625, 1222.045654296875, 945.7867431640625, 796.376220703125, 1058.18896484375, 731.0887451171875, 446.31109619140625, 753.4122314453125, 746.6167602539062, 821.3198852539062, 580.1541748046875, 917.278076171875, 932.0980224609375, 694.4881591796875, 601.853515625, 902.4105224609375, 90.54676055908203, 32.99049377441406, 20.663280487060547, 11.237494468688965, 15.051142692565918, 13.053936004638672, 15.981488227844238, 25.269981384277344, 10.21831226348877, 20.70289421081543, 46.12678146362305, 18.03127670288086, 42.425323486328125, 159.33554077148438, 17.98847007751465, 24.15102767944336, 22.624391555786133, 18.616573333740234, 30.28177833557129, 45.40964889526367, 79.45408630371094, 47.032325744628906, 22.68263053894043, 11.592601776123047, 117.1304702758789, 27.192462921142578, 15.789117813110352, 12.98609733581543, 15.494866371154785, 487.1652526855469, 215.85516357421875, 221.7952117919922, 41.68686294555664, 163.0878448486328, 902.4105224609375, 366.7669372558594, 344.3785095214844, 671.537109375, 697.3107299804688, 138.68807983398438, 242.49566650390625, 141.6893310546875, 746.6167602539062, 231.1064453125, 986.6192016601562, 601.7388916015625, 228.85365295410156, 993.373291015625, 933.4336547851562, 305.5534362792969, 327.9817199707031, 579.6295166015625, 413.3078918457031, 235.14981079101562, 238.74627685546875, 774.1650390625, 384.4671936035156, 409.94195556640625, 467.48565673828125, 580.1541748046875, 1058.18896484375, 796.376220703125, 944.54052734375, 696.9740600585938, 645.377197265625, 1235.656982421875, 932.0980224609375, 821.3198852539062, 761.6058349609375, 1022.7914428710938, 1340.37109375, 753.4122314453125, 1222.045654296875, 1316.854736328125, 917.278076171875, 656.0894775390625, 1219.1279296875, 945.7867431640625, 744.3866577148438, 14.30420970916748, 35.17451858520508, 16.695602416992188, 17.785934448242188, 13.738091468811035, 10.729272842407227, 16.482532501220703, 20.23786163330078, 12.742849349975586, 88.85774993896484, 23.523706436157227, 22.097808837890625, 13.620827674865723, 12.590902328491211, 31.02976417541504, 28.642179489135742, 14.634137153625488, 13.536039352416992, 142.03585815429688, 10.616424560546875, 37.28852081298828, 16.211925506591797, 10.535884857177734, 27.35113525390625, 14.269683837890625, 23.296531677246094, 25.595674514770508, 47.6473274230957, 22.806772232055664, 15.199280738830566, 105.49895477294922, 59.8482780456543, 93.02627563476562, 55.55202865600586, 285.1045837402344, 527.8182983398438, 417.60394287109375, 82.11888885498047, 327.9817199707031, 933.4336547851562, 753.4122314453125, 696.9740600585938, 138.58111572265625, 387.16864013671875, 932.0980224609375, 697.3107299804688, 299.17303466796875, 1058.18896484375, 770.7092895507812, 199.806396484375, 1222.045654296875, 417.4425048828125, 406.0069885253906, 466.6087341308594, 443.5914306640625, 254.00308227539062, 346.4122009277344, 744.3866577148438, 547.1842041015625, 384.4671936035156, 986.6192016601562, 1316.854736328125, 379.2893371582031, 944.54052734375, 1235.656982421875, 833.6937866210938, 821.3198852539062, 694.4881591796875, 796.376220703125, 902.4105224609375, 588.46875, 758.2267456054688, 1022.7914428710938, 1219.1279296875, 731.0887451171875, 993.373291015625, 761.6058349609375, 1340.37109375, 945.7867431640625, 13.517803192138672, 320.31243896484375, 11.61747932434082, 68.26703643798828, 24.384319305419922, 12.508543968200684, 10.588212013244629, 43.833011627197266, 15.430408477783203, 42.28306579589844, 12.922850608825684, 12.53366470336914, 14.706226348876953, 26.9423828125, 23.0596923828125, 11.790124893188477, 32.99049377441406, 16.84490966796875, 26.660045623779297, 34.35701370239258, 90.17214965820312, 21.660005569458008, 19.29122543334961, 28.597309112548828, 78.8879623413086, 12.954513549804688, 15.588908195495605, 13.889812469482422, 26.105369567871094, 14.546613693237305, 559.6427001953125, 154.2989959716797, 645.377197265625, 43.49517822265625, 81.87399291992188, 46.27964401245117, 51.91728973388672, 116.50827026367188, 281.3143005371094, 731.0887451171875, 79.45408630371094, 240.9903564453125, 126.81938171386719, 1219.1279296875, 917.278076171875, 94.699951171875, 381.66632080078125, 131.82586669921875, 529.0054321289062, 993.373291015625, 258.5953369140625, 374.133056640625, 384.4671936035156, 446.31109619140625, 216.65478515625, 1340.37109375, 753.4122314453125, 403.68817138671875, 932.0980224609375, 833.6937866210938, 359.406982421875, 603.223388671875, 435.4186706542969, 945.7867431640625, 610.72265625, 413.5264892578125, 547.1842041015625, 770.7092895507812, 986.6192016601562, 1022.7914428710938, 1235.656982421875, 1222.045654296875, 697.2546997070312, 933.4336547851562, 1058.18896484375, 902.4105224609375, 944.54052734375, 761.6058349609375, 1316.854736328125, 758.2267456054688], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8913999795913696, 0.829200029373169, 0.7886000275611877, 0.7455999851226807, 0.7391999959945679, 0.7150999903678894, 0.7107999920845032, 0.7008000016212463, 0.6664999723434448, 0.6510000228881836, 0.6481000185012817, 0.6317999958992004, 0.6184999942779541, 0.6179999709129333, 0.5992000102996826, 0.5965999960899353, 0.5961999893188477, 0.5884000062942505, 0.5867000222206116, 0.5842999815940857, 0.5828999876976013, 0.5722000002861023, 0.5717999935150146, 0.5708000063896179, 0.5652999877929688, 0.5641999840736389, 0.5503000020980835, 0.5450000166893005, 0.5437999963760376, 0.54339998960495, 0.5392000079154968, 0.47859999537467957, 0.44780001044273376, 0.3959999978542328, 0.3901999890804291, 0.38530001044273376, 0.4117000102996826, 0.4302000105381012, 0.44119998812675476, 0.4196000099182129, 0.35510000586509705, 0.37630000710487366, 0.4634999930858612, 0.3215000033378601, 0.27379998564720154, 0.2831000089645386, 0.23800000548362732, 0.1996999979019165, 0.27630001306533813, 0.3750999867916107, 0.2176000028848648, 0.13040000200271606, 0.3497999906539917, 0.36239999532699585, 0.07729999721050262, 0.18150000274181366, 0.07970000058412552, 0.1362999975681305, 0.009999999776482582, 0.10170000046491623, 0.09449999779462814, 0.06080000102519989, 0.02160000056028366, 0.14749999344348907, -0.07620000094175339, -0.04749999940395355, -0.043800000101327896, 0.05400000140070915, -0.04100000113248825, -0.3422999978065491, -0.09730000048875809, -0.10649999976158142, -0.34850001335144043, -0.16539999842643738, 0.8141999840736389, 0.7549999952316284, 0.7307000160217285, 0.6901000142097473, 0.6844000220298767, 0.659500002861023, 0.6428999900817871, 0.6309999823570251, 0.629800021648407, 0.6154999732971191, 0.6148999929428101, 0.5979999899864197, 0.595300018787384, 0.5928000211715698, 0.578000009059906, 0.5752000212669373, 0.5676000118255615, 0.5669000148773193, 0.5616000294685364, 0.558899998664856, 0.5570999979972839, 0.5522000193595886, 0.5519000291824341, 0.5467000007629395, 0.5447999835014343, 0.54339998960495, 0.5401999950408936, 0.5289000272750854, 0.527400016784668, 0.522599995136261, 0.5092999935150146, 0.47749999165534973, 0.4526999890804291, 0.3898000121116638, 0.4943000078201294, 0.34279999136924744, 0.32280001044273376, 0.36559998989105225, 0.35839998722076416, 0.31929999589920044, 0.3675999939441681, 0.3984000086784363, 0.3310000002384186, 0.4133000075817108, 0.2287999987602234, 0.334199994802475, 0.17630000412464142, 0.15279999375343323, 0.39070001244544983, 0.38089999556541443, 0.17679999768733978, 0.1881999969482422, 0.12549999356269836, 0.16189999878406525, 0.11460000276565552, 0.13809999823570251, 0.09109999984502792, 0.04650000110268593, 0.08449999988079071, 0.09839999675750732, 0.03579999879002571, 0.10750000178813934, 0.20509999990463257, 0.07180000096559525, 0.06920000165700912, 0.02930000051856041, 0.08569999784231186, -0.13699999451637268, -0.16369999945163727, -0.08919999748468399, 0.007499999832361937, -0.37720000743865967, 0.953499972820282, 0.8799999952316284, 0.814300000667572, 0.8113999962806702, 0.7929999828338623, 0.7660999894142151, 0.7501999735832214, 0.7398999929428101, 0.6988999843597412, 0.6935999989509583, 0.6861000061035156, 0.6762999892234802, 0.6672000288963318, 0.6559000015258789, 0.65420001745224, 0.6535000205039978, 0.6477000117301941, 0.6442000269889832, 0.6330999732017517, 0.6327000260353088, 0.6266999840736389, 0.602400004863739, 0.6008999943733215, 0.595300018787384, 0.5949000120162964, 0.5946999788284302, 0.590499997138977, 0.5889999866485596, 0.5878000259399414, 0.5831999778747559, 0.5497000217437744, 0.5489000082015991, 0.5773000121116638, 0.5286999940872192, 0.4528999924659729, 0.4575999975204468, 0.4404999911785126, 0.35749998688697815, 0.328000009059906, 0.47040000557899475, 0.4165000021457672, 0.4683000147342682, 0.2969000041484833, 0.4104999899864197, 0.2460000067949295, 0.28839999437332153, 0.40619999170303345, 0.21529999375343323, 0.21529999375343323, 0.36570000648498535, 0.3495999872684479, 0.250900000333786, 0.2865000069141388, 0.3813000023365021, 0.37549999356269836, 0.15649999678134918, 0.28290000557899475, 0.26420000195503235, 0.227400004863739, 0.17339999973773956, 0.016200000420212746, 0.06360000371932983, -0.00559999980032444, 0.06700000166893005, 0.07739999890327454, -0.15539999306201935, -0.06069999933242798, -0.013700000010430813, -0.0044999998062849045, -0.14650000631809235, -0.27300000190734863, -0.04809999838471413, -0.2924000024795532, -0.3450999855995178, -0.16419999301433563, 0.012900000438094139, -0.38929998874664307, -0.2531999945640564, -0.09629999846220016, 1.0318000316619873, 0.8998000025749207, 0.875, 0.8659999966621399, 0.857699990272522, 0.8454999923706055, 0.8330000042915344, 0.8282999992370605, 0.815500020980835, 0.8149999976158142, 0.7925999760627747, 0.7900999784469604, 0.7833999991416931, 0.7800999879837036, 0.7592999935150146, 0.751800000667572, 0.7497000098228455, 0.7322999835014343, 0.7297999858856201, 0.7250000238418579, 0.7222999930381775, 0.7177000045776367, 0.7160000205039978, 0.7153000235557556, 0.7124000191688538, 0.7027000188827515, 0.7021999955177307, 0.6980999708175659, 0.6891999840736389, 0.6861000061035156, 0.6807000041007996, 0.6579999923706055, 0.631600022315979, 0.6442999839782715, 0.5430999994277954, 0.4634000062942505, 0.4724999964237213, 0.6021999716758728, 0.4830000102519989, 0.37299999594688416, 0.387800008058548, 0.382999986410141, 0.5379999876022339, 0.40950000286102295, 0.29249998927116394, 0.3091999888420105, 0.414000004529953, 0.22190000116825104, 0.2467000037431717, 0.45809999108314514, 0.16619999706745148, 0.3343000113964081, 0.33880001306533813, 0.3100000023841858, 0.31189998984336853, 0.41019999980926514, 0.3529999852180481, 0.1860000044107437, 0.2282000035047531, 0.2847000062465668, 0.04309999942779541, -0.033900000154972076, 0.2816999852657318, 0.012299999594688416, -0.09290000051259995, 0.022600000724196434, 0.025599999353289604, 0.04610000178217888, -0.02329999953508377, -0.09099999815225601, 0.07119999825954437, -0.06319999694824219, -0.24160000681877136, -0.3653999865055084, -0.06369999796152115, -0.3165000081062317, -0.12950000166893005, -0.5878000259399414, -0.3215999901294708, 1.062999963760376, 1.0550999641418457, 1.0092999935150146, 1.003499984741211, 0.984000027179718, 0.968500018119812, 0.8841000199317932, 0.8831999897956848, 0.8801000118255615, 0.8418999910354614, 0.8342000246047974, 0.801800012588501, 0.7996000051498413, 0.7942000031471252, 0.791100025177002, 0.7893000245094299, 0.7889000177383423, 0.7851999998092651, 0.7843999862670898, 0.7825000286102295, 0.774399995803833, 0.7720000147819519, 0.767300009727478, 0.7662000060081482, 0.7657999992370605, 0.765500009059906, 0.7645999789237976, 0.7509999871253967, 0.7260000109672546, 0.7243000268936157, 0.7167999744415283, 0.7192999720573425, 0.6603999733924866, 0.7210000157356262, 0.6912000179290771, 0.7163000106811523, 0.7071999907493591, 0.6496000289916992, 0.569599986076355, 0.460999995470047, 0.6575000286102295, 0.5533999800682068, 0.6110000014305115, 0.36309999227523804, 0.39169999957084656, 0.6352999806404114, 0.46790000796318054, 0.5863999724388123, 0.4050000011920929, 0.3043000102043152, 0.436599999666214, 0.36480000615119934, 0.3547999858856201, 0.3222000002861023, 0.44690001010894775, 0.0551999993622303, 0.17640000581741333, 0.2992999851703644, 0.09350000321865082, 0.11569999903440475, 0.31189998984336853, 0.17249999940395355, 0.2547999918460846, 0.006399999838322401, 0.11249999701976776, 0.2354000061750412, 0.125900000333786, 0.004800000227987766, -0.11029999703168869, -0.12520000338554382, -0.20520000159740448, -0.23409999907016754, 0.015399999916553497, -0.1379999965429306, -0.2531999945640564, -0.16419999301433563, -0.19769999384880066, -0.07680000364780426, -0.4885999858379364, -0.17399999499320984], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.20989990234375, -8.034899711608887, -8.407500267028809, -8.32800006866455, -8.189599990844727, -8.24940013885498, -7.403800010681152, -8.19379997253418, -7.939499855041504, -8.742600440979004, -8.512499809265137, -8.068900108337402, -8.471599578857422, -7.880499839782715, -8.43690013885498, -7.982800006866455, -6.094799995422363, -8.315899848937988, -8.581399917602539, -8.438699722290039, -7.001399993896484, -8.469900131225586, -8.392600059509277, -8.140800476074219, -8.064499855041504, -6.976600170135498, -7.896900177001953, -8.097800254821777, -8.774499893188477, -8.318499565124512, -7.861299991607666, -4.9822998046875, -5.56790018081665, -4.738999843597412, -4.927499771118164, -4.928400039672852, -5.423500061035156, -5.715199947357178, -6.106500148773193, -5.9217000007629395, -5.1666998863220215, -5.642499923706055, -6.7718000411987305, -5.444399833679199, -4.9745001792907715, -5.17549991607666, -4.801400184631348, -4.809199810028076, -5.4390997886657715, -6.167600154876709, -5.133699893951416, -4.622200012207031, -6.014900207519531, -6.088099956512451, -4.6641998291015625, -5.3018999099731445, -4.850900173187256, -5.109000205993652, -4.650199890136719, -5.0482001304626465, -5.219200134277344, -5.119999885559082, -5.034200191497803, -5.417200088500977, -4.972700119018555, -5.057700157165527, -5.067299842834473, -5.354000091552734, -5.26639986038208, -5.020199775695801, -5.306399822235107, -5.336299896240234, -5.308199882507324, -5.378900051116943, -8.613699913024902, -8.406299591064453, -7.205999851226807, -8.533300399780273, -8.062800407409668, -8.328300476074219, -8.850899696350098, -8.454500198364258, -8.802499771118164, -7.223299980163574, -8.708900451660156, -8.097100257873535, -8.014100074768066, -8.366600036621094, -8.426899909973145, -8.949600219726562, -4.187399864196777, -7.489799976348877, -7.917399883270264, -7.933000087738037, -8.715700149536133, -7.494100093841553, -8.522199630737305, -8.882499694824219, -7.585999965667725, -7.88040018081665, -4.137599945068359, -8.668299674987793, -7.014400005340576, -8.904999732971191, -6.847300052642822, -6.350800037384033, -6.165800094604492, -4.840099811553955, -7.345699787139893, -4.623799800872803, -4.337299823760986, -5.080599784851074, -5.500400066375732, -5.088699817657471, -5.658299922943115, -6.026400089263916, -5.529200077056885, -6.479400157928467, -4.980299949645996, -5.9008002281188965, -4.754300117492676, -4.588699817657471, -6.4217000007629395, -6.350200176239014, -5.0366997718811035, -5.186299800872803, -4.884699821472168, -5.152200222015381, -4.907400131225586, -5.087399959564209, -4.86870002746582, -4.706099987030029, -4.9243998527526855, -5.082300186157227, -4.860799789428711, -5.15880012512207, -5.554800033569336, -5.164400100708008, -5.17609977722168, -5.120699882507324, -5.411799907684326, -5.176499843597412, -5.187099933624268, -5.406899929046631, -5.4532999992370605, -5.433000087738037, -6.401500225067139, -7.484600067138672, -8.018199920654297, -8.630200386047363, -8.356399536132812, -8.525699615478516, -8.339200019836426, -7.89139986038208, -8.837800025939941, -8.13700008392334, -7.343400001525879, -8.292400360107422, -7.445899963378906, -6.133900165557861, -8.316900253295898, -8.02299976348877, -8.094200134277344, -8.29259967803955, -7.817200183868408, -7.412499904632568, -6.859000205993652, -7.407700061798096, -8.138400077819824, -8.815199851989746, -6.502600193023682, -7.963200092315674, -8.51099967956543, -8.708000183105469, -8.532500267028809, -5.089000225067139, -5.936600208282471, -5.910200119018555, -7.553400039672852, -6.2378997802734375, -4.60290002822876, -5.498499870300293, -5.57859992980957, -4.993800163269043, -4.9857001304626465, -6.4583001136779785, -5.953400135040283, -6.438899993896484, -4.948500156402588, -6.007500171661377, -4.720600128173828, -5.172599792480469, -6.021500110626221, -4.744500160217285, -4.806700229644775, -5.7729997634887695, -5.718299865722656, -5.247600078582764, -5.55019998550415, -6.019400119781494, -6.009900093078613, -5.052599906921387, -5.626100063323975, -5.580699920654297, -5.486100196838379, -5.32420015335083, -4.880300045013428, -5.117199897766113, -5.0157999992370605, -5.247099876403809, -5.313700199127197, -4.896900177001953, -5.084099769592285, -5.163599967956543, -5.230000019073486, -5.077099800109863, -4.933199882507324, -5.284299850463867, -5.045000076293945, -5.0229997634887695, -5.203700065612793, -5.361599922180176, -5.144199848175049, -5.26200008392334, -5.344600200653076, -8.168499946594238, -7.400700092315674, -8.170700073242188, -8.116399765014648, -8.383000373840332, -8.642399787902832, -8.225600242614746, -8.025099754333496, -8.500399589538574, -6.558800220489502, -7.910200119018555, -7.975299835205078, -8.465900421142578, -8.547800064086914, -7.666600227355957, -7.754199981689453, -8.427800178527832, -8.523200035095215, -6.174900054931641, -8.773500442504883, -7.519800186157227, -8.357399940490723, -8.79010009765625, -7.8368000984191895, -8.490300178527832, -8.009900093078613, -7.916200160980225, -7.298900127410889, -8.044599533081055, -8.453499794006348, -6.521399974822998, -7.111000061035156, -6.696400165557861, -7.1992998123168945, -5.664899826049805, -5.128699779510498, -5.353799819946289, -6.850500106811523, -5.58489990234375, -4.64900016784668, -4.848400115966797, -4.931099891662598, -6.39139986038208, -5.492599964141846, -4.730899810791016, -5.004499912261963, -5.7459001541137695, -4.674699783325195, -4.966800212860107, -6.105400085449219, -4.586400032043457, -5.492400169372559, -5.515699863433838, -5.405300140380859, -5.453999996185303, -5.913300037384033, -5.660200119018555, -5.062300205230713, -5.327899932861328, -5.6244001388549805, -4.923500061035156, -4.711699962615967, -5.6407999992370605, -4.997900009155273, -4.834400177001953, -5.112400054931641, -5.1244001388549805, -5.271599769592285, -5.204100131988525, -5.1468000411987305, -5.412099838256836, -5.293099880218506, -5.1722002029418945, -5.1203999519348145, -5.330100059509277, -5.276199817657471, -5.355000019073486, -5.248000144958496, -5.330399990081787, -8.193900108337402, -5.036499977111816, -8.399100303649902, -6.633999824523926, -7.683000087738037, -8.365900039672852, -8.616999626159668, -7.197299957275391, -8.244400024414062, -7.274600028991699, -8.467700004577637, -8.530599594116211, -8.373000144958496, -7.7729997634887695, -7.931700229644775, -8.604299545288086, -7.575799942016602, -8.25160026550293, -7.793300151824951, -7.541600227355957, -6.584799766540527, -8.013400077819824, -8.133899688720703, -7.741399765014648, -6.727099895477295, -8.533900260925293, -8.349699974060059, -8.478699684143066, -7.872700214385986, -8.459199905395508, -4.816800117492676, -6.102700233459473, -4.730599880218506, -7.367300033569336, -6.764500141143799, -7.309800148010254, -7.204100131988525, -6.4532999992370605, -5.651800155639648, -4.805300235748291, -6.828199863433838, -5.822700023651123, -6.407100200653076, -4.391900062561035, -4.647799968719482, -6.674799919128418, -5.448400020599365, -6.392899990081787, -5.184800148010254, -4.6554999351501465, -5.86899995803833, -5.571499824523926, -5.554200172424316, -5.437699794769287, -6.035699844360352, -4.605000019073486, -5.059800148010254, -5.5609002113342285, -4.929999828338623, -5.0192999839782715, -5.664599895477295, -5.286099910736084, -5.529699802398682, -5.002399921417236, -5.333799839019775, -5.6006999015808105, -5.430200099945068, -5.208700180053711, -5.076900005340576, -5.055799961090088, -4.946700096130371, -4.986700057983398, -5.298299789428711, -5.159999847412109, -5.149799823760986, -5.21999979019165, -5.207900047302246, -5.302199840545654, -5.166500091552734, -5.403900146484375]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5], \"Freq\": [0.23084020614624023, 0.09233608096837997, 0.2770082354545593, 0.04616804048418999, 0.2770082354545593, 0.24155056476593018, 0.33197057247161865, 0.22346656024456024, 0.1162542775273323, 0.08525314182043076, 0.2354261577129364, 0.31390154361724854, 0.07847538590431213, 0.31390154361724854, 0.07847538590431213, 0.2895781993865967, 0.28785452246665955, 0.2275257259607315, 0.11548653990030289, 0.0792892649769783, 0.08528901636600494, 0.2842967212200165, 0.11371868848800659, 0.36958572268486023, 0.1705780327320099, 0.23441460728645325, 0.35162192583084106, 0.07813820242881775, 0.312552809715271, 0.07813820242881775, 0.10068707913160324, 0.1887882798910141, 0.35240477323532104, 0.08810119330883026, 0.2517177164554596, 0.14656668901443481, 0.1954222470521927, 0.31756114959716797, 0.07328334450721741, 0.2687056064605713, 0.3872358500957489, 0.27939802408218384, 0.1519533097743988, 0.13234642148017883, 0.04901719465851784, 0.1265418976545334, 0.46398696303367615, 0.1265418976545334, 0.16872252523899078, 0.08436126261949539, 0.21520832180976868, 0.2502422332763672, 0.17516957223415375, 0.23022286593914032, 0.1251211166381836, 0.2611137926578522, 0.2706959545612335, 0.1796654611825943, 0.20362085103988647, 0.08384387940168381, 0.4717484414577484, 0.12865866720676422, 0.1715448796749115, 0.12865866720676422, 0.12865866720676422, 0.28378546237945557, 0.2913196086883545, 0.20467713475227356, 0.14314842224121094, 0.0791083425283432, 0.24197512865066528, 0.14518508315086365, 0.43555524945259094, 0.09679005295038223, 0.09679005295038223, 0.14823700487613678, 0.14823700487613678, 0.19764934480190277, 0.34588634967803955, 0.19764934480190277, 0.16555090248584747, 0.2601514160633087, 0.14190077781677246, 0.11825065314769745, 0.30745169520378113, 0.21268752217292786, 0.2629591226577759, 0.13534660637378693, 0.18561819195747375, 0.20495343208312988, 0.18602785468101501, 0.3123430609703064, 0.17684128880500793, 0.15387488901615143, 0.16995136439800262, 0.2540917992591858, 0.29961657524108887, 0.19056884944438934, 0.1482202112674713, 0.10798901319503784, 0.14357222616672516, 0.13252821564674377, 0.49698078632354736, 0.13252821564674377, 0.08835213631391525, 0.06723467260599136, 0.5378773808479309, 0.13446934521198273, 0.13446934521198273, 0.13446934521198273, 0.22002637386322021, 0.22622428834438324, 0.20763051509857178, 0.09141940623521805, 0.2556644380092621, 0.16793093085289001, 0.4558125436306, 0.09596053510904312, 0.14394080638885498, 0.14394080638885498, 0.4167301654815674, 0.225728839635849, 0.13891005516052246, 0.09839462488889694, 0.1244402602314949, 0.23371833562850952, 0.28658318519592285, 0.19754762947559357, 0.10294736176729202, 0.180853471159935, 0.2559266984462738, 0.21801163256168365, 0.11374520510435104, 0.2843630015850067, 0.12322396785020828, 0.21173083782196045, 0.19055774807929993, 0.303480863571167, 0.1693846732378006, 0.11998080462217331, 0.21392302215099335, 0.1938677430152893, 0.1938677430152893, 0.22060811519622803, 0.18049755692481995, 0.1548726111650467, 0.4646178185939789, 0.11615445464849472, 0.1548726111650467, 0.07743630558252335, 0.1725044697523117, 0.46001192927360535, 0.1725044697523117, 0.05750149115920067, 0.11500298231840134, 0.35310301184654236, 0.1657760590314865, 0.182353675365448, 0.14090965688228607, 0.15748725831508636, 0.275983065366745, 0.2523273527622223, 0.15770460665225983, 0.07096707075834274, 0.2444421350955963, 0.5429078936576843, 0.2596516013145447, 0.07081407308578491, 0.04720938205718994, 0.07081407308578491, 0.552251398563385, 0.11045028269290924, 0.22090056538581848, 0.05522514134645462, 0.05522514134645462, 0.1296142041683197, 0.1296142041683197, 0.19442129135131836, 0.2592284083366394, 0.32403549551963806, 0.2632027566432953, 0.3915943503379822, 0.1283915936946869, 0.09629369527101517, 0.12197201699018478, 0.44033101201057434, 0.20015046000480652, 0.20015046000480652, 0.040030092000961304, 0.08006018400192261, 0.13005010783672333, 0.234090194106102, 0.25489822030067444, 0.1950751692056656, 0.18727216124534607, 0.27333351969718933, 0.13666675984859467, 0.2050001323223114, 0.3416668772697449, 0.06833337992429733, 0.23917953670024872, 0.18144653737545013, 0.28866496682167053, 0.13196112215518951, 0.15670382976531982, 0.4684058427810669, 0.23420292139053345, 0.11710146069526672, 0.05855073034763336, 0.11710146069526672, 0.2215699404478073, 0.18940655887126923, 0.16260375082492828, 0.1554563343524933, 0.26981499791145325, 0.3503931760787964, 0.14015726745128632, 0.14015726745128632, 0.28031453490257263, 0.07007863372564316, 0.19786322116851807, 0.1582905799150467, 0.39572644233703613, 0.1582905799150467, 0.07914528995752335, 0.2065412700176239, 0.2940819561481476, 0.15319617092609406, 0.13678230345249176, 0.20927691459655762, 0.18392843008041382, 0.3218747675418854, 0.11495526880025864, 0.11495526880025864, 0.2758926451206207, 0.14683395624160767, 0.2202509343624115, 0.14683395624160767, 0.29366791248321533, 0.14683395624160767, 0.0679716020822525, 0.4758011996746063, 0.135943204164505, 0.10195740312337875, 0.23790059983730316, 0.5089862942695618, 0.16966210305690765, 0.12724657356739044, 0.12724657356739044, 0.12724657356739044, 0.20738954842090607, 0.18146586418151855, 0.22035139799118042, 0.12313754856586456, 0.27219879627227783, 0.08815827965736389, 0.5289496779441833, 0.17631655931472778, 0.17631655931472778, 0.08815827965736389, 0.20285673439502716, 0.2540278136730194, 0.21016688644886017, 0.1827538162469864, 0.14985813200473785, 0.3194732069969177, 0.24470289051532745, 0.18862514197826385, 0.1563379466533661, 0.09006425738334656, 0.29719144105911255, 0.20176300406455994, 0.3026445209980011, 0.10906108468770981, 0.08997539430856705, 0.26790425181388855, 0.28008171916007996, 0.12177466601133347, 0.26790425181388855, 0.06088733300566673, 0.09670466184616089, 0.48352330923080444, 0.19340932369232178, 0.09670466184616089, 0.09670466184616089, 0.25847572088241577, 0.1800098717212677, 0.25847572088241577, 0.09692839533090591, 0.20770369470119476, 0.3242906928062439, 0.21355728805065155, 0.2161937952041626, 0.19246520102024078, 0.05273019149899483, 0.47125881910324097, 0.18850353360176086, 0.09425176680088043, 0.15708626806735992, 0.12566901743412018, 0.48844873905181885, 0.18786489963531494, 0.11271893978118896, 0.15029191970825195, 0.07514595985412598, 0.18201085925102234, 0.24268116056919098, 0.18201085925102234, 0.3640217185020447, 0.060670290142297745, 0.15957024693489075, 0.15957024693489075, 0.3191404938697815, 0.07978512346744537, 0.3191404938697815, 0.21454323828220367, 0.18772533535957336, 0.13408952951431274, 0.2949969470500946, 0.16090743243694305, 0.1414249688386917, 0.2592791020870209, 0.37713325023651123, 0.16499578952789307, 0.047141656279563904, 0.3096877634525299, 0.26729002594947815, 0.20277175307273865, 0.1308799535036087, 0.09032560139894485, 0.16693295538425446, 0.3964657783508301, 0.20171065628528595, 0.13911078870296478, 0.09042201936244965, 0.1667734980583191, 0.1667734980583191, 0.3891381621360779, 0.1111823320388794, 0.1667734980583191, 0.193209707736969, 0.193209707736969, 0.386419415473938, 0.0966048538684845, 0.0966048538684845, 0.07516409456729889, 0.4509845972061157, 0.07516409456729889, 0.22549229860305786, 0.07516409456729889, 0.06333476305007935, 0.2533390522003174, 0.31667381525039673, 0.1266695261001587, 0.2533390522003174, 0.11252793669700623, 0.1500372588634491, 0.3000745177268982, 0.1500372588634491, 0.3000745177268982, 0.26195526123046875, 0.1746368259191513, 0.1746368259191513, 0.1164245530962944, 0.2910613715648651, 0.3484690189361572, 0.16895468533039093, 0.09503700584173203, 0.13727568089962006, 0.253432035446167, 0.5569358468055725, 0.27846792340278625, 0.06961698085069656, 0.06961698085069656, 0.06961698085069656, 0.29757216572761536, 0.08502061665058136, 0.2550618350505829, 0.34008246660232544, 0.04251030832529068, 0.15432903170585632, 0.46298709511756897, 0.11023502051830292, 0.11023502051830292, 0.13228203356266022, 0.1952870488166809, 0.38465631008148193, 0.21304041147232056, 0.15386252105236053, 0.05326010286808014, 0.29255250096321106, 0.15201257169246674, 0.26530495285987854, 0.19933724403381348, 0.08891301602125168, 0.06431515514850616, 0.45020607113838196, 0.12863031029701233, 0.16078788042068481, 0.1929454654455185, 0.37742888927459717, 0.20922687649726868, 0.17640697956085205, 0.14358706772327423, 0.09435722231864929, 0.33207398653030396, 0.2337919920682907, 0.2739982604980469, 0.10423846542835236, 0.05658659711480141, 0.13965417444705963, 0.27930834889411926, 0.13965417444705963, 0.31422188878059387, 0.13965417444705963, 0.14634962379932404, 0.20427967607975006, 0.27135658264160156, 0.2378181368112564, 0.13720276951789856, 0.5149354934692383, 0.15448065102100372, 0.15448065102100372, 0.10298709571361542, 0.10298709571361542, 0.222697451710701, 0.18558120727539062, 0.18558120727539062, 0.1113487258553505, 0.2969299256801605, 0.5543249845504761, 0.12318332493305206, 0.12318332493305206, 0.12318332493305206, 0.06159166246652603, 0.2946476936340332, 0.2715141773223877, 0.18872062861919403, 0.1497589498758316, 0.09375153481960297, 0.1398189812898636, 0.2796379625797272, 0.0699094906449318, 0.41945692896842957, 0.1398189812898636, 0.16483911871910095, 0.49451735615730286, 0.16483911871910095, 0.10989274084568024, 0.05494637042284012, 0.11250541359186172, 0.3719773590564728, 0.24528206884860992, 0.15203434228897095, 0.11757322400808334, 0.1300971359014511, 0.2601942718029022, 0.2601942718029022, 0.0433657132089138, 0.3035599887371063, 0.08789107948541641, 0.43945538997650146, 0.08789107948541641, 0.08789107948541641, 0.26367324590682983, 0.23163680732250214, 0.26869869232177734, 0.33355700969696045, 0.07412377744913101, 0.09728745371103287, 0.1540108621120453, 0.23101629316806793, 0.3080217242240906, 0.1540108621120453, 0.1540108621120453, 0.2684662938117981, 0.14722345769405365, 0.22516527771949768, 0.20784486830234528, 0.1501101851463318, 0.23214691877365112, 0.23214691877365112, 0.15476462244987488, 0.07738231122493744, 0.30952924489974976, 0.1336713433265686, 0.31746944785118103, 0.16708917915821075, 0.2840516269207001, 0.08354458957910538, 0.32905399799346924, 0.10968466103076935, 0.14624620974063873, 0.29249241948127747, 0.10968466103076935, 0.18771718442440033, 0.18771718442440033, 0.37543436884880066, 0.12514479458332062, 0.06257239729166031, 0.07154035568237305, 0.5007824897766113, 0.1430807113647461, 0.1430807113647461, 0.1430807113647461, 0.12464607506990433, 0.4985843002796173, 0.1869691163301468, 0.12464607506990433, 0.062323037534952164, 0.39153555035591125, 0.23090557754039764, 0.15345898270606995, 0.08892016112804413, 0.1333802342414856, 0.23794402182102203, 0.2451544553041458, 0.31004828214645386, 0.086525097489357, 0.1297876536846161, 0.33795639872550964, 0.23002839088439941, 0.16243711113929749, 0.07413237541913986, 0.19514256715774536, 0.1882474571466446, 0.2889145612716675, 0.23757433891296387, 0.1067071184515953, 0.17918741703033447, 0.13330905139446259, 0.5332362055778503, 0.2221817523241043, 0.04443635046482086, 0.08887270092964172, 0.4851350486278534, 0.13861000537872314, 0.10395751148462296, 0.13861000537872314, 0.10395751148462296, 0.16192995011806488, 0.28404104709625244, 0.18316665291786194, 0.21502172946929932, 0.15662077069282532, 0.12336597591638565, 0.2467319518327713, 0.18504896759986877, 0.30841493606567383, 0.12336597591638565, 0.17484162747859955, 0.3846515715122223, 0.10490497201681137, 0.06993664801120758, 0.2797465920448303, 0.4085516035556793, 0.17462286353111267, 0.15485423803329468, 0.17462286353111267, 0.0856640487909317, 0.36745524406433105, 0.14653123915195465, 0.21866968274116516, 0.20063507556915283, 0.06762979924678802, 0.22356177866458893, 0.2614535987377167, 0.20082668960094452, 0.23303474485874176, 0.08146742731332779, 0.21598564088344574, 0.287980854511261, 0.1439904272556305, 0.07199521362781525, 0.287980854511261, 0.12421831488609314, 0.24843662977218628, 0.3726549446582794, 0.12421831488609314, 0.12421831488609314, 0.2801697552204132, 0.25143441557884216, 0.15086063742637634, 0.23467211425304413, 0.08141685277223587, 0.2268407642841339, 0.27977028489112854, 0.14555616676807404, 0.14933684468269348, 0.19848567247390747, 0.12302988767623901, 0.12302988767623901, 0.2050498127937317, 0.16403985023498535, 0.36908966302871704, 0.24104824662208557, 0.2620089650154114, 0.18864646553993225, 0.09694331884384155, 0.20960718393325806, 0.3053775429725647, 0.28260818123817444, 0.2571600377559662, 0.07634438574314117, 0.07768376171588898, 0.4746013283729553, 0.17797550559043884, 0.11865033209323883, 0.11865033209323883, 0.059325166046619415, 0.28801828622817993, 0.18001142144203186, 0.1620102822780609, 0.270017147064209, 0.09000571072101593, 0.288105845451355, 0.30752870440483093, 0.1642850786447525, 0.13353221118450165, 0.10763505101203918, 0.2796088755130768, 0.09320296347141266, 0.18640592694282532, 0.37281185388565063, 0.09320296347141266, 0.2194121927022934, 0.37987783551216125, 0.1522786170244217, 0.10151907801628113, 0.14736640453338623, 0.18003445863723755, 0.24972522258758545, 0.2961857318878174, 0.17713068425655365, 0.09872857481241226, 0.1517556607723236, 0.28183192014694214, 0.39022883772850037, 0.13007627427577972, 0.06503813713788986, 0.26932838559150696, 0.3640782833099365, 0.14548209309577942, 0.08132076263427734, 0.13951359689235687, 0.23746046423912048, 0.17809534072875977, 0.17809534072875977, 0.17809534072875977, 0.2968255877494812, 0.4303372800350189, 0.2658454179763794, 0.15950724482536316, 0.09636896103620529, 0.048184480518102646, 0.17212827503681183, 0.447533518075943, 0.10327696800231934, 0.13770262897014618, 0.10327696800231934, 0.15819399058818817, 0.4745819866657257, 0.07909699529409409, 0.07909699529409409, 0.23729099333286285, 0.1890869140625, 0.452593594789505, 0.13592995703220367, 0.14124564826488495, 0.08125421404838562, 0.16634847223758698, 0.24397777020931244, 0.1441686749458313, 0.16634847223758698, 0.2883373498916626, 0.11010875552892685, 0.24223926663398743, 0.3523480296134949, 0.11010875552892685, 0.17617401480674744, 0.15989071130752563, 0.07994535565376282, 0.31978142261505127, 0.15989071130752563, 0.31978142261505127, 0.4832482933998108, 0.15350238978862762, 0.14213185012340546, 0.07959383726119995, 0.14213185012340546, 0.28776875138282776, 0.2853505313396454, 0.1596028357744217, 0.09914721548557281, 0.16685751080513, 0.47419530153274536, 0.15806511044502258, 0.11854882538318634, 0.15806511044502258, 0.07903255522251129, 0.24386917054653168, 0.3185541033744812, 0.19357116520404816, 0.12955549359321594, 0.11431367695331573, 0.22529521584510803, 0.19713331758975983, 0.12672856450080872, 0.3027404546737671, 0.14080950617790222, 0.21162672340869904, 0.24482306838035583, 0.17428083717823029, 0.1410844773054123, 0.22822490334510803, 0.2775290012359619, 0.24927756190299988, 0.2559249699115753, 0.10469657182693481, 0.11300582438707352, 0.22183676064014435, 0.22183676064014435, 0.3882143199443817, 0.11091838032007217, 0.11091838032007217, 0.3035893142223358, 0.2765854001045227, 0.1432024985551834, 0.17266130447387695, 0.10392410308122635, 0.3256548047065735, 0.28759124875068665, 0.1490822285413742, 0.10573208332061768, 0.1321651041507721, 0.2701604664325714, 0.2310582846403122, 0.15640868246555328, 0.10664228349924088, 0.23461303114891052, 0.22813855111598969, 0.13688313961029053, 0.2053246945142746, 0.11406927555799484, 0.31939399242401123, 0.1470995843410492, 0.2574242651462555, 0.3309740722179413, 0.0735497921705246, 0.1470995843410492, 0.3514721989631653, 0.17573609948158264, 0.20359669625759125, 0.19931045174598694, 0.07072306424379349, 0.28112101554870605, 0.1686726063489914, 0.1686726063489914, 0.3373452126979828, 0.05622420459985733, 0.14558063447475433, 0.2183709442615509, 0.07279031723737717, 0.36395156383514404, 0.2183709442615509, 0.3844376504421234, 0.2235102653503418, 0.1922188252210617, 0.12963595986366272, 0.07599349319934845, 0.2988120913505554, 0.23904967308044434, 0.35003700852394104, 0.059762418270111084, 0.059762418270111084, 0.4679797291755676, 0.31198650598526, 0.051997747272253036, 0.051997747272253036, 0.10399549454450607, 0.2163505256175995, 0.19038845598697662, 0.289909690618515, 0.1947154700756073, 0.10817526280879974, 0.4969673752784729, 0.2760929763317108, 0.05521859973669052, 0.05521859973669052, 0.11043719947338104, 0.18107320368289948, 0.2560000419616699, 0.09990245848894119, 0.08741465210914612, 0.37775617837905884, 0.2889210879802704, 0.1540912538766861, 0.11556843668222427, 0.1733526587486267, 0.26965969800949097, 0.17968803644180298, 0.17968803644180298, 0.11979202181100845, 0.35937607288360596, 0.17968803644180298, 0.20257095992565155, 0.16880913078784943, 0.20257095992565155, 0.32636433839797974, 0.10128547996282578, 0.17781828343868256, 0.22687159478664398, 0.324978232383728, 0.17168661952018738, 0.10423830151557922, 0.2260064333677292, 0.2518850266933441, 0.24670931696891785, 0.15527158975601196, 0.12249203771352768, 0.25815001130104065, 0.12907500565052032, 0.3226875066757202, 0.06453750282526016, 0.19361251592636108, 0.272255539894104, 0.24293573200702667, 0.2806326448917389, 0.10471367835998535, 0.10052512586116791, 0.2553379535675049, 0.22422534227371216, 0.18023855984210968, 0.19525843858718872, 0.14483454823493958, 0.16963349282741547, 0.2544502317905426, 0.08481674641370773, 0.16963349282741547, 0.2544502317905426, 0.07397651672363281, 0.22192955017089844, 0.22192955017089844, 0.07397651672363281, 0.36988258361816406, 0.27320942282676697, 0.27808815240859985, 0.24881571531295776, 0.11708974838256836, 0.08293857425451279, 0.10803885757923126, 0.30250880122184753, 0.15125440061092377, 0.17286217212677002, 0.25929325819015503, 0.24003373086452484, 0.389065682888031, 0.12265460193157196, 0.13716213405132294, 0.11078479886054993, 0.236492320895195, 0.21499301493167877, 0.12899580597877502, 0.2794909179210663, 0.13974545896053314, 0.14775370061397552, 0.29550740122795105, 0.14775370061397552, 0.29550740122795105, 0.22163055837154388, 0.21055856347084045, 0.36661961674690247, 0.13376662135124207, 0.11147218197584152, 0.17835548520088196, 0.26620030403137207, 0.19014307856559753, 0.1267620474100113, 0.13943825662136078, 0.27887651324272156, 0.16124245524406433, 0.483727365732193, 0.14332662522792816, 0.08957914263010025, 0.125410795211792, 0.18039976060390472, 0.23091168701648712, 0.20204773545265198, 0.2525596618652344, 0.13710381090641022, 0.20086830854415894, 0.3099111020565033, 0.20517262816429138, 0.21378126740455627, 0.06886913627386093, 0.17215438187122345, 0.17215438187122345, 0.25823158025741577, 0.08607719093561172, 0.3443087637424469, 0.25253891944885254, 0.2139565795660019, 0.20343412458896637, 0.25253891944885254, 0.08067215234041214, 0.2878604829311371, 0.14393024146556854, 0.3358372151851654, 0.11994186043739319, 0.09595348685979843, 0.27260321378707886, 0.18062733113765717, 0.30141493678092957, 0.1329771727323532, 0.11192245036363602, 0.13158518075942993, 0.32896292209625244, 0.1973777562379837, 0.26317036151885986, 0.06579259037971497, 0.25603795051574707, 0.3033064901828766, 0.19038718938827515, 0.12867549061775208, 0.12211041152477264, 0.22511304914951324, 0.38006100058555603, 0.11109475791454315, 0.11401829868555069, 0.16956567764282227, 0.13937507569789886, 0.4181252419948578, 0.13937507569789886, 0.2090626209974289, 0.06968753784894943, 0.26307976245880127, 0.21923312544822693, 0.13153988122940063, 0.3069263696670532, 0.08769325166940689, 0.5993847846984863, 0.1997949182987213, 0.04994872957468033, 0.09989745914936066, 0.04994872957468033, 0.4719712734222412, 0.15732376277446747, 0.15732376277446747, 0.15732376277446747, 0.15732376277446747, 0.2134799212217331, 0.22990144789218903, 0.34279948472976685, 0.13547764718532562, 0.07800228148698807, 0.12324436753988266, 0.4313552677631378, 0.12324436753988266, 0.1848665475845337, 0.06162218376994133, 0.47385409474372864, 0.1353868842124939, 0.1353868842124939, 0.1353868842124939, 0.06769344210624695, 0.1874961405992508, 0.4687403440475464, 0.0937480702996254, 0.0937480702996254, 0.0937480702996254, 0.5088978409767151, 0.16963261365890503, 0.08481630682945251, 0.08481630682945251, 0.08481630682945251, 0.20288985967636108, 0.1803465485572815, 0.3336411118507385, 0.1578032225370407, 0.12624257802963257, 0.15321049094200134, 0.15321049094200134, 0.38302624225616455, 0.07660524547100067, 0.15321049094200134, 0.18205834925174713, 0.2124014049768448, 0.22757293283939362, 0.14412952959537506, 0.23515871167182922, 0.19932042062282562, 0.13288027048110962, 0.39864084124565125, 0.13288027048110962, 0.06644013524055481, 0.23826727271080017, 0.07942242175340652, 0.23826727271080017, 0.3176896870136261, 0.15884484350681305, 0.19572703540325165, 0.2935905456542969, 0.3914540708065033, 0.09786351770162582, 0.09786351770162582, 0.46547532081604004, 0.2260880172252655, 0.10639435797929764, 0.10639435797929764, 0.09309506416320801, 0.37967830896377563, 0.18012644350528717, 0.17306266725063324, 0.13421186804771423, 0.13421186804771423, 0.5375165939331055, 0.13437914848327637, 0.13437914848327637, 0.06718957424163818, 0.06718957424163818, 0.07903071492910385, 0.553214967250824, 0.19757677614688873, 0.1580614298582077, 0.019757678732275963, 0.5016105771064758, 0.11575628817081451, 0.11575628817081451, 0.11575628817081451, 0.11575628817081451, 0.25983935594558716, 0.2125958502292633, 0.20865888893604279, 0.22046977281570435, 0.10236096382141113, 0.22576606273651123, 0.31529396772384644, 0.1401306539773941, 0.18684087693691254, 0.13234561681747437, 0.24664781987667084, 0.2731081247329712, 0.19467222690582275, 0.1823870837688446, 0.10206116735935211, 0.47227025032043457, 0.18057392537593842, 0.12501271069049835, 0.15279331803321838, 0.0833418145775795, 0.18262138962745667, 0.423942506313324, 0.12392165511846542, 0.1369660347700119, 0.13044384121894836, 0.17680034041404724, 0.22100041806697845, 0.3536006808280945, 0.08840017020702362, 0.13260024785995483, 0.2039952278137207, 0.2039952278137207, 0.2039952278137207, 0.13599681854248047, 0.27199363708496094, 0.3004738986492157, 0.12877453863620758, 0.12877453863620758, 0.3004738986492157, 0.12877453863620758, 0.17634639143943787, 0.22043298184871674, 0.35269278287887573, 0.08817319571971893, 0.1322597861289978, 0.1700957715511322, 0.23388169705867767, 0.3401915431022644, 0.12757183611392975, 0.12757183611392975, 0.31091123819351196, 0.216001495718956, 0.27491098642349243, 0.10145524889230728, 0.09818249940872192, 0.4047638177871704, 0.14026468992233276, 0.2284310758113861, 0.12022687494754791, 0.10419663041830063, 0.3945351541042328, 0.24190476536750793, 0.11375284194946289, 0.15263038873672485, 0.09791383892297745, 0.1433977335691452, 0.3248854875564575, 0.20165306329727173, 0.14787891507148743, 0.18148775398731232, 0.11401592940092087, 0.46508654952049255, 0.12960083782672882, 0.10171204805374146, 0.18947970867156982, 0.09491372108459473, 0.2847411632537842, 0.09491372108459473, 0.2847411632537842, 0.18982744216918945, 0.41380149126052856, 0.2019745409488678, 0.16256487369537354, 0.10837658494710922, 0.11822900176048279, 0.5009097456932068, 0.1252274364233017, 0.18784114718437195, 0.06261371821165085, 0.1252274364233017, 0.2152223438024521, 0.3784944713115692, 0.2028532475233078, 0.09647898375988007, 0.10884808003902435, 0.13748905062675476, 0.13748905062675476, 0.20623356103897095, 0.2749781012535095, 0.2749781012535095, 0.2635422646999359, 0.23891215026378632, 0.1428546905517578, 0.2044299840927124, 0.15024371445178986, 0.4609171152114868, 0.1646132618188858, 0.1646132618188858, 0.1316906064748764, 0.0987679585814476, 0.17550860345363617, 0.438771516084671, 0.17550860345363617, 0.17550860345363617, 0.08775430172681808, 0.18636587262153625, 0.4526028335094452, 0.14643032848834991, 0.11980663239955902, 0.10649478435516357, 0.3506242334842682, 0.20688173174858093, 0.17464041709899902, 0.17598381638526917, 0.0926937609910965, 0.27965471148490906, 0.16604498028755188, 0.28839391469955444, 0.14856655895709991, 0.11797932535409927, 0.3441987633705139, 0.3921251893043518, 0.10456671565771103, 0.0740680918097496, 0.08713892847299576, 0.20048224925994873, 0.46779191493988037, 0.11137902736663818, 0.08910322189331055, 0.13365483283996582, 0.28866735100746155, 0.21650052070617676, 0.15502506494522095, 0.14700652658939362, 0.18977205455303192, 0.13272768259048462, 0.4424256384372711, 0.14378832280635834, 0.15484897792339325, 0.13272768259048462, 0.4034460484981537, 0.21742601692676544, 0.14736652374267578, 0.14978237450122833, 0.08213871717453003, 0.47743746638298035, 0.17903906106948853, 0.17903906106948853, 0.11935936659574509, 0.05967968329787254, 0.3222934603691101, 0.10743115842342377, 0.3760090470314026, 0.16114673018455505, 0.053715579211711884, 0.38898783922195435, 0.24384313821792603, 0.14804761111736298, 0.1074070930480957, 0.11030998826026917, 0.2820989787578583, 0.3624735474586487, 0.13868553936481476, 0.12292581051588058, 0.09298234432935715, 0.22983777523040771, 0.22983777523040771, 0.15322518348693848, 0.11491888761520386, 0.26814407110214233, 0.21818850934505463, 0.24813595414161682, 0.23957954347133636, 0.1369026005268097, 0.15615452826023102, 0.5328474640846252, 0.10656949132680893, 0.053284745663404465, 0.1598542332649231, 0.10656949132680893, 0.10762490332126617, 0.4304996132850647, 0.19731232523918152, 0.07174993306398392, 0.1793748289346695, 0.2587857246398926, 0.17252382636070251, 0.34504765272140503, 0.08626191318035126, 0.08626191318035126, 0.19244451820850372, 0.25659269094467163, 0.19244451820850372, 0.06414817273616791, 0.25659269094467163, 0.1779756098985672, 0.1779756098985672, 0.4449390470981598, 0.0889878049492836, 0.0889878049492836, 0.3075271248817444, 0.15690159797668457, 0.3702877461910248, 0.08786489069461823, 0.08786489069461823, 0.4213159382343292, 0.22535504400730133, 0.1273745894432068, 0.1371726393699646, 0.08818241208791733, 0.22341656684875488, 0.36755630373954773, 0.19098512828350067, 0.14774321019649506, 0.06846636533737183, 0.3222712278366089, 0.16113561391830444, 0.16113561391830444, 0.3222712278366089, 0.06445424258708954, 0.18838733434677124, 0.28258100152015686, 0.09419366717338562, 0.28258100152015686, 0.09419366717338562, 0.3958287835121155, 0.17152580618858337, 0.13434189558029175, 0.14993514120578766, 0.14753618836402893, 0.060623522847890854, 0.15155881643295288, 0.45467641949653625, 0.030311761423945427, 0.30311763286590576, 0.2315795123577118, 0.2315795123577118, 0.15438634157180786, 0.07719317078590393, 0.3087726831436157, 0.33595603704452515, 0.1445886790752411, 0.2806721329689026, 0.15309388935565948, 0.08505216240882874, 0.19813895225524902, 0.19813895225524902, 0.36325475573539734, 0.16511580348014832, 0.09906947612762451, 0.44854632019996643, 0.0996769592165947, 0.0996769592165947, 0.1993539184331894, 0.0996769592165947, 0.19042865931987762, 0.16113193333148956, 0.10253850370645523, 0.20507700741291046, 0.3662089407444, 0.15551111102104187, 0.25918519496917725, 0.20734815299510956, 0.15551111102104187, 0.25918519496917725, 0.251850426197052, 0.188887819647789, 0.125925213098526, 0.29382550716400146, 0.125925213098526, 0.1373293101787567, 0.22316011786460876, 0.25749245285987854, 0.1373293101787567, 0.2489093691110611, 0.2273755818605423, 0.4124487340450287, 0.14277072250843048, 0.08460486680269241, 0.1321951150894165, 0.175552636384964, 0.6144342422485352, 0.087776318192482, 0.087776318192482, 0.087776318192482, 0.0944446548819542, 0.283333957195282, 0.0944446548819542, 0.283333957195282, 0.283333957195282, 0.13927073776721954, 0.29568248987197876, 0.23783157765865326, 0.21212005615234375, 0.11463053524494171, 0.2080773264169693, 0.23469185829162598, 0.2540479004383087, 0.18388228118419647, 0.11855568736791611, 0.13576006889343262, 0.2262667715549469, 0.13576006889343262, 0.3167734742164612, 0.18101342022418976, 0.6332183480262756, 0.12664367258548737, 0.06332183629274368, 0.06332183629274368, 0.06332183629274368, 0.11305709928274155, 0.5087569355964661, 0.16958564519882202, 0.11305709928274155, 0.11305709928274155, 0.28842633962631226, 0.3148247003555298, 0.16523407399654388, 0.11439282447099686, 0.1163482517004013, 0.31252530217170715, 0.25053682923316956, 0.12655983865261078, 0.21954257786273956, 0.09298273921012878], \"Term\": [\"Facebook\", \"Facebook\", \"Facebook\", \"Facebook\", \"Facebook\", \"People\", \"People\", \"People\", \"People\", \"People\", \"Technology\", \"Technology\", \"Technology\", \"Technology\", \"Technology\", \"able\", \"able\", \"able\", \"able\", \"able\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"acess\", \"acess\", \"acess\", \"acess\", \"acess\", \"addicting\", \"addicting\", \"addicting\", \"addicting\", \"addicting\", \"addiction\", \"addiction\", \"addiction\", \"addiction\", \"addiction\", \"adult\", \"adult\", \"adult\", \"adult\", \"adult\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"affect\", \"affect\", \"affect\", \"affect\", \"affect\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"alow\", \"alow\", \"alow\", \"alow\", \"alow\", \"alternative\", \"alternative\", \"alternative\", \"alternative\", \"alternative\", \"apart\", \"apart\", \"apart\", \"apart\", \"apart\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"away\", \"away\", \"away\", \"away\", \"away\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad_effect\", \"bad_effect\", \"bad_effect\", \"bad_effect\", \"bad_effect\", \"beautiful_nature\", \"beautiful_nature\", \"beautiful_nature\", \"beautiful_nature\", \"beautiful_nature\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"beneficial_society\", \"beneficial_society\", \"beneficial_society\", \"beneficial_society\", \"beneficial_society\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit_society\", \"benefit_society\", \"benefit_society\", \"benefit_society\", \"benefit_society\", \"benifit\", \"benifit\", \"benifit\", \"benifit\", \"benifit\", \"better\", \"better\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big_problem\", \"big_problem\", \"big_problem\", \"big_problem\", \"big_problem\", \"board_game\", \"board_game\", \"board_game\", \"board_game\", \"board_game\", \"book\", \"book\", \"book\", \"book\", \"book\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"buisnesse\", \"buisnesse\", \"buisnesse\", \"buisnesse\", \"buisnesse\", \"buissness\", \"buissness\", \"buissness\", \"buissness\", \"buissness\", \"burn_calorie\", \"burn_calorie\", \"burn_calorie\", \"burn_calorie\", \"burn_calorie\", \"business\", \"business\", \"business\", \"business\", \"business\", \"career\", \"career\", \"career\", \"career\", \"career\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"change\", \"change\", \"change\", \"change\", \"change\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"chat\", \"chat\", \"chat\", \"chat\", \"chat\", \"chating\", \"chating\", \"chating\", \"chating\", \"chating\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child_adult\", \"child_adult\", \"child_adult\", \"child_adult\", \"child_adult\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"click_away\", \"click_away\", \"click_away\", \"click_away\", \"click_away\", \"close\", \"close\", \"close\", \"close\", \"close\", \"com\", \"com\", \"com\", \"com\", \"com\", \"come\", \"come\", \"come\", \"come\", \"come\", \"communicate\", \"communicate\", \"communicate\", \"communicate\", \"communicate\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"computor\", \"computor\", \"computor\", \"computor\", \"computor\", \"conclution\", \"conclution\", \"conclution\", \"conclution\", \"conclution\", \"connect\", \"connect\", \"connect\", \"connect\", \"connect\", \"country\", \"country\", \"country\", \"country\", \"country\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"current_event\", \"current_event\", \"current_event\", \"current_event\", \"current_event\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"daily_life\", \"daily_life\", \"daily_life\", \"daily_life\", \"daily_life\", \"damage\", \"damage\", \"damage\", \"damage\", \"damage\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear_local_newspaper\", \"dear_local_newspaper\", \"dear_local_newspaper\", \"dear_local_newspaper\", \"dear_local_newspaper\", \"dear_reader\", \"dear_reader\", \"dear_reader\", \"dear_reader\", \"dear_reader\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"delete\", \"delete\", \"delete\", \"delete\", \"delete\", \"depressed\", \"depressed\", \"depressed\", \"depressed\", \"depressed\", \"depression\", \"depression\", \"depression\", \"depression\", \"depression\", \"design\", \"design\", \"design\", \"design\", \"design\", \"die\", \"die\", \"die\", \"die\", \"die\", \"disaster\", \"disaster\", \"disaster\", \"disaster\", \"disaster\", \"dollar\", \"dollar\", \"dollar\", \"dollar\", \"dollar\", \"download\", \"download\", \"download\", \"download\", \"download\", \"e_mail\", \"e_mail\", \"e_mail\", \"e_mail\", \"e_mail\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"ect\", \"ect\", \"ect\", \"ect\", \"ect\", \"education\", \"education\", \"education\", \"education\", \"education\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"electricity\", \"electricity\", \"electricity\", \"electricity\", \"electricity\", \"email\", \"email\", \"email\", \"email\", \"email\", \"enhance\", \"enhance\", \"enhance\", \"enhance\", \"enhance\", \"entertaining\", \"entertaining\", \"entertaining\", \"entertaining\", \"entertaining\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"example\", \"example\", \"example\", \"example\", \"example\", \"excersice\", \"excersice\", \"excersice\", \"excersice\", \"excersice\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exercise_enjoy_nature_interact\", \"exercise_enjoy_nature_interact\", \"exercise_enjoy_nature_interact\", \"exercise_enjoy_nature_interact\", \"exercise_enjoy_nature_interact\", \"explore_nature\", \"explore_nature\", \"explore_nature\", \"explore_nature\", \"explore_nature\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye_hand\", \"eye_hand\", \"eye_hand\", \"eye_hand\", \"eye_hand\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fail_class\", \"fail_class\", \"fail_class\", \"fail_class\", \"fail_class\", \"famous\", \"famous\", \"famous\", \"famous\", \"famous\", \"final\", \"final\", \"final\", \"final\", \"final\", \"foreign_place\", \"foreign_place\", \"foreign_place\", \"foreign_place\", \"foreign_place\", \"frend\", \"frend\", \"frend\", \"frend\", \"frend\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"future\", \"future\", \"future\", \"future\", \"future\", \"game\", \"game\", \"game\", \"game\", \"game\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get_fat\", \"get_fat\", \"get_fat\", \"get_fat\", \"get_fat\", \"government\", \"government\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great_resource\", \"great_resource\", \"great_resource\", \"great_resource\", \"great_resource\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand_eye_coordination\", \"hand_eye_coordination\", \"hand_eye_coordination\", \"hand_eye_coordination\", \"hand_eye_coordination\", \"have\", \"have\", \"have\", \"have\", \"have\", \"headache\", \"headache\", \"headache\", \"headache\", \"headache\", \"health_issue\", \"health_issue\", \"health_issue\", \"health_issue\", \"health_issue\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"homework\", \"homework\", \"homework\", \"homework\", \"homework\", \"honestly\", \"honestly\", \"honestly\", \"honestly\", \"honestly\", \"hour\", \"hour\", \"hour\", \"hour\", \"hour\", \"important\", \"important\", \"important\", \"important\", \"important\", \"incredible\", \"incredible\", \"incredible\", \"incredible\", \"incredible\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"information\", \"information\", \"information\", \"information\", \"information\", \"instal\", \"instal\", \"instal\", \"instal\", \"instal\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact_family\", \"interact_family\", \"interact_family\", \"interact_family\", \"interact_family\", \"internet\", \"internet\", \"internet\", \"internet\", \"internet\", \"intouch\", \"intouch\", \"intouch\", \"intouch\", \"intouch\", \"job\", \"job\", \"job\", \"job\", \"job\", \"jog\", \"jog\", \"jog\", \"jog\", \"jog\", \"kick\", \"kick\", \"kick\", \"kick\", \"kick\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"lack_exercise\", \"lack_exercise\", \"lack_exercise\", \"lack_exercise\", \"lack_exercise\", \"lake\", \"lake\", \"lake\", \"lake\", \"lake\", \"laptop\", \"laptop\", \"laptop\", \"laptop\", \"laptop\", \"lastly\", \"lastly\", \"lastly\", \"lastly\", \"lastly\", \"lesson\", \"lesson\", \"lesson\", \"lesson\", \"lesson\", \"let\", \"let\", \"let\", \"let\", \"let\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"little\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live_faraway\", \"live_faraway\", \"live_faraway\", \"live_faraway\", \"live_faraway\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love_one\", \"love_one\", \"love_one\", \"love_one\", \"love_one\", \"majority\", \"majority\", \"majority\", \"majority\", \"majority\", \"make\", \"make\", \"make\", \"make\", \"make\", \"massive\", \"massive\", \"massive\", \"massive\", \"massive\", \"material\", \"material\", \"material\", \"material\", \"material\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet_new\", \"meet_new\", \"meet_new\", \"meet_new\", \"meet_new\", \"method\", \"method\", \"method\", \"method\", \"method\", \"money\", \"money\", \"money\", \"money\", \"money\", \"natural_disaster\", \"natural_disaster\", \"natural_disaster\", \"natural_disaster\", \"natural_disaster\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"neat\", \"neat\", \"neat\", \"neat\", \"neat\", \"neatly\", \"neatly\", \"neatly\", \"neatly\", \"neatly\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative_effect\", \"negative_effect\", \"negative_effect\", \"negative_effect\", \"negative_effect\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new_one\", \"new_one\", \"new_one\", \"new_one\", \"new_one\", \"news\", \"news\", \"news\", \"news\", \"news\", \"not\", \"not\", \"not\", \"not\", \"not\", \"o\", \"o\", \"o\", \"o\", \"o\", \"obease\", \"obease\", \"obease\", \"obease\", \"obease\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"outdoors\", \"outdoors\", \"outdoors\", \"outdoors\", \"outdoors\", \"outside\", \"outside\", \"outside\", \"outside\", \"outside\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page_essay\", \"page_essay\", \"page_essay\", \"page_essay\", \"page_essay\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"park\", \"park\", \"park\", \"park\", \"park\", \"past\", \"past\", \"past\", \"past\", \"past\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"person\", \"person\", \"person\", \"person\", \"person\", \"personal_experience\", \"personal_experience\", \"personal_experience\", \"personal_experience\", \"personal_experience\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"physically\", \"physically\", \"physically\", \"physically\", \"physically\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plan_vacation\", \"plan_vacation\", \"plan_vacation\", \"plan_vacation\", \"plan_vacation\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play_game\", \"play_game\", \"play_game\", \"play_game\", \"play_game\", \"plug\", \"plug\", \"plug\", \"plug\", \"plug\", \"point_view\", \"point_view\", \"point_view\", \"point_view\", \"point_view\", \"portable\", \"portable\", \"portable\", \"portable\", \"portable\", \"pose\", \"pose\", \"pose\", \"pose\", \"pose\", \"positive_effect\", \"positive_effect\", \"positive_effect\", \"positive_effect\", \"positive_effect\", \"post_picture\", \"post_picture\", \"post_picture\", \"post_picture\", \"post_picture\", \"power_point\", \"power_point\", \"power_point\", \"power_point\", \"power_point\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"program\", \"program\", \"program\", \"program\", \"program\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"question\", \"quiz\", \"quiz\", \"quiz\", \"quiz\", \"quiz\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"relative_live\", \"relative_live\", \"relative_live\", \"relative_live\", \"relative_live\", \"rely\", \"rely\", \"rely\", \"rely\", \"rely\", \"research\", \"research\", \"research\", \"research\", \"research\", \"researching\", \"researching\", \"researching\", \"researching\", \"researching\", \"reson\", \"reson\", \"reson\", \"reson\", \"reson\", \"road\", \"road\", \"road\", \"road\", \"road\", \"save\", \"save\", \"save\", \"save\", \"save\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school_project\", \"school_project\", \"school_project\", \"school_project\", \"school_project\", \"school_work\", \"school_work\", \"school_work\", \"school_work\", \"school_work\", \"schoolwork\", \"schoolwork\", \"schoolwork\", \"schoolwork\", \"schoolwork\", \"seriously\", \"seriously\", \"seriously\", \"seriously\", \"seriously\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shop_online\", \"shop_online\", \"shop_online\", \"shop_online\", \"shop_online\", \"shopping\", \"shopping\", \"shopping\", \"shopping\", \"shopping\", \"site\", \"site\", \"site\", \"site\", \"site\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"society\", \"society\", \"society\", \"society\", \"society\", \"spend\", \"spend\", \"spend\", \"spend\", \"spend\", \"spend_time\", \"spend_time\", \"spend_time\", \"spend_time\", \"spend_time\", \"spending_time_family\", \"spending_time_family\", \"spending_time_family\", \"spending_time_family\", \"spending_time_family\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"star\", \"star\", \"star\", \"star\", \"star\", \"start\", \"start\", \"start\", \"start\", \"start\", \"status\", \"status\", \"status\", \"status\", \"status\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"stock\", \"stock\", \"stock\", \"stock\", \"stock\", \"storm\", \"storm\", \"storm\", \"storm\", \"storm\", \"story\", \"story\", \"story\", \"story\", \"story\", \"student\", \"student\", \"student\", \"student\", \"student\", \"study\", \"study\", \"study\", \"study\", \"study\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"suppose\", \"suppose\", \"suppose\", \"suppose\", \"suppose\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take_away\", \"take_away\", \"take_away\", \"take_away\", \"take_away\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach_hand_eye\", \"teach_hand_eye\", \"teach_hand_eye\", \"teach_hand_eye\", \"teach_hand_eye\", \"teach_skill\", \"teach_skill\", \"teach_skill\", \"teach_skill\", \"teach_skill\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"television\", \"television\", \"television\", \"television\", \"television\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"thay\", \"thay\", \"thay\", \"thay\", \"thay\", \"thi\", \"thi\", \"thi\", \"thi\", \"thi\", \"throught\", \"throught\", \"throught\", \"throught\", \"throught\", \"till\", \"till\", \"till\", \"till\", \"till\", \"tradition\", \"tradition\", \"tradition\", \"tradition\", \"tradition\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"trip\", \"trip\", \"trip\", \"trip\", \"trip\", \"try\", \"try\", \"try\", \"try\", \"try\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter_facebook\", \"twitter_facebook\", \"twitter_facebook\", \"twitter_facebook\", \"twitter_facebook\", \"type\", \"type\", \"type\", \"type\", \"type\", \"u\", \"u\", \"u\", \"u\", \"u\", \"unfortunately\", \"unfortunately\", \"unfortunately\", \"unfortunately\", \"unfortunately\", \"useful\", \"useful\", \"useful\", \"useful\", \"useful\", \"usefull\", \"usefull\", \"usefull\", \"usefull\", \"usefull\", \"video_chatting\", \"video_chatting\", \"video_chatting\", \"video_chatting\", \"video_chatting\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"waist\", \"waist\", \"waist\", \"waist\", \"waist\", \"war\", \"war\", \"war\", \"war\", \"war\", \"waste\", \"waste\", \"waste\", \"waste\", \"waste\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch_news\", \"watch_news\", \"watch_news\", \"watch_news\", \"watch_news\", \"watch_tv\", \"watch_tv\", \"watch_tv\", \"watch_tv\", \"watch_tv\", \"website\", \"website\", \"website\", \"website\", \"website\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well_grade\", \"well_grade\", \"well_grade\", \"well_grade\", \"well_grade\", \"white\", \"white\", \"white\", \"white\", \"white\", \"will_able\", \"will_able\", \"will_able\", \"will_able\", \"will_able\", \"work\", \"work\", \"work\", \"work\", \"work\", \"write\", \"write\", \"write\", \"write\", \"write\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 3, 5, 1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el81863063857361877425266\", ldavis_el81863063857361877425266_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el81863063857361877425266\", ldavis_el81863063857361877425266_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el81863063857361877425266\", ldavis_el81863063857361877425266_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing text with LDA\n",
    "Beyond data exploration, one of the key uses for an LDA model is providing a compact, quantitative description of natural language text. Once an LDA model has been trained, it can be used to represent free text as a mixture of the topics the model learned from the original corpus. This mixture can be interpreted as a probability distribution across the topics, so the LDA representation of a paragraph of text might look like 50% _Topic A_, 20% _Topic B_, 20% _Topic C_, and 10% _Topic D_.\n",
    "\n",
    "To use an LDA model to generate a vector representation of new text, you'll need to apply any text preprocessing steps you used on the model's training corpus to the new text, too. For our model, the preprocessing steps we used include:\n",
    "1. Using spaCy to remove punctuation and lemmatize the text\n",
    "1. Applying our first-order phrase model to join word pairs\n",
    "1. Applying our second-order phrase model to join longer phrases\n",
    "1. Removing stopwords\n",
    "1. Creating a bag-of-words representation\n",
    "\n",
    "Once you've applied these preprocessing steps to the new text, it's ready to pass directly to the model to create an LDA representation. The `lda_description(...)` function will perform all these steps for us, including printing the resulting topical description of the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_essay(essay_number):\n",
    "    \"\"\"\n",
    "    retrieve a particular review index\n",
    "    from the reviews file and return it\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(it.islice(line_review(essay_set1_txt_filepath),essay_number, essay_number+1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_description(essay_text, min_topic_freq=0.05):\n",
    "    \"\"\"\n",
    "    accept the original text of a review and (1) parse it with spaCy,\n",
    "    (2) apply text pre-proccessing steps, (3) create a bag-of-words\n",
    "    representation, (4) create an LDA representation, and\n",
    "    (5) print a sorted list of the top topics in the LDA representation\n",
    "    \"\"\"\n",
    "    \n",
    "    # parse the essay text with spaCy\n",
    "    parsed_essay = nlp(essay_text)\n",
    "    \n",
    "    # lemmatize the text and remove punctuation and whitespace\n",
    "    unigram_essay = [token.lemma_ for token in parsed_essay if not punct_space_stop(token)]\n",
    "    \n",
    "    # apply the first-order and secord-order phrase models\n",
    "    bigram_essay = bigram_model[unigram_essay]\n",
    "    trigram_essay = trigram_model[bigram_essay]\n",
    "    \n",
    "    # create a bag-of-words representation\n",
    "    essay_bow = trigram_dictionary.doc2bow(trigram_essay)\n",
    "    \n",
    "    # create an LDA representation\n",
    "    essay_lda = lda[essay_bow]\n",
    "    \n",
    "    # sort with the most highly related topics first\n",
    "    essay_lda = sorted(essay_lda)\n",
    "    \n",
    "    topics = [];\n",
    "    freqs = [];\n",
    "    for topic_number, freq in essay_lda:\n",
    "#         if freq < min_topic_freq:\n",
    "#             break\n",
    "            \n",
    "        # print the most highly related topic names and frequencies\n",
    "#         print('{:25} {}'.format(topic_names[topic_number],round(freq, 3)))\n",
    "        \n",
    "#         print(topic_names[topic_number])\n",
    "        topics.append(topic_names[topic_number])\n",
    "        freqs.append(round(freq, 3))\n",
    "        \n",
    "    # return topic and freq\n",
    "#     print(topics)\n",
    "#     print(freqs)\n",
    "    return list(zip(topics, freqs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_essay = get_sample_essay(0)\n",
    "print(sample_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple = lda_description(sample_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('looking_at_websites_for_info', 0.205),\n",
       " ('doesnt_have_the_negative_exercise_effect', 0.564),\n",
       " ('spend_time_looking_on_websites', 0.013),\n",
       " ('games_and_information', 0.215)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDFFromTuple(tuple):\n",
    "    return pd.DataFrame({k:v for k,*v in tuple})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = pd.DataFrame(columns=list(topic_names.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>looking_at_websites_for_info</th>\n",
       "      <th>doesnt_have_the_negative_exercise_effect</th>\n",
       "      <th>spend_time_looking_on_websites</th>\n",
       "      <th>games_and_information</th>\n",
       "      <th>bad_if_kids_spend_too_much_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [looking_at_websites_for_info, doesnt_have_the_negative_exercise_effect, spend_time_looking_on_websites, games_and_information, bad_if_kids_spend_too_much_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "steve = createDFFromTuple(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>looking_at_websites_for_info</th>\n",
       "      <th>doesnt_have_the_negative_exercise_effect</th>\n",
       "      <th>spend_time_looking_on_websites</th>\n",
       "      <th>games_and_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   looking_at_websites_for_info  doesnt_have_the_negative_exercise_effect  \\\n",
       "0                         0.205                                     0.564   \n",
       "\n",
       "   spend_time_looking_on_websites  games_and_information  \n",
       "0                           0.013                  0.215  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left.join(right, Seq(\"firstname\", \"lastname\")).show\n",
    "jo = pd.concat([steve, colNames], sort=True).drop_duplicates().reset_index(drop=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_if_kids_spend_too_much_time</th>\n",
       "      <th>doesnt_have_the_negative_exercise_effect</th>\n",
       "      <th>games_and_information</th>\n",
       "      <th>looking_at_websites_for_info</th>\n",
       "      <th>spend_time_looking_on_websites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad_if_kids_spend_too_much_time  doesnt_have_the_negative_exercise_effect  \\\n",
       "0                                0                                     0.564   \n",
       "\n",
       "   games_and_information  looking_at_websites_for_info  \\\n",
       "0                  0.215                         0.205   \n",
       "\n",
       "   spend_time_looking_on_websites  \n",
       "0                           0.013  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essays.loc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([essays.loc[[0]], jo], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(essays.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(jo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essays = essays.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prompt</th>\n",
       "      <th>has_source_material</th>\n",
       "      <th>grade_7</th>\n",
       "      <th>grade_8</th>\n",
       "      <th>grade_10</th>\n",
       "      <th>bad_if_kids_spend_too_much_time</th>\n",
       "      <th>doesnt_have_the_negative_exercise_effect</th>\n",
       "      <th>games_and_information</th>\n",
       "      <th>looking_at_websites_for_info</th>\n",
       "      <th>spend_time_looking_on_websites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0             4.0             4.0            8.0   \n",
       "\n",
       "                                              prompt  has_source_material  \\\n",
       "0  More and more people use computers, but not ev...                    0   \n",
       "\n",
       "   grade_7  grade_8  grade_10  bad_if_kids_spend_too_much_time  \\\n",
       "0        0        1         0                                0   \n",
       "\n",
       "   doesnt_have_the_negative_exercise_effect  games_and_information  \\\n",
       "0                                     0.564                  0.215   \n",
       "\n",
       "   looking_at_websites_for_info  spend_time_looking_on_websites  \n",
       "0                         0.205                           0.013  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neww = pd.concat([essays.loc[[0]], jo], axis=1, sort=False)\n",
    "neww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'domain1_score', 'prompt', 'has_source_material', 'grade_7', 'grade_8',\n",
       "       'grade_10', 'bad_if_kids_spend_too_much_time',\n",
       "       'doesnt_have_the_negative_exercise_effect', 'games_and_information',\n",
       "       'looking_at_websites_for_info', 'spend_time_looking_on_websites'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neww.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_topic_and_score_df(topic_names):\n",
    "    \n",
    "    processed_df = pd.DataFrame(columns=['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
    "       'domain1_score', 'prompt', 'has_source_material', 'grade_7', 'grade_8',\n",
    "       'grade_10', 'bad_if_kids_spend_too_much_time',\n",
    "       'doesnt_have_the_negative_exercise_effect', 'games_and_information',\n",
    "       'looking_at_websites_for_info', 'spend_time_looking_on_websites'])\n",
    "    for n in range(len(essays)):\n",
    "        tuple = lda_description(get_sample_essay(n))\n",
    "        topic_scores = createDFFromTuple(tuple)\n",
    "        processed_topic_scores = pd.concat([topic_scores, topic_names], sort=True).drop_duplicates().reset_index(drop=True).fillna(0)\n",
    "        indexNamesArr = processed_topic_scores.index.values\n",
    "        indexNamesArr[0] = n\n",
    "        merged_dfs = pd.concat([essays.loc[[n]], processed_topic_scores], axis=1, sort=False)\n",
    "        processed_df = processed_df.append(merged_dfs)\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prompt</th>\n",
       "      <th>has_source_material</th>\n",
       "      <th>grade_7</th>\n",
       "      <th>grade_8</th>\n",
       "      <th>grade_10</th>\n",
       "      <th>bad_if_kids_spend_too_much_time</th>\n",
       "      <th>doesnt_have_the_negative_exercise_effect</th>\n",
       "      <th>games_and_information</th>\n",
       "      <th>looking_at_websites_for_info</th>\n",
       "      <th>spend_time_looking_on_websites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I think that computers have a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Did you know that more and more people these d...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>@PERCENT1 of people agree that computers make ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear reader, @ORGANIZATION1 has had a dramatic...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>In the @LOCATION1 we have the technology of a ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, @CAPS1 people acknowledge the...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2 I feel that computers do ta...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper I raed ur argument on the...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>My three detaileds for this news paper article...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, In this world today we should have every...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, The computer blinked to l...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I belive that computers ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I must admit that the ex...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>I aegre waf the evansmant ov tnachnolage. The ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Well computers can be a good or a bad thing. I...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 of the @CAPS2 @CAPS3 daily, I am w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local Newspaper @CAPS1 a take all your co...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 you ever see a ch...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I've heard that not many...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 off, I beileve that comput...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you think that computers are useless? Or do...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers a good because you can get infermati...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper, Computers are high tec and hav...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 people throughout...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper People, I think that computers ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>1758</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 on a beautiful su...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, I believe that computers have a n...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "      <td>I think we can all agree that computer usage i...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>1761</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @PERSON1, Computers are very helpful in d...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>1762</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper, @CAPS1 are worried that people...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>1763</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper: @CAPS1 you know that ove...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>1764</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @PERSON1, The advansing technology is sho...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1765</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local Newspaper I ting that computers are...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>1766</td>\n",
       "      <td>1</td>\n",
       "      <td>Man has always been interested in technology. ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1767</td>\n",
       "      <td>1</td>\n",
       "      <td>Guaranteed, @NUM1 years from now we will still...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>1768</td>\n",
       "      <td>1</td>\n",
       "      <td>I think the effects of the computer are bad, t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>1769</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear editor, I think people are using computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>1770</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3, experts have been ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers, a @LOCATION1 topic if you ask me. S...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>1772</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper Readers, @CAPS1 many hours a da...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1773</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 newspaper, I have resently read th...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>1774</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION2 (our local newspaper), @CA...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1775</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, In my opinion computers do ben...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>Technology, such as computers are very big. I ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1777</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper, Computers have advance a lot s...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1778</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper, I think that computers have a ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1779</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, *@CAPS1*. Now I hear my favor...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1780</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper I think that computers were one...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1781</td>\n",
       "      <td>1</td>\n",
       "      <td>Mom!!! Did you know that the human body has on...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1782</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, I believe that computers ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1783</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 several reasons on way I t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1784</td>\n",
       "      <td>1</td>\n",
       "      <td>Do a adults and kids spend to much time on the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1785</td>\n",
       "      <td>1</td>\n",
       "      <td>My opinion is that people should have computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear readers, I think that its good and bad to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1787</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear - Local Newspaper I agree thats computers...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1783 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essay_id essay_set                                              essay  \\\n",
       "0           1         1  Dear local newspaper, I think effects computer...   \n",
       "1           2         1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2           3         1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3           4         1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4           5         1  Dear @LOCATION1, I know having computers has a...   \n",
       "5           6         1  Dear @LOCATION1, I think that computers have a...   \n",
       "6           7         1  Did you know that more and more people these d...   \n",
       "7           8         1  @PERCENT1 of people agree that computers make ...   \n",
       "8           9         1  Dear reader, @ORGANIZATION1 has had a dramatic...   \n",
       "9          10         1  In the @LOCATION1 we have the technology of a ...   \n",
       "10         11         1  Dear @LOCATION1, @CAPS1 people acknowledge the...   \n",
       "11         12         1  Dear @CAPS1 @CAPS2 I feel that computers do ta...   \n",
       "12         13         1  Dear local newspaper I raed ur argument on the...   \n",
       "13         14         1  My three detaileds for this news paper article...   \n",
       "14         15         1  Dear, In this world today we should have every...   \n",
       "15         16         1  Dear @ORGANIZATION1, The computer blinked to l...   \n",
       "16         17         1  Dear Local Newspaper, I belive that computers ...   \n",
       "17         18         1  Dear Local Newspaper, I must admit that the ex...   \n",
       "18         19         1  I aegre waf the evansmant ov tnachnolage. The ...   \n",
       "19         20         1  Well computers can be a good or a bad thing. I...   \n",
       "20         21         1  Dear @CAPS1 of the @CAPS2 @CAPS3 daily, I am w...   \n",
       "21         22         1  Dear local Newspaper @CAPS1 a take all your co...   \n",
       "22         23         1  Dear local newspaper, @CAPS1 you ever see a ch...   \n",
       "23         24         1  Dear local newspaper, I've heard that not many...   \n",
       "24         25         1  Dear @CAPS1, @CAPS2 off, I beileve that comput...   \n",
       "25         26         1  Do you think that computers are useless? Or do...   \n",
       "26         27         1  Computers a good because you can get infermati...   \n",
       "27         28         1  Dear Newspaper, Computers are high tec and hav...   \n",
       "28         29         1  Dear local newspaper, @CAPS1 people throughout...   \n",
       "29         30         1  Dear Newspaper People, I think that computers ...   \n",
       "...       ...       ...                                                ...   \n",
       "1753     1758         1  Dear local newspaper, @CAPS1 on a beautiful su...   \n",
       "1754     1759         1  Dear @CAPS1, I believe that computers have a n...   \n",
       "1755     1760         1  I think we can all agree that computer usage i...   \n",
       "1756     1761         1  Dear @PERSON1, Computers are very helpful in d...   \n",
       "1757     1762         1  Dear Newspaper, @CAPS1 are worried that people...   \n",
       "1758     1763         1  Dear Local Newspaper: @CAPS1 you know that ove...   \n",
       "1759     1764         1  Dear @PERSON1, The advansing technology is sho...   \n",
       "1760     1765         1  Dear local Newspaper I ting that computers are...   \n",
       "1761     1766         1  Man has always been interested in technology. ...   \n",
       "1762     1767         1  Guaranteed, @NUM1 years from now we will still...   \n",
       "1763     1768         1  I think the effects of the computer are bad, t...   \n",
       "1764     1769         1  Dear editor, I think people are using computer...   \n",
       "1765     1770         1  Dear @CAPS1 @CAPS2, @CAPS3, experts have been ...   \n",
       "1766     1771         1  Computers, a @LOCATION1 topic if you ask me. S...   \n",
       "1767     1772         1  Dear Newspaper Readers, @CAPS1 many hours a da...   \n",
       "1768     1773         1  Dear @CAPS1 newspaper, I have resently read th...   \n",
       "1769     1774         1  Dear @ORGANIZATION2 (our local newspaper), @CA...   \n",
       "1770     1775         1  Dear newspaper, In my opinion computers do ben...   \n",
       "1771     1776         1  Technology, such as computers are very big. I ...   \n",
       "1772     1777         1  Dear Newspaper, Computers have advance a lot s...   \n",
       "1773     1778         1  Dear Newspaper, I think that computers have a ...   \n",
       "1774     1779         1  Dear @LOCATION1, *@CAPS1*. Now I hear my favor...   \n",
       "1775     1780         1  Dear Newspaper I think that computers were one...   \n",
       "1776     1781         1  Mom!!! Did you know that the human body has on...   \n",
       "1777     1782         1  Dear @ORGANIZATION1, I believe that computers ...   \n",
       "1778     1783         1  Dear @CAPS1, @CAPS2 several reasons on way I t...   \n",
       "1779     1784         1  Do a adults and kids spend to much time on the...   \n",
       "1780     1785         1  My opinion is that people should have computer...   \n",
       "1781     1786         1  Dear readers, I think that its good and bad to...   \n",
       "1782     1787         1  Dear - Local Newspaper I agree thats computers...   \n",
       "\n",
       "      rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0                4.0             4.0            8.0   \n",
       "1                5.0             4.0            9.0   \n",
       "2                4.0             3.0            7.0   \n",
       "3                5.0             5.0           10.0   \n",
       "4                4.0             4.0            8.0   \n",
       "5                4.0             4.0            8.0   \n",
       "6                5.0             5.0           10.0   \n",
       "7                5.0             5.0           10.0   \n",
       "8                4.0             5.0            9.0   \n",
       "9                5.0             4.0            9.0   \n",
       "10               4.0             4.0            8.0   \n",
       "11               4.0             4.0            8.0   \n",
       "12               4.0             3.0            7.0   \n",
       "13               3.0             3.0            6.0   \n",
       "14               3.0             3.0            6.0   \n",
       "15               6.0             6.0           12.0   \n",
       "16               4.0             4.0            8.0   \n",
       "17               4.0             4.0            8.0   \n",
       "18               2.0             2.0            4.0   \n",
       "19               3.0             3.0            6.0   \n",
       "20               4.0             4.0            8.0   \n",
       "21               2.0             1.0            3.0   \n",
       "22               5.0             5.0           10.0   \n",
       "23               6.0             5.0           11.0   \n",
       "24               4.0             4.0            8.0   \n",
       "25               5.0             4.0            9.0   \n",
       "26               2.0             2.0            4.0   \n",
       "27               5.0             4.0            9.0   \n",
       "28               5.0             4.0            9.0   \n",
       "29               4.0             4.0            8.0   \n",
       "...              ...             ...            ...   \n",
       "1753             5.0             5.0           10.0   \n",
       "1754             5.0             5.0           10.0   \n",
       "1755             6.0             6.0           12.0   \n",
       "1756             4.0             4.0            8.0   \n",
       "1757             4.0             4.0            8.0   \n",
       "1758             6.0             6.0           12.0   \n",
       "1759             4.0             4.0            8.0   \n",
       "1760             2.0             3.0            5.0   \n",
       "1761             4.0             4.0            8.0   \n",
       "1762             4.0             5.0            9.0   \n",
       "1763             4.0             4.0            8.0   \n",
       "1764             4.0             5.0            9.0   \n",
       "1765             5.0             5.0           10.0   \n",
       "1766             4.0             4.0            8.0   \n",
       "1767             5.0             5.0           10.0   \n",
       "1768             4.0             4.0            8.0   \n",
       "1769             6.0             4.0           10.0   \n",
       "1770             4.0             5.0            9.0   \n",
       "1771             4.0             5.0            9.0   \n",
       "1772             6.0             5.0           11.0   \n",
       "1773             3.0             2.0            5.0   \n",
       "1774             5.0             5.0           10.0   \n",
       "1775             5.0             4.0            9.0   \n",
       "1776             5.0             5.0           10.0   \n",
       "1777             4.0             4.0            8.0   \n",
       "1778             4.0             4.0            8.0   \n",
       "1779             3.0             4.0            7.0   \n",
       "1780             4.0             4.0            8.0   \n",
       "1781             1.0             1.0            2.0   \n",
       "1782             4.0             3.0            7.0   \n",
       "\n",
       "                                                 prompt has_source_material  \\\n",
       "0     More and more people use computers, but not ev...                   0   \n",
       "1     More and more people use computers, but not ev...                   0   \n",
       "2     More and more people use computers, but not ev...                   0   \n",
       "3     More and more people use computers, but not ev...                   0   \n",
       "4     More and more people use computers, but not ev...                   0   \n",
       "5     More and more people use computers, but not ev...                   0   \n",
       "6     More and more people use computers, but not ev...                   0   \n",
       "7     More and more people use computers, but not ev...                   0   \n",
       "8     More and more people use computers, but not ev...                   0   \n",
       "9     More and more people use computers, but not ev...                   0   \n",
       "10    More and more people use computers, but not ev...                   0   \n",
       "11    More and more people use computers, but not ev...                   0   \n",
       "12    More and more people use computers, but not ev...                   0   \n",
       "13    More and more people use computers, but not ev...                   0   \n",
       "14    More and more people use computers, but not ev...                   0   \n",
       "15    More and more people use computers, but not ev...                   0   \n",
       "16    More and more people use computers, but not ev...                   0   \n",
       "17    More and more people use computers, but not ev...                   0   \n",
       "18    More and more people use computers, but not ev...                   0   \n",
       "19    More and more people use computers, but not ev...                   0   \n",
       "20    More and more people use computers, but not ev...                   0   \n",
       "21    More and more people use computers, but not ev...                   0   \n",
       "22    More and more people use computers, but not ev...                   0   \n",
       "23    More and more people use computers, but not ev...                   0   \n",
       "24    More and more people use computers, but not ev...                   0   \n",
       "25    More and more people use computers, but not ev...                   0   \n",
       "26    More and more people use computers, but not ev...                   0   \n",
       "27    More and more people use computers, but not ev...                   0   \n",
       "28    More and more people use computers, but not ev...                   0   \n",
       "29    More and more people use computers, but not ev...                   0   \n",
       "...                                                 ...                 ...   \n",
       "1753  More and more people use computers, but not ev...                   0   \n",
       "1754  More and more people use computers, but not ev...                   0   \n",
       "1755  More and more people use computers, but not ev...                   0   \n",
       "1756  More and more people use computers, but not ev...                   0   \n",
       "1757  More and more people use computers, but not ev...                   0   \n",
       "1758  More and more people use computers, but not ev...                   0   \n",
       "1759  More and more people use computers, but not ev...                   0   \n",
       "1760  More and more people use computers, but not ev...                   0   \n",
       "1761  More and more people use computers, but not ev...                   0   \n",
       "1762  More and more people use computers, but not ev...                   0   \n",
       "1763  More and more people use computers, but not ev...                   0   \n",
       "1764  More and more people use computers, but not ev...                   0   \n",
       "1765  More and more people use computers, but not ev...                   0   \n",
       "1766  More and more people use computers, but not ev...                   0   \n",
       "1767  More and more people use computers, but not ev...                   0   \n",
       "1768  More and more people use computers, but not ev...                   0   \n",
       "1769  More and more people use computers, but not ev...                   0   \n",
       "1770  More and more people use computers, but not ev...                   0   \n",
       "1771  More and more people use computers, but not ev...                   0   \n",
       "1772  More and more people use computers, but not ev...                   0   \n",
       "1773  More and more people use computers, but not ev...                   0   \n",
       "1774  More and more people use computers, but not ev...                   0   \n",
       "1775  More and more people use computers, but not ev...                   0   \n",
       "1776  More and more people use computers, but not ev...                   0   \n",
       "1777  More and more people use computers, but not ev...                   0   \n",
       "1778  More and more people use computers, but not ev...                   0   \n",
       "1779  More and more people use computers, but not ev...                   0   \n",
       "1780  More and more people use computers, but not ev...                   0   \n",
       "1781  More and more people use computers, but not ev...                   0   \n",
       "1782  More and more people use computers, but not ev...                   0   \n",
       "\n",
       "     grade_7 grade_8 grade_10 bad_if_kids_spend_too_much_time  \\\n",
       "0          0       1        0                               0   \n",
       "1          0       1        0                           0.108   \n",
       "2          0       1        0                           0.407   \n",
       "3          0       1        0                               0   \n",
       "4          0       1        0                           0.527   \n",
       "5          0       1        0                               0   \n",
       "6          0       1        0                               0   \n",
       "7          0       1        0                               0   \n",
       "8          0       1        0                               0   \n",
       "9          0       1        0                           0.992   \n",
       "10         0       1        0                               0   \n",
       "11         0       1        0                           0.988   \n",
       "12         0       1        0                           0.977   \n",
       "13         0       1        0                           0.579   \n",
       "14         0       1        0                           0.579   \n",
       "15         0       1        0                               0   \n",
       "16         0       1        0                           0.984   \n",
       "17         0       1        0                           0.175   \n",
       "18         0       1        0                           0.069   \n",
       "19         0       1        0                               0   \n",
       "20         0       1        0                           0.204   \n",
       "21         0       1        0                           0.017   \n",
       "22         0       1        0                           0.264   \n",
       "23         0       1        0                               0   \n",
       "24         0       1        0                           0.706   \n",
       "25         0       1        0                           0.936   \n",
       "26         0       1        0                           0.964   \n",
       "27         0       1        0                           0.366   \n",
       "28         0       1        0                           0.023   \n",
       "29         0       1        0                           0.989   \n",
       "...      ...     ...      ...                             ...   \n",
       "1753       0       1        0                           0.492   \n",
       "1754       0       1        0                               0   \n",
       "1755       0       1        0                           0.433   \n",
       "1756       0       1        0                           0.517   \n",
       "1757       0       1        0                           0.596   \n",
       "1758       0       1        0                               0   \n",
       "1759       0       1        0                           0.525   \n",
       "1760       0       1        0                            0.01   \n",
       "1761       0       1        0                               0   \n",
       "1762       0       1        0                               0   \n",
       "1763       0       1        0                           0.669   \n",
       "1764       0       1        0                               0   \n",
       "1765       0       1        0                               0   \n",
       "1766       0       1        0                           0.937   \n",
       "1767       0       1        0                               0   \n",
       "1768       0       1        0                               0   \n",
       "1769       0       1        0                               0   \n",
       "1770       0       1        0                           0.353   \n",
       "1771       0       1        0                           0.373   \n",
       "1772       0       1        0                           0.346   \n",
       "1773       0       1        0                            0.91   \n",
       "1774       0       1        0                           0.723   \n",
       "1775       0       1        0                           0.036   \n",
       "1776       0       1        0                            0.27   \n",
       "1777       0       1        0                           0.151   \n",
       "1778       0       1        0                           0.065   \n",
       "1779       0       1        0                           0.734   \n",
       "1780       0       1        0                           0.543   \n",
       "1781       0       1        0                           0.727   \n",
       "1782       0       1        0                           0.979   \n",
       "\n",
       "      doesnt_have_the_negative_exercise_effect  games_and_information  \\\n",
       "0                                        0.562                  0.149   \n",
       "1                                        0.000                  0.000   \n",
       "2                                        0.000                  0.000   \n",
       "3                                        0.019                  0.172   \n",
       "4                                        0.233                  0.051   \n",
       "5                                        0.055                  0.000   \n",
       "6                                        0.011                  0.000   \n",
       "7                                        0.000                  0.010   \n",
       "8                                        0.000                  0.000   \n",
       "9                                        0.000                  0.000   \n",
       "10                                       0.989                  0.000   \n",
       "11                                       0.000                  0.000   \n",
       "12                                       0.000                  0.000   \n",
       "13                                       0.000                  0.000   \n",
       "14                                       0.000                  0.406   \n",
       "15                                       0.000                  0.903   \n",
       "16                                       0.000                  0.000   \n",
       "17                                       0.531                  0.061   \n",
       "18                                       0.069                  0.068   \n",
       "19                                       0.000                  0.977   \n",
       "20                                       0.536                  0.087   \n",
       "21                                       0.017                  0.931   \n",
       "22                                       0.731                  0.000   \n",
       "23                                       0.035                  0.509   \n",
       "24                                       0.285                  0.000   \n",
       "25                                       0.000                  0.000   \n",
       "26                                       0.000                  0.000   \n",
       "27                                       0.000                  0.000   \n",
       "28                                       0.000                  0.014   \n",
       "29                                       0.000                  0.000   \n",
       "...                                        ...                    ...   \n",
       "1753                                     0.000                  0.000   \n",
       "1754                                     0.000                  0.175   \n",
       "1755                                     0.440                  0.000   \n",
       "1756                                     0.293                  0.159   \n",
       "1757                                     0.000                  0.393   \n",
       "1758                                     0.000                  0.000   \n",
       "1759                                     0.467                  0.000   \n",
       "1760                                     0.010                  0.010   \n",
       "1761                                     0.000                  0.410   \n",
       "1762                                     0.116                  0.873   \n",
       "1763                                     0.323                  0.000   \n",
       "1764                                     0.087                  0.023   \n",
       "1765                                     0.000                  0.000   \n",
       "1766                                     0.000                  0.000   \n",
       "1767                                     0.670                  0.000   \n",
       "1768                                     0.000                  0.000   \n",
       "1769                                     0.000                  0.124   \n",
       "1770                                     0.000                  0.000   \n",
       "1771                                     0.000                  0.000   \n",
       "1772                                     0.554                  0.000   \n",
       "1773                                     0.065                  0.000   \n",
       "1774                                     0.000                  0.000   \n",
       "1775                                     0.033                  0.000   \n",
       "1776                                     0.590                  0.065   \n",
       "1777                                     0.842                  0.000   \n",
       "1778                                     0.929                  0.000   \n",
       "1779                                     0.000                  0.000   \n",
       "1780                                     0.000                  0.000   \n",
       "1781                                     0.068                  0.068   \n",
       "1782                                     0.000                  0.000   \n",
       "\n",
       "      looking_at_websites_for_info  spend_time_looking_on_websites  \n",
       "0                            0.269                           0.018  \n",
       "1                            0.885                           0.000  \n",
       "2                            0.000                           0.581  \n",
       "3                            0.806                           0.000  \n",
       "4                            0.187                           0.000  \n",
       "5                            0.000                           0.931  \n",
       "6                            0.978                           0.000  \n",
       "7                            0.980                           0.000  \n",
       "8                            0.343                           0.651  \n",
       "9                            0.000                           0.000  \n",
       "10                           0.000                           0.000  \n",
       "11                           0.000                           0.000  \n",
       "12                           0.000                           0.000  \n",
       "13                           0.000                           0.413  \n",
       "14                           0.000                           0.000  \n",
       "15                           0.092                           0.000  \n",
       "16                           0.000                           0.000  \n",
       "17                           0.000                           0.230  \n",
       "18                           0.068                           0.726  \n",
       "19                           0.000                           0.000  \n",
       "20                           0.170                           0.000  \n",
       "21                           0.017                           0.017  \n",
       "22                           0.000                           0.000  \n",
       "23                           0.452                           0.000  \n",
       "24                           0.000                           0.000  \n",
       "25                           0.022                           0.036  \n",
       "26                           0.000                           0.000  \n",
       "27                           0.000                           0.628  \n",
       "28                           0.943                           0.018  \n",
       "29                           0.000                           0.000  \n",
       "...                            ...                             ...  \n",
       "1753                         0.000                           0.503  \n",
       "1754                         0.818                           0.000  \n",
       "1755                         0.092                           0.031  \n",
       "1756                         0.000                           0.029  \n",
       "1757                         0.000                           0.000  \n",
       "1758                         0.994                           0.000  \n",
       "1759                         0.000                           0.000  \n",
       "1760                         0.010                           0.959  \n",
       "1761                         0.581                           0.000  \n",
       "1762                         0.000                           0.000  \n",
       "1763                         0.000                           0.000  \n",
       "1764                         0.000                           0.883  \n",
       "1765                         0.528                           0.464  \n",
       "1766                         0.057                           0.000  \n",
       "1767                         0.000                           0.325  \n",
       "1768                         0.977                           0.013  \n",
       "1769                         0.869                           0.000  \n",
       "1770                         0.639                           0.000  \n",
       "1771                         0.619                           0.000  \n",
       "1772                         0.097                           0.000  \n",
       "1773                         0.000                           0.000  \n",
       "1774                         0.269                           0.000  \n",
       "1775                         0.741                           0.186  \n",
       "1776                         0.073                           0.000  \n",
       "1777                         0.000                           0.000  \n",
       "1778                         0.000                           0.000  \n",
       "1779                         0.000                           0.253  \n",
       "1780                         0.000                           0.444  \n",
       "1781                         0.069                           0.069  \n",
       "1782                         0.000                           0.000  \n",
       "\n",
       "[1783 rows x 16 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "\n",
    "    essays_with_topic_scores = process_topic_and_score_df(colNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prompt</th>\n",
       "      <th>has_source_material</th>\n",
       "      <th>grade_7</th>\n",
       "      <th>grade_8</th>\n",
       "      <th>grade_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1783</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 several reasons on way I t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1784</td>\n",
       "      <td>1</td>\n",
       "      <td>Do a adults and kids spend to much time on the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1785</td>\n",
       "      <td>1</td>\n",
       "      <td>My opinion is that people should have computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear readers, I think that its good and bad to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1787</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear - Local Newspaper I agree thats computers...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "1778      1783          1  Dear @CAPS1, @CAPS2 several reasons on way I t...   \n",
       "1779      1784          1  Do a adults and kids spend to much time on the...   \n",
       "1780      1785          1  My opinion is that people should have computer...   \n",
       "1781      1786          1  Dear readers, I think that its good and bad to...   \n",
       "1782      1787          1  Dear - Local Newspaper I agree thats computers...   \n",
       "\n",
       "      rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "1778             4.0             4.0            8.0   \n",
       "1779             3.0             4.0            7.0   \n",
       "1780             4.0             4.0            8.0   \n",
       "1781             1.0             1.0            2.0   \n",
       "1782             4.0             3.0            7.0   \n",
       "\n",
       "                                                 prompt  has_source_material  \\\n",
       "1778  More and more people use computers, but not ev...                    0   \n",
       "1779  More and more people use computers, but not ev...                    0   \n",
       "1780  More and more people use computers, but not ev...                    0   \n",
       "1781  More and more people use computers, but not ev...                    0   \n",
       "1782  More and more people use computers, but not ev...                    0   \n",
       "\n",
       "      grade_7  grade_8  grade_10  \n",
       "1778        0        1         0  \n",
       "1779        0        1         0  \n",
       "1780        0        1         0  \n",
       "1781        0        1         0  \n",
       "1782        0        1         0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# essays.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_with_topic_scores = essays_with_topic_scores.drop(['essay_set', 'essay', 'rater1_domain1', 'rater2_domain1', 'prompt', 'has_source_material', 'grade_7', 'grade_8', 'grade_10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_with_topic_scores.to_csv('../data/processed/essays_with_topic_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vector Embedding with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of *word vector embedding models*, or *word vector models* for short, is to learn dense, numerical vector representations for each term in a corpus vocabulary. If the model is successful, the vectors it learns about each term should encode some information about the *meaning* or *concept* the term represents, and the relationship between it and other terms in the vocabulary. Word vector models are also fully unsupervised &mdash; they learn all of these meanings and relationships solely by analyzing the text of the corpus, without any advance knowledge provided.\n",
    "\n",
    "Perhaps the best-known word vector model is [word2vec](https://arxiv.org/pdf/1301.3781v3.pdf), originally proposed in 2013. The general idea of word2vec is, for a given *focus word*, to use the *context* of the word &mdash; i.e., the other words immediately before and after it &mdash; to provide hints about what the focus word might mean. To do this, word2vec uses a *sliding window* technique, where it considers snippets of text only a few tokens long at a time.\n",
    "\n",
    "At the start of the learning process, the model initializes random vectors for all terms in the corpus vocabulary. The model then slides the window across every snippet of text in the corpus, with each word taking turns as the focus word. Each time the model considers a new snippet, it tries to learn some information about the focus word based on the surrouding context, and it \"nudges\" the words' vector representations accordingly. One complete pass sliding the window across all of the corpus text is known as a training *epoch*. It's common to train a word2vec model for multiple passes/epochs over the corpus. Over time, the model rearranges the terms' vector representations such that terms that frequently appear in similar contexts have vector representations that are *close* to each other in vector space.\n",
    "\n",
    "For a deeper dive into word2vec's machine learning process, see [here](https://arxiv.org/pdf/1411.2738v4.pdf).\n",
    "\n",
    "Word2vec has a number of user-defined hyperparameters, including:\n",
    "- The dimensionality of the vectors. Typical choices include a few dozen to several hundred.\n",
    "- The width of the sliding window, in tokens. Five is a common default choice, but narrower and wider windows are possible.\n",
    "- The number of training epochs.\n",
    "\n",
    "For using word2vec in Python, [gensim](https://rare-technologies.com/deep-learning-with-word2vec-and-gensim/) comes to the rescue again! It offers a [highly-optimized](https://rare-technologies.com/word2vec-in-python-part-two-optimizing/), [parallelized](https://rare-technologies.com/parallelizing-word2vec-in-python/) implementation of the word2vec algorithm with its [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "trigram_sentences = LineSentence(trigram_sentences_filepath)\n",
    "word2vec_filepath = os.path.join(intermediate_directory, 'word2vec_model_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train our word2vec model using the normalized sentences with our phrase models applied. We'll use 100-dimensional vectors, and set up our training process to run for twelve epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "\n",
    "# word2vec_filepath = os.path.join(intermediate_directory, 'word2vec_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 training epochs so far.\n",
      "CPU times: user 37.2 s, sys: 496 ms, total: 37.7 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to train the word2vec model yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "#     t = time()\n",
    "    # initiate the model and perform 15 epochs of training\n",
    "    # workers should be cores - 1\n",
    "    essay2vec_model = Word2Vec(min_count=20, window=5, size=100, sample=6e-5, alpha=0.03, min_alpha=0.0007, negative=20, workers=4)    \n",
    "    essay2vec_model.build_vocab(trigram_sentences)\n",
    "    \n",
    "    for i in range(6):\n",
    "        essay2vec_model.train(trigram_sentences, total_examples=essay2vec_model.corpus_count, epochs=15, report_delay=1)\n",
    "    \n",
    "    essay2vec_model.save(word2vec_filepath)\n",
    "\n",
    "        \n",
    "# load the finished model from disk\n",
    "essay2vec_model = Word2Vec.load(word2vec_filepath)\n",
    "essay2vec_model.init_sims()\n",
    "\n",
    "print('{} training epochs so far.'.format(essay2vec_model.train_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,250 terms in the essay2vec vocabulary.\n"
     ]
    }
   ],
   "source": [
    "print('{:,} terms in the essay2vec vocabulary.'.format(len(essay2vec_model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at the word vectors our model has learned. We'll create a pandas DataFrame with the terms as the row labels, and the 100 dimensions of the word vector model as the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dear_Local_Newspaper</th>\n",
       "      <td>-0.080966</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.160840</td>\n",
       "      <td>0.153978</td>\n",
       "      <td>-0.150762</td>\n",
       "      <td>-0.227000</td>\n",
       "      <td>-0.119609</td>\n",
       "      <td>0.028311</td>\n",
       "      <td>0.119844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083057</td>\n",
       "      <td>-0.036303</td>\n",
       "      <td>-0.172746</td>\n",
       "      <td>0.107085</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>-0.054023</td>\n",
       "      <td>-0.026584</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.089317</td>\n",
       "      <td>-0.006336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dear_Newspaper</th>\n",
       "      <td>-0.160894</td>\n",
       "      <td>-0.078554</td>\n",
       "      <td>-0.005497</td>\n",
       "      <td>0.128657</td>\n",
       "      <td>0.114997</td>\n",
       "      <td>-0.129569</td>\n",
       "      <td>-0.273821</td>\n",
       "      <td>-0.217280</td>\n",
       "      <td>-0.019305</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131236</td>\n",
       "      <td>-0.100623</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>-0.025299</td>\n",
       "      <td>0.176573</td>\n",
       "      <td>-0.096566</td>\n",
       "      <td>-0.069011</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.033215</td>\n",
       "      <td>0.079021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr.</th>\n",
       "      <td>-0.048280</td>\n",
       "      <td>0.085749</td>\n",
       "      <td>-0.078311</td>\n",
       "      <td>-0.077604</td>\n",
       "      <td>0.105933</td>\n",
       "      <td>0.043426</td>\n",
       "      <td>-0.245606</td>\n",
       "      <td>-0.125072</td>\n",
       "      <td>0.157281</td>\n",
       "      <td>0.109850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042051</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>-0.073568</td>\n",
       "      <td>0.167597</td>\n",
       "      <td>-0.038416</td>\n",
       "      <td>0.056799</td>\n",
       "      <td>0.049680</td>\n",
       "      <td>0.022879</td>\n",
       "      <td>-0.012547</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook</th>\n",
       "      <td>0.160234</td>\n",
       "      <td>0.161505</td>\n",
       "      <td>-0.004742</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.042157</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>-0.074445</td>\n",
       "      <td>0.072042</td>\n",
       "      <td>-0.013195</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045397</td>\n",
       "      <td>0.061529</td>\n",
       "      <td>-0.110230</td>\n",
       "      <td>-0.138034</td>\n",
       "      <td>-0.101535</td>\n",
       "      <td>0.122856</td>\n",
       "      <td>0.225491</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.037411</td>\n",
       "      <td>-0.037007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>-0.054791</td>\n",
       "      <td>0.059666</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>-0.049464</td>\n",
       "      <td>0.207019</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.076224</td>\n",
       "      <td>-0.133590</td>\n",
       "      <td>-0.162718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117228</td>\n",
       "      <td>-0.056509</td>\n",
       "      <td>-0.127031</td>\n",
       "      <td>-0.096924</td>\n",
       "      <td>0.016651</td>\n",
       "      <td>-0.033707</td>\n",
       "      <td>-0.080514</td>\n",
       "      <td>-0.129022</td>\n",
       "      <td>0.033612</td>\n",
       "      <td>-0.022756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.061915</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>0.038366</td>\n",
       "      <td>0.046556</td>\n",
       "      <td>-0.055796</td>\n",
       "      <td>-0.045085</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>-0.175662</td>\n",
       "      <td>-0.038806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113731</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>0.111721</td>\n",
       "      <td>-0.185697</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.260463</td>\n",
       "      <td>0.133326</td>\n",
       "      <td>-0.022905</td>\n",
       "      <td>0.135234</td>\n",
       "      <td>-0.020684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability_learn</th>\n",
       "      <td>0.078620</td>\n",
       "      <td>-0.060835</td>\n",
       "      <td>0.106955</td>\n",
       "      <td>-0.152974</td>\n",
       "      <td>0.055909</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>-0.215835</td>\n",
       "      <td>-0.024729</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>-0.039019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200842</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>-0.149448</td>\n",
       "      <td>-0.010260</td>\n",
       "      <td>-0.103228</td>\n",
       "      <td>0.045211</td>\n",
       "      <td>0.028685</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>0.066922</td>\n",
       "      <td>0.105161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability_learn_far_away</th>\n",
       "      <td>0.068378</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>0.083156</td>\n",
       "      <td>-0.106033</td>\n",
       "      <td>0.218467</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>-0.183279</td>\n",
       "      <td>-0.111118</td>\n",
       "      <td>-0.029186</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214203</td>\n",
       "      <td>-0.048395</td>\n",
       "      <td>-0.052231</td>\n",
       "      <td>-0.211182</td>\n",
       "      <td>-0.067038</td>\n",
       "      <td>-0.046495</td>\n",
       "      <td>-0.022695</td>\n",
       "      <td>-0.043916</td>\n",
       "      <td>-0.026545</td>\n",
       "      <td>0.121319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability_learn_faraway_place</th>\n",
       "      <td>-0.043237</td>\n",
       "      <td>-0.050755</td>\n",
       "      <td>0.093305</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.205478</td>\n",
       "      <td>-0.025085</td>\n",
       "      <td>-0.212736</td>\n",
       "      <td>-0.158275</td>\n",
       "      <td>-0.032956</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275119</td>\n",
       "      <td>-0.010331</td>\n",
       "      <td>-0.027732</td>\n",
       "      <td>-0.158186</td>\n",
       "      <td>-0.004436</td>\n",
       "      <td>-0.042032</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>-0.012597</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.114431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.023570</td>\n",
       "      <td>-0.053252</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>-0.085435</td>\n",
       "      <td>0.164259</td>\n",
       "      <td>-0.058869</td>\n",
       "      <td>0.080843</td>\n",
       "      <td>0.106354</td>\n",
       "      <td>-0.153176</td>\n",
       "      <td>-0.034961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>-0.001847</td>\n",
       "      <td>-0.063932</td>\n",
       "      <td>-0.096556</td>\n",
       "      <td>-0.110397</td>\n",
       "      <td>0.145599</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>-0.044561</td>\n",
       "      <td>0.179839</td>\n",
       "      <td>-0.101470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>0.009471</td>\n",
       "      <td>-0.037858</td>\n",
       "      <td>0.118418</td>\n",
       "      <td>0.268994</td>\n",
       "      <td>0.313056</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>-0.136287</td>\n",
       "      <td>-0.139082</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134323</td>\n",
       "      <td>-0.086783</td>\n",
       "      <td>-0.121617</td>\n",
       "      <td>-0.086920</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.044351</td>\n",
       "      <td>-0.079989</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>-0.135252</td>\n",
       "      <td>-0.084513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>-0.060129</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>0.098544</td>\n",
       "      <td>0.117001</td>\n",
       "      <td>0.130719</td>\n",
       "      <td>0.050971</td>\n",
       "      <td>0.028348</td>\n",
       "      <td>-0.110445</td>\n",
       "      <td>-0.042671</td>\n",
       "      <td>0.020960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>-0.028911</td>\n",
       "      <td>-0.187556</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>-0.081402</td>\n",
       "      <td>-0.078189</td>\n",
       "      <td>-0.054812</td>\n",
       "      <td>-0.072359</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.008121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>-0.016774</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>-0.144403</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-0.151972</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>-0.021094</td>\n",
       "      <td>-0.106052</td>\n",
       "      <td>-0.072616</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138290</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>-0.109659</td>\n",
       "      <td>-0.086719</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.038707</td>\n",
       "      <td>0.214862</td>\n",
       "      <td>0.108611</td>\n",
       "      <td>-0.051788</td>\n",
       "      <td>-0.025838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accord</th>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>-0.031065</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>0.164677</td>\n",
       "      <td>0.130134</td>\n",
       "      <td>-0.074918</td>\n",
       "      <td>-0.004850</td>\n",
       "      <td>0.192992</td>\n",
       "      <td>0.155685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>-0.012145</td>\n",
       "      <td>-0.067884</td>\n",
       "      <td>-0.066159</td>\n",
       "      <td>-0.064794</td>\n",
       "      <td>0.077432</td>\n",
       "      <td>0.110461</td>\n",
       "      <td>-0.009767</td>\n",
       "      <td>-0.051933</td>\n",
       "      <td>0.118402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>-0.034982</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>-0.047256</td>\n",
       "      <td>-0.047565</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>-0.015990</td>\n",
       "      <td>-0.091662</td>\n",
       "      <td>0.074502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081644</td>\n",
       "      <td>-0.045451</td>\n",
       "      <td>-0.062248</td>\n",
       "      <td>-0.130844</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.045767</td>\n",
       "      <td>0.112684</td>\n",
       "      <td>0.020622</td>\n",
       "      <td>-0.031739</td>\n",
       "      <td>-0.023910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accurate</th>\n",
       "      <td>0.086073</td>\n",
       "      <td>-0.032643</td>\n",
       "      <td>0.139284</td>\n",
       "      <td>0.028096</td>\n",
       "      <td>-0.101803</td>\n",
       "      <td>-0.074570</td>\n",
       "      <td>-0.103560</td>\n",
       "      <td>0.101796</td>\n",
       "      <td>-0.118272</td>\n",
       "      <td>-0.060125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>-0.004177</td>\n",
       "      <td>-0.047235</td>\n",
       "      <td>0.125650</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>0.088164</td>\n",
       "      <td>0.177889</td>\n",
       "      <td>-0.017273</td>\n",
       "      <td>-0.106321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acess</th>\n",
       "      <td>0.080051</td>\n",
       "      <td>-0.026162</td>\n",
       "      <td>-0.011615</td>\n",
       "      <td>-0.231321</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.039610</td>\n",
       "      <td>-0.229335</td>\n",
       "      <td>-0.029583</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139043</td>\n",
       "      <td>0.123306</td>\n",
       "      <td>-0.073263</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.102984</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>-0.032433</td>\n",
       "      <td>-0.082574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>-0.249494</td>\n",
       "      <td>0.017735</td>\n",
       "      <td>-0.168136</td>\n",
       "      <td>0.125373</td>\n",
       "      <td>0.117684</td>\n",
       "      <td>0.136604</td>\n",
       "      <td>0.054115</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>0.041054</td>\n",
       "      <td>-0.051953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067933</td>\n",
       "      <td>0.086227</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>0.093552</td>\n",
       "      <td>0.140933</td>\n",
       "      <td>-0.012769</td>\n",
       "      <td>-0.014208</td>\n",
       "      <td>-0.048643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>-0.099725</td>\n",
       "      <td>0.280859</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>0.055052</td>\n",
       "      <td>0.066803</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>-0.038965</td>\n",
       "      <td>-0.197699</td>\n",
       "      <td>0.072265</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143444</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>-0.052328</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.018039</td>\n",
       "      <td>-0.082166</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.064940</td>\n",
       "      <td>0.072419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.124149</td>\n",
       "      <td>-0.012404</td>\n",
       "      <td>0.076643</td>\n",
       "      <td>0.300641</td>\n",
       "      <td>0.060930</td>\n",
       "      <td>0.082660</td>\n",
       "      <td>-0.099111</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>0.088329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025298</td>\n",
       "      <td>-0.188665</td>\n",
       "      <td>-0.017035</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>-0.121720</td>\n",
       "      <td>-0.019516</td>\n",
       "      <td>-0.057793</td>\n",
       "      <td>-0.134708</td>\n",
       "      <td>-0.021576</td>\n",
       "      <td>0.065409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activity</th>\n",
       "      <td>-0.014207</td>\n",
       "      <td>-0.051895</td>\n",
       "      <td>-0.065365</td>\n",
       "      <td>0.077290</td>\n",
       "      <td>0.242847</td>\n",
       "      <td>-0.060283</td>\n",
       "      <td>-0.081119</td>\n",
       "      <td>-0.153714</td>\n",
       "      <td>-0.105502</td>\n",
       "      <td>0.068179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088216</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.063110</td>\n",
       "      <td>-0.042854</td>\n",
       "      <td>-0.248585</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.140672</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>-0.057184</td>\n",
       "      <td>-0.010675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actually</th>\n",
       "      <td>-0.124487</td>\n",
       "      <td>0.123299</td>\n",
       "      <td>-0.047490</td>\n",
       "      <td>0.076760</td>\n",
       "      <td>0.122557</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>-0.086286</td>\n",
       "      <td>-0.007715</td>\n",
       "      <td>-0.100940</td>\n",
       "      <td>-0.014237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090606</td>\n",
       "      <td>-0.065074</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.023920</td>\n",
       "      <td>0.155269</td>\n",
       "      <td>0.134975</td>\n",
       "      <td>0.084377</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>-0.051784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad</th>\n",
       "      <td>-0.052581</td>\n",
       "      <td>0.090988</td>\n",
       "      <td>0.119070</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.055564</td>\n",
       "      <td>0.043385</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>-0.114068</td>\n",
       "      <td>0.162840</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065438</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.056090</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>-0.053827</td>\n",
       "      <td>-0.055392</td>\n",
       "      <td>0.041043</td>\n",
       "      <td>0.039948</td>\n",
       "      <td>-0.047681</td>\n",
       "      <td>-0.048392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add</th>\n",
       "      <td>-0.185433</td>\n",
       "      <td>-0.083624</td>\n",
       "      <td>-0.036671</td>\n",
       "      <td>-0.040051</td>\n",
       "      <td>0.042287</td>\n",
       "      <td>0.065492</td>\n",
       "      <td>-0.015215</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>-0.114772</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004022</td>\n",
       "      <td>-0.200743</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.147879</td>\n",
       "      <td>-0.054279</td>\n",
       "      <td>0.063821</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>0.072677</td>\n",
       "      <td>-0.126859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addict</th>\n",
       "      <td>-0.022299</td>\n",
       "      <td>0.191387</td>\n",
       "      <td>-0.074030</td>\n",
       "      <td>-0.055573</td>\n",
       "      <td>0.310384</td>\n",
       "      <td>0.063680</td>\n",
       "      <td>-0.085369</td>\n",
       "      <td>-0.100936</td>\n",
       "      <td>0.161640</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189984</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>-0.100763</td>\n",
       "      <td>0.062804</td>\n",
       "      <td>-0.072491</td>\n",
       "      <td>-0.054097</td>\n",
       "      <td>-0.050763</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.021930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addicted</th>\n",
       "      <td>-0.180987</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>-0.209175</td>\n",
       "      <td>0.048430</td>\n",
       "      <td>0.220865</td>\n",
       "      <td>-0.021063</td>\n",
       "      <td>-0.116353</td>\n",
       "      <td>-0.085872</td>\n",
       "      <td>-0.082910</td>\n",
       "      <td>-0.066901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121385</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>-0.041007</td>\n",
       "      <td>0.033138</td>\n",
       "      <td>-0.053710</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>-0.151991</td>\n",
       "      <td>-0.012026</td>\n",
       "      <td>-0.053500</td>\n",
       "      <td>0.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addicting</th>\n",
       "      <td>0.124235</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.060788</td>\n",
       "      <td>0.151284</td>\n",
       "      <td>0.075862</td>\n",
       "      <td>-0.154718</td>\n",
       "      <td>-0.115967</td>\n",
       "      <td>-0.035943</td>\n",
       "      <td>0.065051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020696</td>\n",
       "      <td>0.044556</td>\n",
       "      <td>-0.041164</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>-0.120047</td>\n",
       "      <td>0.072648</td>\n",
       "      <td>-0.037826</td>\n",
       "      <td>0.137466</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>-0.072847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addiction</th>\n",
       "      <td>-0.041202</td>\n",
       "      <td>0.211525</td>\n",
       "      <td>-0.219157</td>\n",
       "      <td>0.047944</td>\n",
       "      <td>0.194943</td>\n",
       "      <td>-0.022224</td>\n",
       "      <td>-0.121570</td>\n",
       "      <td>-0.164046</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180623</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>-0.135802</td>\n",
       "      <td>-0.037686</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>-0.016029</td>\n",
       "      <td>-0.183707</td>\n",
       "      <td>0.182267</td>\n",
       "      <td>-0.015915</td>\n",
       "      <td>0.002725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addictive</th>\n",
       "      <td>-0.135284</td>\n",
       "      <td>0.265247</td>\n",
       "      <td>-0.142602</td>\n",
       "      <td>0.277454</td>\n",
       "      <td>0.203590</td>\n",
       "      <td>0.044446</td>\n",
       "      <td>-0.005216</td>\n",
       "      <td>-0.042800</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>0.108935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034896</td>\n",
       "      <td>-0.014617</td>\n",
       "      <td>-0.072891</td>\n",
       "      <td>-0.068128</td>\n",
       "      <td>-0.142953</td>\n",
       "      <td>-0.042299</td>\n",
       "      <td>-0.033439</td>\n",
       "      <td>0.133010</td>\n",
       "      <td>-0.002407</td>\n",
       "      <td>0.158381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addition</th>\n",
       "      <td>0.067104</td>\n",
       "      <td>0.186199</td>\n",
       "      <td>-0.142296</td>\n",
       "      <td>0.034541</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.023728</td>\n",
       "      <td>-0.247746</td>\n",
       "      <td>-0.159316</td>\n",
       "      <td>-0.016654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006716</td>\n",
       "      <td>-0.130061</td>\n",
       "      <td>0.046863</td>\n",
       "      <td>0.101913</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.054943</td>\n",
       "      <td>0.125698</td>\n",
       "      <td>0.100385</td>\n",
       "      <td>0.147561</td>\n",
       "      <td>-0.031337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will</th>\n",
       "      <td>-0.210274</td>\n",
       "      <td>0.107353</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>0.136388</td>\n",
       "      <td>0.195531</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>0.076249</td>\n",
       "      <td>0.109844</td>\n",
       "      <td>-0.016581</td>\n",
       "      <td>-0.047279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108592</td>\n",
       "      <td>0.088655</td>\n",
       "      <td>-0.043294</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>-0.045943</td>\n",
       "      <td>-0.083427</td>\n",
       "      <td>-0.278405</td>\n",
       "      <td>-0.181813</td>\n",
       "      <td>0.149525</td>\n",
       "      <td>0.186288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will_not</th>\n",
       "      <td>-0.129235</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.126605</td>\n",
       "      <td>0.071264</td>\n",
       "      <td>0.038460</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.035405</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>-0.108512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039451</td>\n",
       "      <td>0.173878</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.006654</td>\n",
       "      <td>-0.099778</td>\n",
       "      <td>-0.146238</td>\n",
       "      <td>-0.187370</td>\n",
       "      <td>-0.020311</td>\n",
       "      <td>-0.008023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td>-0.065997</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>-0.128991</td>\n",
       "      <td>0.104487</td>\n",
       "      <td>0.201266</td>\n",
       "      <td>-0.089693</td>\n",
       "      <td>0.198117</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057563</td>\n",
       "      <td>0.220913</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>-0.068581</td>\n",
       "      <td>-0.105390</td>\n",
       "      <td>-0.068331</td>\n",
       "      <td>0.083326</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>-0.045385</td>\n",
       "      <td>-0.174301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <td>-0.124794</td>\n",
       "      <td>0.047326</td>\n",
       "      <td>-0.135098</td>\n",
       "      <td>0.049944</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>-0.024452</td>\n",
       "      <td>0.082130</td>\n",
       "      <td>0.103574</td>\n",
       "      <td>-0.065450</td>\n",
       "      <td>-0.160271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157480</td>\n",
       "      <td>0.075503</td>\n",
       "      <td>0.128558</td>\n",
       "      <td>-0.207491</td>\n",
       "      <td>0.143063</td>\n",
       "      <td>0.048720</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>0.151653</td>\n",
       "      <td>0.118451</td>\n",
       "      <td>-0.048937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>0.157742</td>\n",
       "      <td>0.211656</td>\n",
       "      <td>0.020748</td>\n",
       "      <td>-0.136406</td>\n",
       "      <td>0.062554</td>\n",
       "      <td>0.185311</td>\n",
       "      <td>0.095738</td>\n",
       "      <td>0.090334</td>\n",
       "      <td>-0.082855</td>\n",
       "      <td>-0.145515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046139</td>\n",
       "      <td>0.137625</td>\n",
       "      <td>-0.134025</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>-0.032358</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>0.100498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonder</th>\n",
       "      <td>-0.036164</td>\n",
       "      <td>0.063715</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.248363</td>\n",
       "      <td>-0.063726</td>\n",
       "      <td>-0.038604</td>\n",
       "      <td>0.141808</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>-0.121845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006780</td>\n",
       "      <td>0.145184</td>\n",
       "      <td>0.071114</td>\n",
       "      <td>0.042687</td>\n",
       "      <td>0.111052</td>\n",
       "      <td>-0.197036</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.042903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>0.200375</td>\n",
       "      <td>0.110637</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>-0.036366</td>\n",
       "      <td>-0.035389</td>\n",
       "      <td>-0.121819</td>\n",
       "      <td>-0.019157</td>\n",
       "      <td>0.108040</td>\n",
       "      <td>-0.199105</td>\n",
       "      <td>-0.103509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032440</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>-0.063284</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>-0.083893</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.029312</td>\n",
       "      <td>0.077423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>-0.045878</td>\n",
       "      <td>-0.054326</td>\n",
       "      <td>0.106562</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>-0.076788</td>\n",
       "      <td>0.055572</td>\n",
       "      <td>-0.094184</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>0.172067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037526</td>\n",
       "      <td>-0.045535</td>\n",
       "      <td>0.082279</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>-0.041055</td>\n",
       "      <td>0.293838</td>\n",
       "      <td>-0.082126</td>\n",
       "      <td>-0.001794</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>-0.033845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>-0.116637</td>\n",
       "      <td>-0.073446</td>\n",
       "      <td>-0.211282</td>\n",
       "      <td>-0.112790</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>0.166608</td>\n",
       "      <td>-0.013387</td>\n",
       "      <td>-0.154851</td>\n",
       "      <td>-0.034203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>-0.172235</td>\n",
       "      <td>-0.083438</td>\n",
       "      <td>-0.119303</td>\n",
       "      <td>-0.044952</td>\n",
       "      <td>0.023880</td>\n",
       "      <td>-0.010212</td>\n",
       "      <td>-0.037849</td>\n",
       "      <td>-0.073563</td>\n",
       "      <td>-0.151407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker</th>\n",
       "      <td>-0.022504</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.090817</td>\n",
       "      <td>-0.057094</td>\n",
       "      <td>-0.108500</td>\n",
       "      <td>0.057872</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>-0.098129</td>\n",
       "      <td>0.028791</td>\n",
       "      <td>-0.088584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002502</td>\n",
       "      <td>-0.220155</td>\n",
       "      <td>-0.013423</td>\n",
       "      <td>-0.171200</td>\n",
       "      <td>0.163627</td>\n",
       "      <td>0.041264</td>\n",
       "      <td>0.070564</td>\n",
       "      <td>-0.101153</td>\n",
       "      <td>-0.005687</td>\n",
       "      <td>0.089583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>-0.031874</td>\n",
       "      <td>0.139463</td>\n",
       "      <td>-0.143214</td>\n",
       "      <td>-0.134749</td>\n",
       "      <td>-0.035267</td>\n",
       "      <td>-0.100296</td>\n",
       "      <td>-0.087241</td>\n",
       "      <td>0.060740</td>\n",
       "      <td>-0.058429</td>\n",
       "      <td>-0.146486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228013</td>\n",
       "      <td>-0.096753</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>-0.044096</td>\n",
       "      <td>0.204079</td>\n",
       "      <td>-0.045788</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>-0.024602</td>\n",
       "      <td>-0.044594</td>\n",
       "      <td>0.056458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worried</th>\n",
       "      <td>-0.149530</td>\n",
       "      <td>0.066812</td>\n",
       "      <td>-0.116020</td>\n",
       "      <td>0.057878</td>\n",
       "      <td>0.186423</td>\n",
       "      <td>0.031979</td>\n",
       "      <td>-0.065942</td>\n",
       "      <td>-0.130018</td>\n",
       "      <td>-0.005233</td>\n",
       "      <td>-0.087113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092626</td>\n",
       "      <td>-0.053344</td>\n",
       "      <td>-0.051258</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>-0.053174</td>\n",
       "      <td>-0.227502</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.035557</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.078444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worry</th>\n",
       "      <td>-0.115249</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>-0.144226</td>\n",
       "      <td>0.076544</td>\n",
       "      <td>0.149391</td>\n",
       "      <td>-0.062495</td>\n",
       "      <td>0.074391</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173196</td>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.086681</td>\n",
       "      <td>-0.016223</td>\n",
       "      <td>0.018278</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>-0.174869</td>\n",
       "      <td>0.051112</td>\n",
       "      <td>0.063893</td>\n",
       "      <td>0.095718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worth</th>\n",
       "      <td>0.066123</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>0.183848</td>\n",
       "      <td>-0.068840</td>\n",
       "      <td>0.141505</td>\n",
       "      <td>-0.098121</td>\n",
       "      <td>-0.058005</td>\n",
       "      <td>-0.064479</td>\n",
       "      <td>0.136190</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104596</td>\n",
       "      <td>0.087585</td>\n",
       "      <td>-0.104555</td>\n",
       "      <td>0.040626</td>\n",
       "      <td>0.083674</td>\n",
       "      <td>-0.016526</td>\n",
       "      <td>-0.317687</td>\n",
       "      <td>-0.199293</td>\n",
       "      <td>-0.058497</td>\n",
       "      <td>-0.112080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <td>-0.129512</td>\n",
       "      <td>-0.066839</td>\n",
       "      <td>-0.048920</td>\n",
       "      <td>0.171823</td>\n",
       "      <td>-0.177231</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>0.048246</td>\n",
       "      <td>-0.043790</td>\n",
       "      <td>0.162369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081206</td>\n",
       "      <td>-0.146629</td>\n",
       "      <td>0.106912</td>\n",
       "      <td>-0.111590</td>\n",
       "      <td>-0.037091</td>\n",
       "      <td>0.156758</td>\n",
       "      <td>-0.080771</td>\n",
       "      <td>-0.085659</td>\n",
       "      <td>0.063928</td>\n",
       "      <td>-0.056529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write_essay</th>\n",
       "      <td>-0.276980</td>\n",
       "      <td>-0.092888</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>-0.055676</td>\n",
       "      <td>-0.178226</td>\n",
       "      <td>0.107930</td>\n",
       "      <td>-0.072077</td>\n",
       "      <td>0.043175</td>\n",
       "      <td>-0.009157</td>\n",
       "      <td>0.241753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096314</td>\n",
       "      <td>-0.044447</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>-0.127319</td>\n",
       "      <td>-0.042781</td>\n",
       "      <td>0.205939</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.039154</td>\n",
       "      <td>0.167516</td>\n",
       "      <td>-0.085724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write_letter</th>\n",
       "      <td>-0.094048</td>\n",
       "      <td>-0.188189</td>\n",
       "      <td>0.183612</td>\n",
       "      <td>-0.083681</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>-0.073572</td>\n",
       "      <td>-0.097978</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.052986</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122145</td>\n",
       "      <td>-0.225296</td>\n",
       "      <td>-0.089557</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.155174</td>\n",
       "      <td>0.060816</td>\n",
       "      <td>-0.104516</td>\n",
       "      <td>0.033624</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>-0.053705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write_paper</th>\n",
       "      <td>-0.039994</td>\n",
       "      <td>-0.162954</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.183336</td>\n",
       "      <td>-0.065429</td>\n",
       "      <td>0.028342</td>\n",
       "      <td>-0.081525</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.197878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>-0.094506</td>\n",
       "      <td>0.112994</td>\n",
       "      <td>0.026295</td>\n",
       "      <td>-0.064076</td>\n",
       "      <td>0.253173</td>\n",
       "      <td>0.083666</td>\n",
       "      <td>-0.006361</td>\n",
       "      <td>0.068730</td>\n",
       "      <td>-0.072751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writing</th>\n",
       "      <td>0.003102</td>\n",
       "      <td>-0.065624</td>\n",
       "      <td>0.116759</td>\n",
       "      <td>0.221152</td>\n",
       "      <td>-0.092194</td>\n",
       "      <td>-0.004935</td>\n",
       "      <td>0.056955</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>0.036182</td>\n",
       "      <td>0.262661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052755</td>\n",
       "      <td>-0.107070</td>\n",
       "      <td>0.100780</td>\n",
       "      <td>-0.044422</td>\n",
       "      <td>-0.146656</td>\n",
       "      <td>0.136562</td>\n",
       "      <td>-0.155263</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.040746</td>\n",
       "      <td>-0.121560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong</th>\n",
       "      <td>-0.159924</td>\n",
       "      <td>-0.071432</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>0.063522</td>\n",
       "      <td>0.202766</td>\n",
       "      <td>-0.027204</td>\n",
       "      <td>-0.115663</td>\n",
       "      <td>-0.068590</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.168906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037976</td>\n",
       "      <td>0.031521</td>\n",
       "      <td>0.092895</td>\n",
       "      <td>0.315482</td>\n",
       "      <td>0.080589</td>\n",
       "      <td>-0.107264</td>\n",
       "      <td>0.047725</td>\n",
       "      <td>0.101677</td>\n",
       "      <td>-0.060642</td>\n",
       "      <td>0.067841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yahoo</th>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.078907</td>\n",
       "      <td>0.077289</td>\n",
       "      <td>0.124349</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>-0.077911</td>\n",
       "      <td>-0.201298</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080930</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.174040</td>\n",
       "      <td>0.058013</td>\n",
       "      <td>0.026157</td>\n",
       "      <td>0.105651</td>\n",
       "      <td>0.076351</td>\n",
       "      <td>0.092045</td>\n",
       "      <td>-0.025008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-0.084354</td>\n",
       "      <td>0.051403</td>\n",
       "      <td>-0.092265</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>0.095282</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>0.115821</td>\n",
       "      <td>0.102618</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016205</td>\n",
       "      <td>0.062934</td>\n",
       "      <td>-0.077875</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>-0.052626</td>\n",
       "      <td>0.079668</td>\n",
       "      <td>-0.189148</td>\n",
       "      <td>-0.176204</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>-0.014047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_ago</th>\n",
       "      <td>0.143823</td>\n",
       "      <td>0.146433</td>\n",
       "      <td>0.056964</td>\n",
       "      <td>-0.035602</td>\n",
       "      <td>0.032863</td>\n",
       "      <td>-0.061437</td>\n",
       "      <td>-0.182808</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>-0.046499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061817</td>\n",
       "      <td>0.123939</td>\n",
       "      <td>-0.093537</td>\n",
       "      <td>0.038132</td>\n",
       "      <td>-0.105527</td>\n",
       "      <td>-0.060461</td>\n",
       "      <td>0.151425</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>-0.035396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_old</th>\n",
       "      <td>-0.265906</td>\n",
       "      <td>0.137993</td>\n",
       "      <td>0.102887</td>\n",
       "      <td>-0.057300</td>\n",
       "      <td>0.240518</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.163350</td>\n",
       "      <td>0.102529</td>\n",
       "      <td>0.084942</td>\n",
       "      <td>-0.083565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021522</td>\n",
       "      <td>0.070995</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>-0.011797</td>\n",
       "      <td>-0.099303</td>\n",
       "      <td>-0.123955</td>\n",
       "      <td>-0.019513</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>-0.178045</td>\n",
       "      <td>0.006188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>-0.113401</td>\n",
       "      <td>-0.039949</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.141987</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>-0.221333</td>\n",
       "      <td>-0.167595</td>\n",
       "      <td>-0.077956</td>\n",
       "      <td>-0.124617</td>\n",
       "      <td>0.090622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.018503</td>\n",
       "      <td>-0.081860</td>\n",
       "      <td>0.103133</td>\n",
       "      <td>0.075920</td>\n",
       "      <td>-0.016118</td>\n",
       "      <td>0.022301</td>\n",
       "      <td>0.074965</td>\n",
       "      <td>-0.014454</td>\n",
       "      <td>-0.042515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>-0.090288</td>\n",
       "      <td>0.205408</td>\n",
       "      <td>0.083452</td>\n",
       "      <td>-0.021273</td>\n",
       "      <td>0.105388</td>\n",
       "      <td>0.089513</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.122347</td>\n",
       "      <td>0.026380</td>\n",
       "      <td>-0.106663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.205986</td>\n",
       "      <td>0.165020</td>\n",
       "      <td>-0.191593</td>\n",
       "      <td>-0.152620</td>\n",
       "      <td>0.069355</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>0.042936</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>-0.003103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young_child</th>\n",
       "      <td>-0.088664</td>\n",
       "      <td>0.103843</td>\n",
       "      <td>0.080633</td>\n",
       "      <td>0.131359</td>\n",
       "      <td>0.181052</td>\n",
       "      <td>-0.050389</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>-0.133385</td>\n",
       "      <td>-0.011312</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087158</td>\n",
       "      <td>0.076534</td>\n",
       "      <td>-0.033679</td>\n",
       "      <td>-0.017185</td>\n",
       "      <td>-0.271744</td>\n",
       "      <td>0.113278</td>\n",
       "      <td>-0.021692</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>-0.151703</td>\n",
       "      <td>-0.009119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>-0.011421</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>-0.077571</td>\n",
       "      <td>-0.061826</td>\n",
       "      <td>-0.050209</td>\n",
       "      <td>-0.039554</td>\n",
       "      <td>-0.023727</td>\n",
       "      <td>-0.232815</td>\n",
       "      <td>0.234117</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.023236</td>\n",
       "      <td>-0.018881</td>\n",
       "      <td>0.106277</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>0.147399</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>0.256224</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.011791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>-0.039809</td>\n",
       "      <td>0.143098</td>\n",
       "      <td>0.109364</td>\n",
       "      <td>0.029712</td>\n",
       "      <td>0.127894</td>\n",
       "      <td>-0.047535</td>\n",
       "      <td>-0.050082</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.067090</td>\n",
       "      <td>-0.066447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053343</td>\n",
       "      <td>-0.015251</td>\n",
       "      <td>-0.038807</td>\n",
       "      <td>-0.086042</td>\n",
       "      <td>-0.101111</td>\n",
       "      <td>-0.011986</td>\n",
       "      <td>0.064623</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>-0.041173</td>\n",
       "      <td>-0.009698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.140483</td>\n",
       "      <td>0.123493</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.155623</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>-0.166562</td>\n",
       "      <td>-0.131816</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>-0.027659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>-0.125255</td>\n",
       "      <td>0.232657</td>\n",
       "      <td>0.127279</td>\n",
       "      <td>-0.003595</td>\n",
       "      <td>-0.043506</td>\n",
       "      <td>-0.029938</td>\n",
       "      <td>-0.100074</td>\n",
       "      <td>0.238505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0         1         2         3         4   \\\n",
       "Dear_Local_Newspaper        -0.080966  0.055885  0.006367  0.160840  0.153978   \n",
       "Dear_Newspaper              -0.160894 -0.078554 -0.005497  0.128657  0.114997   \n",
       "Dr.                         -0.048280  0.085749 -0.078311 -0.077604  0.105933   \n",
       "Facebook                     0.160234  0.161505 -0.004742  0.027028  0.042157   \n",
       "People                      -0.054791  0.059666 -0.006936 -0.049464  0.207019   \n",
       "ability                      0.061915  0.095871 -0.082138  0.038366  0.046556   \n",
       "ability_learn                0.078620 -0.060835  0.106955 -0.152974  0.055909   \n",
       "ability_learn_far_away       0.068378  0.036706  0.083156 -0.106033  0.218467   \n",
       "ability_learn_faraway_place -0.043237 -0.050755  0.093305  0.010634  0.205478   \n",
       "able                         0.023570 -0.053252  0.063354 -0.085435  0.164259   \n",
       "absolutely                   0.009471 -0.037858  0.118418  0.268994  0.313056   \n",
       "abuse                       -0.060129  0.100730  0.098544  0.117001  0.130719   \n",
       "access                      -0.016774  0.015856 -0.144403 -0.247768 -0.151972   \n",
       "accord                       0.023603  0.048625 -0.031065 -0.005102  0.164677   \n",
       "account                     -0.034982  0.061856 -0.047256 -0.047565  0.001725   \n",
       "accurate                     0.086073 -0.032643  0.139284  0.028096 -0.101803   \n",
       "acess                        0.080051 -0.026162 -0.011615 -0.231321  0.000147   \n",
       "act                         -0.249494  0.017735 -0.168136  0.125373  0.117684   \n",
       "action                      -0.099725  0.280859  0.035305  0.055052  0.066803   \n",
       "active                      -0.002011  0.124149 -0.012404  0.076643  0.300641   \n",
       "activity                    -0.014207 -0.051895 -0.065365  0.077290  0.242847   \n",
       "actually                    -0.124487  0.123299 -0.047490  0.076760  0.122557   \n",
       "ad                          -0.052581  0.090988  0.119070  0.018722  0.055564   \n",
       "add                         -0.185433 -0.083624 -0.036671 -0.040051  0.042287   \n",
       "addict                      -0.022299  0.191387 -0.074030 -0.055573  0.310384   \n",
       "addicted                    -0.180987  0.108654 -0.209175  0.048430  0.220865   \n",
       "addicting                    0.124235  0.220020  0.008297  0.060788  0.151284   \n",
       "addiction                   -0.041202  0.211525 -0.219157  0.047944  0.194943   \n",
       "addictive                   -0.135284  0.265247 -0.142602  0.277454  0.203590   \n",
       "addition                     0.067104  0.186199 -0.142296  0.034541 -0.001580   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "will                        -0.210274  0.107353  0.011885  0.136388  0.195531   \n",
       "will_not                    -0.129235  0.015577  0.009054  0.126605  0.071264   \n",
       "win                         -0.065997  0.051860  0.036722 -0.128991  0.104487   \n",
       "window                      -0.124794  0.047326 -0.135098  0.049944  0.008427   \n",
       "wish                         0.157742  0.211656  0.020748 -0.136406  0.062554   \n",
       "wonder                      -0.036164  0.063715  0.017805 -0.000229  0.248363   \n",
       "wonderful                    0.200375  0.110637  0.073242 -0.036366 -0.035389   \n",
       "word                        -0.045878 -0.054326  0.106562  0.250029  0.028261   \n",
       "work                        -0.116637 -0.073446 -0.211282 -0.112790  0.074468   \n",
       "worker                      -0.022504  0.003409 -0.090817 -0.057094 -0.108500   \n",
       "world                       -0.031874  0.139463 -0.143214 -0.134749 -0.035267   \n",
       "worried                     -0.149530  0.066812 -0.116020  0.057878  0.186423   \n",
       "worry                       -0.115249  0.006581  0.003609 -0.144226  0.076544   \n",
       "worth                        0.066123  0.025590  0.183848 -0.068840  0.141505   \n",
       "write                       -0.129512 -0.066839 -0.048920  0.171823 -0.177231   \n",
       "write_essay                 -0.276980 -0.092888  0.029463 -0.055676 -0.178226   \n",
       "write_letter                -0.094048 -0.188189  0.183612 -0.083681  0.003714   \n",
       "write_paper                 -0.039994 -0.162954  0.073475  0.183336 -0.065429   \n",
       "writing                      0.003102 -0.065624  0.116759  0.221152 -0.092194   \n",
       "wrong                       -0.159924 -0.071432  0.066980  0.063522  0.202766   \n",
       "yahoo                        0.118643  0.078907  0.077289  0.124349  0.050914   \n",
       "year                        -0.084354  0.051403 -0.092265  0.017354  0.049213   \n",
       "year_ago                     0.143823  0.146433  0.056964 -0.035602  0.032863   \n",
       "year_old                    -0.265906  0.137993  0.102887 -0.057300  0.240518   \n",
       "yes                         -0.113401 -0.039949  0.003711  0.141987  0.136337   \n",
       "young                       -0.090288  0.205408  0.083452 -0.021273  0.105388   \n",
       "young_child                 -0.088664  0.103843  0.080633  0.131359  0.181052   \n",
       "youth                       -0.011421  0.034357 -0.077571 -0.061826 -0.050209   \n",
       "youtube                     -0.039809  0.143098  0.109364  0.029712  0.127894   \n",
       "’                           -0.140483  0.123493  0.016328  0.021604  0.155623   \n",
       "\n",
       "                                   5         6         7         8         9   \\\n",
       "Dear_Local_Newspaper        -0.150762 -0.227000 -0.119609  0.028311  0.119844   \n",
       "Dear_Newspaper              -0.129569 -0.273821 -0.217280 -0.019305  0.088784   \n",
       "Dr.                          0.043426 -0.245606 -0.125072  0.157281  0.109850   \n",
       "Facebook                     0.097615 -0.074445  0.072042 -0.013195  0.026856   \n",
       "People                       0.001976  0.008313  0.076224 -0.133590 -0.162718   \n",
       "ability                     -0.055796 -0.045085 -0.001371 -0.175662 -0.038806   \n",
       "ability_learn                0.004751 -0.215835 -0.024729  0.032057 -0.039019   \n",
       "ability_learn_far_away       0.031863 -0.183279 -0.111118 -0.029186  0.013766   \n",
       "ability_learn_faraway_place -0.025085 -0.212736 -0.158275 -0.032956  0.036593   \n",
       "able                        -0.058869  0.080843  0.106354 -0.153176 -0.034961   \n",
       "absolutely                   0.026245 -0.136287 -0.139082 -0.000933  0.011531   \n",
       "abuse                        0.050971  0.028348 -0.110445 -0.042671  0.020960   \n",
       "access                      -0.002618 -0.021094 -0.106052 -0.072616  0.058271   \n",
       "accord                       0.130134 -0.074918 -0.004850  0.192992  0.155685   \n",
       "account                      0.026578 -0.001665 -0.015990 -0.091662  0.074502   \n",
       "accurate                    -0.074570 -0.103560  0.101796 -0.118272 -0.060125   \n",
       "acess                        0.039610 -0.229335 -0.029583  0.013439  0.050250   \n",
       "act                          0.136604  0.054115 -0.005799  0.041054 -0.051953   \n",
       "action                       0.053238 -0.038965 -0.197699  0.072265 -0.003704   \n",
       "active                       0.060930  0.082660 -0.099111  0.100015  0.088329   \n",
       "activity                    -0.060283 -0.081119 -0.153714 -0.105502  0.068179   \n",
       "actually                     0.006980 -0.086286 -0.007715 -0.100940 -0.014237   \n",
       "ad                           0.043385  0.015693 -0.114068  0.162840 -0.156114   \n",
       "add                          0.065492 -0.015215  0.014397 -0.114772  0.088571   \n",
       "addict                       0.063680 -0.085369 -0.100936  0.161640  0.005782   \n",
       "addicted                    -0.021063 -0.116353 -0.085872 -0.082910 -0.066901   \n",
       "addicting                    0.075862 -0.154718 -0.115967 -0.035943  0.065051   \n",
       "addiction                   -0.022224 -0.121570 -0.164046  0.000114  0.037053   \n",
       "addictive                    0.044446 -0.005216 -0.042800  0.039721  0.108935   \n",
       "addition                    -0.000304 -0.023728 -0.247746 -0.159316 -0.016654   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "will                         0.053409  0.076249  0.109844 -0.016581 -0.047279   \n",
       "will_not                     0.038460  0.011696  0.035405  0.003678 -0.108512   \n",
       "win                          0.201266 -0.089693  0.198117  0.128069 -0.058174   \n",
       "window                      -0.024452  0.082130  0.103574 -0.065450 -0.160271   \n",
       "wish                         0.185311  0.095738  0.090334 -0.082855 -0.145515   \n",
       "wonder                      -0.063726 -0.038604  0.141808  0.016108 -0.121845   \n",
       "wonderful                   -0.121819 -0.019157  0.108040 -0.199105 -0.103509   \n",
       "word                        -0.076788  0.055572 -0.094184  0.037543  0.172067   \n",
       "work                         0.096693  0.166608 -0.013387 -0.154851 -0.034203   \n",
       "worker                       0.057872  0.029849 -0.098129  0.028791 -0.088584   \n",
       "world                       -0.100296 -0.087241  0.060740 -0.058429 -0.146486   \n",
       "worried                      0.031979 -0.065942 -0.130018 -0.005233 -0.087113   \n",
       "worry                        0.149391 -0.062495  0.074391  0.156100  0.009033   \n",
       "worth                       -0.098121 -0.058005 -0.064479  0.136190  0.007481   \n",
       "write                       -0.010816 -0.117696  0.048246 -0.043790  0.162369   \n",
       "write_essay                  0.107930 -0.072077  0.043175 -0.009157  0.241753   \n",
       "write_letter                -0.073572 -0.097978  0.031064  0.052986  0.004131   \n",
       "write_paper                  0.028342 -0.081525  0.051980  0.021970  0.197878   \n",
       "writing                     -0.004935  0.056955  0.010158  0.036182  0.262661   \n",
       "wrong                       -0.027204 -0.115663 -0.068590  0.176000  0.168906   \n",
       "yahoo                       -0.077911 -0.201298  0.124579 -0.008861  0.066481   \n",
       "year                         0.095282  0.027088  0.115821  0.102618  0.017117   \n",
       "year_ago                    -0.061437 -0.182808  0.041300  0.014933 -0.046499   \n",
       "year_old                     0.011261 -0.163350  0.102529  0.084942 -0.083565   \n",
       "yes                         -0.221333 -0.167595 -0.077956 -0.124617  0.090622   \n",
       "young                        0.089513 -0.048530 -0.122347  0.026380 -0.106663   \n",
       "young_child                 -0.050389  0.063325 -0.133385 -0.011312  0.003758   \n",
       "youth                       -0.039554 -0.023727 -0.232815  0.234117  0.036047   \n",
       "youtube                     -0.047535 -0.050082  0.001353  0.067090 -0.066447   \n",
       "’                           -0.004921 -0.166562 -0.131816  0.039862 -0.027659   \n",
       "\n",
       "                             ...        90        91        92        93  \\\n",
       "Dear_Local_Newspaper         ...  0.083057 -0.036303 -0.172746  0.107085   \n",
       "Dear_Newspaper               ...  0.131236 -0.100623 -0.083030 -0.025299   \n",
       "Dr.                          ...  0.042051  0.012459 -0.073568  0.167597   \n",
       "Facebook                     ...  0.045397  0.061529 -0.110230 -0.138034   \n",
       "People                       ... -0.117228 -0.056509 -0.127031 -0.096924   \n",
       "ability                      ...  0.113731 -0.003393  0.111721 -0.185697   \n",
       "ability_learn                ...  0.200842  0.038983 -0.149448 -0.010260   \n",
       "ability_learn_far_away       ...  0.214203 -0.048395 -0.052231 -0.211182   \n",
       "ability_learn_faraway_place  ...  0.275119 -0.010331 -0.027732 -0.158186   \n",
       "able                         ...  0.029970 -0.001847 -0.063932 -0.096556   \n",
       "absolutely                   ... -0.134323 -0.086783 -0.121617 -0.086920   \n",
       "abuse                        ...  0.138893 -0.028911 -0.187556  0.004646   \n",
       "access                       ...  0.138290  0.049777 -0.109659 -0.086719   \n",
       "accord                       ...  0.029439 -0.012145 -0.067884 -0.066159   \n",
       "account                      ... -0.081644 -0.045451 -0.062248 -0.130844   \n",
       "accurate                     ...  0.047950 -0.004177 -0.047235  0.125650   \n",
       "acess                        ...  0.139043  0.123306 -0.073263  0.036500   \n",
       "act                          ...  0.067933  0.086227  0.030296  0.039736   \n",
       "action                       ... -0.143444  0.135385 -0.052328  0.090600   \n",
       "active                       ... -0.025298 -0.188665 -0.017035  0.020137   \n",
       "activity                     ... -0.088216 -0.000491  0.063110 -0.042854   \n",
       "actually                     ...  0.090606 -0.065074  0.019000  0.023920   \n",
       "ad                           ...  0.065438 -0.074953  0.056090  0.006360   \n",
       "add                          ... -0.004022 -0.200743  0.000062 -0.147879   \n",
       "addict                       ... -0.189984 -0.014849 -0.100763  0.062804   \n",
       "addicted                     ... -0.121385  0.001723 -0.041007  0.033138   \n",
       "addicting                    ... -0.020696  0.044556 -0.041164 -0.002323   \n",
       "addiction                    ... -0.180623  0.028451 -0.135802 -0.037686   \n",
       "addictive                    ... -0.034896 -0.014617 -0.072891 -0.068128   \n",
       "addition                     ... -0.006716 -0.130061  0.046863  0.101913   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "will                         ... -0.108592  0.088655 -0.043294  0.019784   \n",
       "will_not                     ... -0.039451  0.173878  0.027983  0.000860   \n",
       "win                          ... -0.057563  0.220913  0.009554 -0.068581   \n",
       "window                       ... -0.157480  0.075503  0.128558 -0.207491   \n",
       "wish                         ...  0.046139  0.137625 -0.134025 -0.010959   \n",
       "wonder                       ... -0.006780  0.145184  0.071114  0.042687   \n",
       "wonderful                    ...  0.032440  0.067650  0.142903 -0.063284   \n",
       "word                         ...  0.037526 -0.045535  0.082279  0.013238   \n",
       "work                         ...  0.015053 -0.172235 -0.083438 -0.119303   \n",
       "worker                       ... -0.002502 -0.220155 -0.013423 -0.171200   \n",
       "world                        ...  0.228013 -0.096753 -0.002665 -0.044096   \n",
       "worried                      ...  0.092626 -0.053344 -0.051258  0.146055   \n",
       "worry                        ... -0.173196  0.016125  0.086681 -0.016223   \n",
       "worth                        ... -0.104596  0.087585 -0.104555  0.040626   \n",
       "write                        ...  0.081206 -0.146629  0.106912 -0.111590   \n",
       "write_essay                  ...  0.096314 -0.044447  0.018310 -0.127319   \n",
       "write_letter                 ...  0.122145 -0.225296 -0.089557  0.001705   \n",
       "write_paper                  ...  0.022393 -0.094506  0.112994  0.026295   \n",
       "writing                      ...  0.052755 -0.107070  0.100780 -0.044422   \n",
       "wrong                        ...  0.037976  0.031521  0.092895  0.315482   \n",
       "yahoo                        ...  0.080930  0.005401  0.000851 -0.174040   \n",
       "year                         ... -0.016205  0.062934 -0.077875  0.093595   \n",
       "year_ago                     ... -0.061817  0.123939 -0.093537  0.038132   \n",
       "year_old                     ... -0.021522  0.070995  0.019442 -0.011797   \n",
       "yes                          ... -0.025857 -0.018503 -0.081860  0.103133   \n",
       "young                        ...  0.069264  0.205986  0.165020 -0.191593   \n",
       "young_child                  ...  0.087158  0.076534 -0.033679 -0.017185   \n",
       "youth                        ...  0.002169 -0.023236 -0.018881  0.106277   \n",
       "youtube                      ... -0.053343 -0.015251 -0.038807 -0.086042   \n",
       "’                            ...  0.000081  0.092527 -0.125255  0.232657   \n",
       "\n",
       "                                   94        95        96        97        98  \\\n",
       "Dear_Local_Newspaper        -0.002207 -0.054023 -0.026584  0.041401  0.089317   \n",
       "Dear_Newspaper               0.176573 -0.096566 -0.069011  0.045533  0.033215   \n",
       "Dr.                         -0.038416  0.056799  0.049680  0.022879 -0.012547   \n",
       "Facebook                    -0.101535  0.122856  0.225491  0.016016  0.037411   \n",
       "People                       0.016651 -0.033707 -0.080514 -0.129022  0.033612   \n",
       "ability                      0.000819  0.260463  0.133326 -0.022905  0.135234   \n",
       "ability_learn               -0.103228  0.045211  0.028685  0.023814  0.066922   \n",
       "ability_learn_far_away      -0.067038 -0.046495 -0.022695 -0.043916 -0.026545   \n",
       "ability_learn_faraway_place -0.004436 -0.042032  0.026861 -0.012597  0.061112   \n",
       "able                        -0.110397  0.145599  0.058895 -0.044561  0.179839   \n",
       "absolutely                   0.001776 -0.044351 -0.079989  0.007832 -0.135252   \n",
       "abuse                       -0.081402 -0.078189 -0.054812 -0.072359  0.006348   \n",
       "access                       0.018677  0.038707  0.214862  0.108611 -0.051788   \n",
       "accord                      -0.064794  0.077432  0.110461 -0.009767 -0.051933   \n",
       "account                      0.021602  0.045767  0.112684  0.020622 -0.031739   \n",
       "accurate                     0.033922 -0.016223  0.088164  0.177889 -0.017273   \n",
       "acess                        0.029464  0.010733  0.102984  0.055651 -0.032433   \n",
       "act                          0.058830  0.093552  0.140933 -0.012769 -0.014208   \n",
       "action                       0.018039 -0.082166  0.013245  0.094843  0.064940   \n",
       "active                      -0.121720 -0.019516 -0.057793 -0.134708 -0.021576   \n",
       "activity                    -0.248585  0.037895  0.140672  0.000508 -0.057184   \n",
       "actually                     0.155269  0.134975  0.084377 -0.108588  0.016488   \n",
       "ad                          -0.053827 -0.055392  0.041043  0.039948 -0.047681   \n",
       "add                         -0.054279  0.063821  0.003096  0.019184  0.072677   \n",
       "addict                      -0.072491 -0.054097 -0.050763 -0.024606  0.045586   \n",
       "addicted                    -0.053710  0.002833 -0.151991 -0.012026 -0.053500   \n",
       "addicting                   -0.120047  0.072648 -0.037826  0.137466  0.007619   \n",
       "addiction                    0.013853 -0.016029 -0.183707  0.182267 -0.015915   \n",
       "addictive                   -0.142953 -0.042299 -0.033439  0.133010 -0.002407   \n",
       "addition                     0.006348 -0.054943  0.125698  0.100385  0.147561   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "will                        -0.045943 -0.083427 -0.278405 -0.181813  0.149525   \n",
       "will_not                    -0.006654 -0.099778 -0.146238 -0.187370 -0.020311   \n",
       "win                         -0.105390 -0.068331  0.083326  0.055815 -0.045385   \n",
       "window                       0.143063  0.048720 -0.010025  0.151653  0.118451   \n",
       "wish                         0.025053 -0.010894 -0.032358  0.013457  0.069877   \n",
       "wonder                       0.111052 -0.197036  0.003673  0.086538  0.035479   \n",
       "wonderful                    0.077990 -0.083893  0.029566  0.009894  0.029312   \n",
       "word                        -0.041055  0.293838 -0.082126 -0.001794  0.103639   \n",
       "work                        -0.044952  0.023880 -0.010212 -0.037849 -0.073563   \n",
       "worker                       0.163627  0.041264  0.070564 -0.101153 -0.005687   \n",
       "world                        0.204079 -0.045788  0.020667 -0.024602 -0.044594   \n",
       "worried                     -0.053174 -0.227502  0.013293  0.035557  0.054435   \n",
       "worry                        0.018278  0.057971 -0.174869  0.051112  0.063893   \n",
       "worth                        0.083674 -0.016526 -0.317687 -0.199293 -0.058497   \n",
       "write                       -0.037091  0.156758 -0.080771 -0.085659  0.063928   \n",
       "write_essay                 -0.042781  0.205939  0.047902  0.039154  0.167516   \n",
       "write_letter                 0.155174  0.060816 -0.104516  0.033624  0.010150   \n",
       "write_paper                 -0.064076  0.253173  0.083666 -0.006361  0.068730   \n",
       "writing                     -0.146656  0.136562 -0.155263 -0.034360  0.040746   \n",
       "wrong                        0.080589 -0.107264  0.047725  0.101677 -0.060642   \n",
       "yahoo                        0.058013  0.026157  0.105651  0.076351  0.092045   \n",
       "year                        -0.052626  0.079668 -0.189148 -0.176204  0.061498   \n",
       "year_ago                    -0.105527 -0.060461  0.151425 -0.005155  0.005458   \n",
       "year_old                    -0.099303 -0.123955 -0.019513 -0.002453 -0.178045   \n",
       "yes                          0.075920 -0.016118  0.022301  0.074965 -0.014454   \n",
       "young                       -0.152620  0.069355  0.092479  0.042936  0.004319   \n",
       "young_child                 -0.271744  0.113278 -0.021692  0.116293 -0.151703   \n",
       "youth                       -0.002704  0.147399  0.020246  0.256224  0.002119   \n",
       "youtube                     -0.101111 -0.011986  0.064623  0.043936 -0.041173   \n",
       "’                            0.127279 -0.003595 -0.043506 -0.029938 -0.100074   \n",
       "\n",
       "                                   99  \n",
       "Dear_Local_Newspaper        -0.006336  \n",
       "Dear_Newspaper               0.079021  \n",
       "Dr.                          0.038800  \n",
       "Facebook                    -0.037007  \n",
       "People                      -0.022756  \n",
       "ability                     -0.020684  \n",
       "ability_learn                0.105161  \n",
       "ability_learn_far_away       0.121319  \n",
       "ability_learn_faraway_place  0.114431  \n",
       "able                        -0.101470  \n",
       "absolutely                  -0.084513  \n",
       "abuse                       -0.008121  \n",
       "access                      -0.025838  \n",
       "accord                       0.118402  \n",
       "account                     -0.023910  \n",
       "accurate                    -0.106321  \n",
       "acess                       -0.082574  \n",
       "act                         -0.048643  \n",
       "action                       0.072419  \n",
       "active                       0.065409  \n",
       "activity                    -0.010675  \n",
       "actually                    -0.051784  \n",
       "ad                          -0.048392  \n",
       "add                         -0.126859  \n",
       "addict                       0.021930  \n",
       "addicted                     0.047624  \n",
       "addicting                   -0.072847  \n",
       "addiction                    0.002725  \n",
       "addictive                    0.158381  \n",
       "addition                    -0.031337  \n",
       "...                               ...  \n",
       "will                         0.186288  \n",
       "will_not                    -0.008023  \n",
       "win                         -0.174301  \n",
       "window                      -0.048937  \n",
       "wish                         0.100498  \n",
       "wonder                       0.042903  \n",
       "wonderful                    0.077423  \n",
       "word                        -0.033845  \n",
       "work                        -0.151407  \n",
       "worker                       0.089583  \n",
       "world                        0.056458  \n",
       "worried                      0.078444  \n",
       "worry                        0.095718  \n",
       "worth                       -0.112080  \n",
       "write                       -0.056529  \n",
       "write_essay                 -0.085724  \n",
       "write_letter                -0.053705  \n",
       "write_paper                 -0.072751  \n",
       "writing                     -0.121560  \n",
       "wrong                        0.067841  \n",
       "yahoo                       -0.025008  \n",
       "year                        -0.014047  \n",
       "year_ago                    -0.035396  \n",
       "year_old                     0.006188  \n",
       "yes                         -0.042515  \n",
       "young                       -0.003103  \n",
       "young_child                 -0.009119  \n",
       "youth                        0.011791  \n",
       "youtube                     -0.009698  \n",
       "’                            0.238505  \n",
       "\n",
       "[1250 rows x 100 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a list of the terms, integer indices,\n",
    "# and term counts from the food2vec model vocabulary\n",
    "ordered_vocab = [(term, voc.index, voc.count)\n",
    "                 for term, voc in essay2vec_model.wv.vocab.items()]\n",
    "\n",
    "# sort by the term counts, so the most common terms appear first\n",
    "ordered_vocab = sorted(ordered_vocab)\n",
    "\n",
    "# unzip the terms, integer indices, and counts into separate lists\n",
    "ordered_terms, term_indices, term_counts = zip(*ordered_vocab)\n",
    "\n",
    "# create a DataFrame with the food2vec vectors as data,\n",
    "# and the terms as row labels\n",
    "word_vectors = pd.DataFrame(essay2vec_model.wv.syn0norm[term_indices, :], index=ordered_terms)\n",
    "\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy wall of numbers! This DataFrame has 1,257 rows &mdash; one for each term in the vocabulary &mdash; and 100 colums. Our model has learned a quantitative vector representation for each term, as expected.\n",
    "\n",
    "Put another way, our model has \"embedded\" the terms into a 100-dimensional vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So... what can we do with all these numbers?\n",
    "The first thing we can use them for is to simply look up related words and phrases for a given term of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_terms(token, topn=5):\n",
    "    \"\"\"\n",
    "    look up the topn most similar terms to token\n",
    "    and print them as a formatted list\n",
    "    \"\"\"\n",
    "\n",
    "    for word, similarity in essay2vec_model.wv.most_similar(positive=[token], topn=topn):\n",
    "\n",
    "        print('{:20} {}'.format(word, round(similarity, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What things are like Facebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter              0.667\n",
      "facebook_myspace     0.66\n",
      "skype                0.649\n",
      "Facebook             0.638\n",
      "yahoo                0.628\n"
     ]
    }
   ],
   "source": [
    "get_related_terms('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strongly_believe     0.655\n",
      "dear                 0.604\n",
      "believe              0.598\n",
      "come_attention       0.598\n",
      "great_invention      0.585\n"
     ]
    }
   ],
   "source": [
    "get_related_terms('society')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Word2Vec From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('dear local newspaper think effects computers people great learning skillsaffects give us time chat friendsnew people helps us learn globeastronomy keeps us troble thing dont think would feel teenager always phone friends ever time chat friends buisness partner things well theres new way chat computer plenty sites internet organization organization caps facebook myspace ect think setting meeting boss computer teenager fun phone rushing get cause want use learn countrysstates outside well computerinternet new way learn going time might think child spends lot time computer ask question economy sea floor spreading even dates youll surprise much heshe knows believe computer much interesting class day reading books child home computer local library better friends fresh perpressured something know isnt right might know child caps forbidde hospital bed driveby rather child computer learning chatting playing games safe sound home community place hope reached point understand agree computers great effects child gives us time chat friendsnew people helps us learn globe believe keeps us troble thank listening',\n",
       "      dtype='<U1114')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus = normalize_corpus(test_essay)\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from string import punctuation\n",
    "\n",
    "# remove_terms = punctuation + '0123456789'\n",
    "\n",
    "# norm_corpus = [[word.lower() for word in sent if word not in remove_terms] for sent in test_essay]\n",
    "# norm_corpus = [' '.join(tok_sent) for tok_sent in norm_corpus]\n",
    "# norm_corpus = filter(None, normalize_corpus(norm_corpus))\n",
    "# norm_corpus = [tok_sent for tok_sent in norm_corpus if len(tok_sent.split()) > 2]\n",
    "\n",
    "# print('Total lines:', len(test_essay))\n",
    "\n",
    "# norm_corpus\n",
    "# print('\\nSample line:', test_essay[1])\n",
    "# print('\\nProcessed line:', norm_corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "type(norm_corpus)\n",
    "# tokenizer.fit_on_texts(norm_corpus)\n",
    "# word2id = tokenizer.word_index\n",
    "\n",
    "# # build vocabulary of unique words\n",
    "# word2id['PAD'] = 0\n",
    "# id2word = {v:k for k, v in word2id.items()}\n",
    "# wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_corpus]\n",
    "\n",
    "# vocab_size = len(word2id)\n",
    "# embed_size = 100\n",
    "# window_size = 2 # context window size\n",
    "\n",
    "# print('Vocabulary Size:', vocab_size)\n",
    "# print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
