{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.helpers import uniqueColumns, printEssaySetStats\n",
    "from data.Essay_Dicts.essay_dictionaries import essay_prompts, essay_gradeLevels, essay_sourceDependent\n",
    "\n",
    "training_essay_set = pd.read_excel('./data/training_set_rel3.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Description\n",
    "The file contains 28 columns:\n",
    "\n",
    "+ essay_id: A unique identifier for each individual student essay\n",
    "+ essay_set: 1-8, an id for each set of essays\n",
    "+ essay: The ascii text of a student's response\n",
    "+ rater1_domain1: Rater 1's domain 1 score; all essays have this\n",
    "+ rater2_domain1: Rater 2's domain 1 score; all essays have this\n",
    "+ rater3_domain1: Rater 3's domain 1 score; only some essays in set 8 have this.\n",
    "+ domain1_score: Resolved score between the raters; all essays have this\n",
    "+ rater1_domain2: Rater 1's domain 2 score; only essays in set 2 have this\n",
    "+ rater2_domain2: Rater 2's domain 2 score; only essays in set 2 have this\n",
    "+ domain2_score: Resolved score between the raters; only essays in set 2 have this\n",
    "+ rater1_trait1 score - rater3_trait6 score: trait scores for sets 7-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anonymization in Essays\n",
    "\n",
    "We have made an effort to remove personally identifying information from the essays using the Named Entity Recognizer (NER) from the Stanford Natural Language Processing group and a variety of other approaches. The relevant entities are identified in the text and then replaced with a string such as \"@PERSON1.\"\n",
    "\n",
    "The entitities identified by NER are: \"PERSON\", \"ORGANIZATION\", \"LOCATION\", \"DATE\", \"TIME\", \"MONEY\", \"PERCENT\"\n",
    "\n",
    "Other replacements made: \"MONTH\" (any month name not tagged as a date by the NER), \"EMAIL\" (anything that looks like an e-mail address), \"NUM\" (word containing digits or non-alphanumeric symbols), and \"CAPS\" (any capitalized word that doesn't begin a sentence, except in essays where more than 20% of the characters are capitalized letters), \"DR\" (any word following \"Dr.\" with or without the period, with any capitalization, that doesn't fall into any of the above), \"CITY\" and \"STATE\" (various cities and states).\n",
    "\n",
    "Here are some hypothetical examples of replacements made:\n",
    "\n",
    "+ \"I attend Springfield School...\" --> \"...I attend @ORGANIZATION1\"\n",
    "+ \"once my family took my on a trip to Springfield.\" --> \"once my family took me on a trip to @LOCATION1\"\n",
    "+ \"John Doe is a person, and so is Jane Doe. But if I talk about Mr. Doe, I can't tell that's the same person.\" --> \"...@PERSON1 is a person, and so is @PERSON2. But if you talk about @PERSON3, I can't tell that's the same person.\"\n",
    "+ \"...my phone number is 555-2106\" --> \"...my phone number is @NUM1\"\n",
    "\n",
    "Any words appearing in the prompt or source material for the corresponding essay set were white-listed and not anonymized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of esseays in the dataset: 12978\n"
     ]
    }
   ],
   "source": [
    "print('Total number of esseays in the dataset: {}'.format(len(training_essay_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_id\n",
      "essay_set\n",
      "essay\n",
      "rater1_domain1\n",
      "rater2_domain1\n",
      "rater3_domain1\n",
      "domain1_score\n",
      "rater1_domain2\n",
      "rater2_domain2\n",
      "domain2_score\n",
      "rater1_trait1\n",
      "rater1_trait2\n",
      "rater1_trait3\n",
      "rater1_trait4\n",
      "rater1_trait5\n",
      "rater1_trait6\n",
      "rater2_trait1\n",
      "rater2_trait2\n",
      "rater2_trait3\n",
      "rater2_trait4\n",
      "rater2_trait5\n",
      "rater2_trait6\n",
      "rater3_trait1\n",
      "rater3_trait2\n",
      "rater3_trait3\n",
      "rater3_trait4\n",
      "rater3_trait5\n",
      "rater3_trait6\n"
     ]
    }
   ],
   "source": [
    "uniqueColumns(training_essay_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = training_essay_set[training_essay_set.essay_set == 1]\n",
    "set2 = training_essay_set[training_essay_set.essay_set == 2]\n",
    "set3 = training_essay_set[training_essay_set.essay_set == 3]\n",
    "set4 = training_essay_set[training_essay_set.essay_set == 4]\n",
    "set5 = training_essay_set[training_essay_set.essay_set == 5]\n",
    "set6 = training_essay_set[training_essay_set.essay_set == 6]\n",
    "set7 = training_essay_set[training_essay_set.essay_set == 7]\n",
    "set8 = training_essay_set[training_essay_set.essay_set == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #1 Length of dataset 1783\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       0\n",
      "rater2_domain1       0\n",
      "rater3_domain1    1783\n",
      "domain1_score        0\n",
      "rater1_domain2    1783\n",
      "rater2_domain2    1783\n",
      "domain2_score     1783\n",
      "rater1_trait1     1783\n",
      "rater1_trait2     1783\n",
      "rater1_trait3     1783\n",
      "rater1_trait4     1783\n",
      "rater1_trait5     1783\n",
      "rater1_trait6     1783\n",
      "rater2_trait1     1783\n",
      "rater2_trait2     1783\n",
      "rater2_trait3     1783\n",
      "rater2_trait4     1783\n",
      "rater2_trait5     1783\n",
      "rater2_trait6     1783\n",
      "rater3_trait1     1783\n",
      "rater3_trait2     1783\n",
      "rater3_trait3     1783\n",
      "rater3_trait4     1783\n",
      "rater3_trait5     1783\n",
      "rater3_trait6     1783\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #2 Length of dataset 1800\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       0\n",
      "rater2_domain1       0\n",
      "rater3_domain1    1800\n",
      "domain1_score        0\n",
      "rater1_domain2       0\n",
      "rater2_domain2       0\n",
      "domain2_score        0\n",
      "rater1_trait1     1800\n",
      "rater1_trait2     1800\n",
      "rater1_trait3     1800\n",
      "rater1_trait4     1800\n",
      "rater1_trait5     1800\n",
      "rater1_trait6     1800\n",
      "rater2_trait1     1800\n",
      "rater2_trait2     1800\n",
      "rater2_trait3     1800\n",
      "rater2_trait4     1800\n",
      "rater2_trait5     1800\n",
      "rater2_trait6     1800\n",
      "rater3_trait1     1800\n",
      "rater3_trait2     1800\n",
      "rater3_trait3     1800\n",
      "rater3_trait4     1800\n",
      "rater3_trait5     1800\n",
      "rater3_trait6     1800\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #3 Length of dataset 1726\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       0\n",
      "rater2_domain1       0\n",
      "rater3_domain1    1726\n",
      "domain1_score        0\n",
      "rater1_domain2    1726\n",
      "rater2_domain2    1726\n",
      "domain2_score     1726\n",
      "rater1_trait1     1726\n",
      "rater1_trait2     1726\n",
      "rater1_trait3     1726\n",
      "rater1_trait4     1726\n",
      "rater1_trait5     1726\n",
      "rater1_trait6     1726\n",
      "rater2_trait1     1726\n",
      "rater2_trait2     1726\n",
      "rater2_trait3     1726\n",
      "rater2_trait4     1726\n",
      "rater2_trait5     1726\n",
      "rater2_trait6     1726\n",
      "rater3_trait1     1726\n",
      "rater3_trait2     1726\n",
      "rater3_trait3     1726\n",
      "rater3_trait4     1726\n",
      "rater3_trait5     1726\n",
      "rater3_trait6     1726\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #4 Length of dataset 1772\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       1\n",
      "rater2_domain1       1\n",
      "rater3_domain1    1772\n",
      "domain1_score        1\n",
      "rater1_domain2    1772\n",
      "rater2_domain2    1772\n",
      "domain2_score     1772\n",
      "rater1_trait1     1772\n",
      "rater1_trait2     1772\n",
      "rater1_trait3     1772\n",
      "rater1_trait4     1772\n",
      "rater1_trait5     1772\n",
      "rater1_trait6     1772\n",
      "rater2_trait1     1772\n",
      "rater2_trait2     1772\n",
      "rater2_trait3     1772\n",
      "rater2_trait4     1772\n",
      "rater2_trait5     1772\n",
      "rater2_trait6     1772\n",
      "rater3_trait1     1772\n",
      "rater3_trait2     1772\n",
      "rater3_trait3     1772\n",
      "rater3_trait4     1772\n",
      "rater3_trait5     1772\n",
      "rater3_trait6     1772\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #5 Length of dataset 1805\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       0\n",
      "rater2_domain1       0\n",
      "rater3_domain1    1805\n",
      "domain1_score        0\n",
      "rater1_domain2    1805\n",
      "rater2_domain2    1805\n",
      "domain2_score     1805\n",
      "rater1_trait1     1805\n",
      "rater1_trait2     1805\n",
      "rater1_trait3     1805\n",
      "rater1_trait4     1805\n",
      "rater1_trait5     1805\n",
      "rater1_trait6     1805\n",
      "rater2_trait1     1805\n",
      "rater2_trait2     1805\n",
      "rater2_trait3     1805\n",
      "rater2_trait4     1805\n",
      "rater2_trait5     1805\n",
      "rater2_trait6     1805\n",
      "rater3_trait1     1805\n",
      "rater3_trait2     1805\n",
      "rater3_trait3     1805\n",
      "rater3_trait4     1805\n",
      "rater3_trait5     1805\n",
      "rater3_trait6     1805\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #6 Length of dataset 1800\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       0\n",
      "rater2_domain1       0\n",
      "rater3_domain1    1800\n",
      "domain1_score        0\n",
      "rater1_domain2    1800\n",
      "rater2_domain2    1800\n",
      "domain2_score     1800\n",
      "rater1_trait1     1800\n",
      "rater1_trait2     1800\n",
      "rater1_trait3     1800\n",
      "rater1_trait4     1800\n",
      "rater1_trait5     1800\n",
      "rater1_trait6     1800\n",
      "rater2_trait1     1800\n",
      "rater2_trait2     1800\n",
      "rater2_trait3     1800\n",
      "rater2_trait4     1800\n",
      "rater2_trait5     1800\n",
      "rater2_trait6     1800\n",
      "rater3_trait1     1800\n",
      "rater3_trait2     1800\n",
      "rater3_trait3     1800\n",
      "rater3_trait4     1800\n",
      "rater3_trait5     1800\n",
      "rater3_trait6     1800\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #7 Length of dataset 1569\n",
      "essay_id             0\n",
      "essay_set            0\n",
      "essay                0\n",
      "rater1_domain1       0\n",
      "rater2_domain1       0\n",
      "rater3_domain1    1569\n",
      "domain1_score        0\n",
      "rater1_domain2    1569\n",
      "rater2_domain2    1569\n",
      "domain2_score     1569\n",
      "rater1_trait1        0\n",
      "rater1_trait2        0\n",
      "rater1_trait3        0\n",
      "rater1_trait4        0\n",
      "rater1_trait5     1569\n",
      "rater1_trait6     1569\n",
      "rater2_trait1        0\n",
      "rater2_trait2        0\n",
      "rater2_trait3        0\n",
      "rater2_trait4        0\n",
      "rater2_trait5     1569\n",
      "rater2_trait6     1569\n",
      "rater3_trait1     1569\n",
      "rater3_trait2     1569\n",
      "rater3_trait3     1569\n",
      "rater3_trait4     1569\n",
      "rater3_trait5     1569\n",
      "rater3_trait6     1569\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set #8 Length of dataset 723\n",
      "essay_id            0\n",
      "essay_set           0\n",
      "essay               0\n",
      "rater1_domain1      0\n",
      "rater2_domain1      0\n",
      "rater3_domain1    595\n",
      "domain1_score       0\n",
      "rater1_domain2    723\n",
      "rater2_domain2    723\n",
      "domain2_score     723\n",
      "rater1_trait1       0\n",
      "rater1_trait2       0\n",
      "rater1_trait3       0\n",
      "rater1_trait4       0\n",
      "rater1_trait5       0\n",
      "rater1_trait6       0\n",
      "rater2_trait1       0\n",
      "rater2_trait2       0\n",
      "rater2_trait3       0\n",
      "rater2_trait4       0\n",
      "rater2_trait5       0\n",
      "rater2_trait6       0\n",
      "rater3_trait1     595\n",
      "rater3_trait2     595\n",
      "rater3_trait3     595\n",
      "rater3_trait4     595\n",
      "rater3_trait5     595\n",
      "rater3_trait6     595\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printEssaySetStats(set8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set['prompt'] = training_essay_set.essay_set.map(essay_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set['grade_level'] = training_essay_set.essay_set.map(essay_gradeLevels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set['has_source_material'] = training_essay_set.essay_set.map(essay_sourceDependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "source3 = open('./data/sourceEssay3.txt')\n",
    "source4 = open('./data/sourceEssay4.txt')\n",
    "source5 = open('./data/sourceEssay5.txt')\n",
    "source6 = open('./data/sourceEssay6.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_sourceText = {\n",
    "    1: np.nan,\n",
    "    2: np.nan,\n",
    "    3: source3.read(),\n",
    "    4: source4.read(),\n",
    "    5: source5.read(),\n",
    "    6: source6.read(),\n",
    "    7: np.nan,\n",
    "    8: np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set['source_text'] = training_essay_set.essay_set.map(essay_sourceText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradeDF = pd.get_dummies(training_essay_set['grade_level'], prefix='grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set = pd.concat([training_essay_set, gradeDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set.drop(['grade_level', 7, 8, 10], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_essay_set.to_csv('./data/prepped_essays_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
